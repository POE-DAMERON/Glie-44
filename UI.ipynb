{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UI.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN77YiuQrScnGQ4e0rhQbde",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/POE-DAMERON/Glie-44/blob/main/UI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOOULEB41Jny"
      },
      "source": [
        "class Utils():\n",
        "\n",
        "  @staticmethod\n",
        "  def add_blocks(pred, draw, height, width, font_path, precision):\n",
        "    boxes = pred['detection_boxes'].numpy()[0]\n",
        "    classes = pred['detection_classes'].numpy()[0]\n",
        "\n",
        "    boxes[:, 0] *= height\n",
        "    boxes[:, 1] *= width\n",
        "    boxes[:, 2] *= height\n",
        "    boxes[:, 3] *= width\n",
        "    \n",
        "    for i in range(len(boxes)):\n",
        "      if pred['detection_scores'].numpy()[0][i] > precision:\n",
        "        draw.rectangle(Utils.prepare_coords(boxes[i]), outline = Utils.which_color(classes[i]), width = 3)\n",
        "        draw.text((boxes[i][1], boxes[i][0]),str(classes[i])[:-2], fill=(255,255,255), stroke_fill= (0,0,0,255), stroke_width = 2, font= ImageFont.truetype(font_path, 20))\n",
        "\n",
        "  @staticmethod\n",
        "  def which_color(class_id):\n",
        "    color_value = int(class_id) * 9\n",
        "    return (min(color_value, 255), max(min(color_value - 255, 255),0),max(min(color_value - 256 * 2 - 1, 255),0))\n",
        "\n",
        "  @staticmethod\n",
        "  def prepare_coords(array):\n",
        "    return (array[1], array[0], array[3], array[2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwLPBwbY1N-7"
      },
      "source": [
        "class Glie_44():\n",
        "\n",
        "  def __init__(self, precision = .2, font_path = Path().absolute().joinpath('Glie-44/Model/Data/fonts/Roboto-Regular.ttf')):\n",
        "    self._precision = precision\n",
        "    self._font_path = str(font_path)\n",
        "\n",
        "\n",
        "  def set_font_path(self, font_path):\n",
        "    self._font_path = font_path\n",
        "\n",
        "\n",
        "  def load_model(self):\n",
        "    self._model = hub.load(\"https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2\")\n",
        "\n",
        "  def set_model(self,model):\n",
        "    self._model = model\n",
        "\n",
        "  def get_image_data(self, image_path):\n",
        "    image_data = plt.imread(image_path)\n",
        "    return np.array(image_data)\n",
        "\n",
        "  def pred(self, image_data):\n",
        "    return self._model(image_data)\n",
        "\n",
        "  def pred_on_image_path(self, image_path):\n",
        "    image_data = np.array([self.get_image_data(image_path)])\n",
        "    return self.pred(image_data)\n",
        "  \n",
        "  def run_on_image(self, image_data):\n",
        "    pred = self.pred(np.array([image_data]))\n",
        "\n",
        "    image = Image.fromarray(image_data)\n",
        "    draw = ImageDraw.Draw(image)\n",
        "    Utils.add_blocks(pred,draw, image.size[1], image.size[0], self._font_path, self._precision)\n",
        "\n",
        "    return np.array(image)\n",
        "\n",
        "  def run_on_image_with_path(self, image_path):\n",
        "    pred = self.pred_on_image_path(image_path)\n",
        "\n",
        "    image = Image.open(image_path)\n",
        "    draw = ImageDraw.Draw(image)\n",
        "    Utils.add_blocks(pred,draw, image.size[1], image.size[0], self._font_path, self._precision)\n",
        "\n",
        "    return np.array(image)\n",
        "\n",
        "  # Takes a folder path where the images should be in chronological order to \n",
        "  # detect and compile in a video\n",
        "\n",
        "  def run_on_folder(self, folder_path = Path().absolute().joinpath('Glie-44/Model/Data/VisDrone2019-MOT-train/sequences/uav0000013_00000_v'), output_folder = Path().absolute().joinpath('Glie-44/Model/outputs'), framerate = 20):\n",
        "\n",
        "    video_frames = sorted(listdir(folder_path), key=lambda x: x.lstrip(\"_\"))\n",
        "    s = Image.open(Path(folder_path).joinpath(video_frames[0])).size\n",
        "\n",
        "    output_path = path.basename(folder_path) + '.avi'\n",
        "    fourcc = cv.VideoWriter_fourcc(*'DIVX')\n",
        "    writer = cv.VideoWriter(str(output_folder) + '/' + output_path, fourcc, framerate, s)\n",
        "\n",
        "    sample = video_frames\n",
        "    total_frames = len(sample)\n",
        "    for i in range(total_frames):\n",
        "      #print(i + 1, '/', total_frames)\n",
        "      result = self.run_on_image_with_path(Path(folder_path).joinpath(sample[i]))\n",
        "      #print(sample[i], ':', result.shape)\n",
        "      writer.write(cv.cvtColor(result,cv.COLOR_RGB2BGR))\n",
        "\n",
        "    writer.release()\n",
        "\n",
        "  # Takes a video file to detect objects\n",
        "\n",
        "  def run_on_video(self, video_path, output_folder = Path().absolute().joinpath('Glie-44/Model/outputs'), framerate = 24):\n",
        "    cap = cv.VideoCapture(video_path)\n",
        "\n",
        "    output_path = Path(video_path).stem + '_output.avi'\n",
        "\n",
        "    if (cap.isOpened()):\n",
        "      s = (int(cap.get(3)),int(cap.get(4)))\n",
        "      fourcc = cv.VideoWriter_fourcc(*'DIVX')\n",
        "      writer = cv.VideoWriter(str(output_folder) + '/' + output_path, fourcc, framerate, s)\n",
        "      ret, frame = cap.read()\n",
        "\n",
        "      while ret == True:\n",
        "        result = self.run_on_image(frame)\n",
        "          \n",
        "        writer.write(result)\n",
        "        ret, frame = cap.read()\n",
        "\n",
        "  #  takes a video stream and outputs a video stream with the boxes around the\n",
        "  #  detected objects\n",
        "\n",
        "  def run_on_stream():\n",
        "    pass\n",
        "\n",
        "  def build_video_from_directory(self, folder_path = Path().absolute().joinpath('Glie-44/Model/Data/VisDrone2019-MOT-train/sequences/uav0000013_00000_v'), output_folder = Path().absolute(), framerate = 24):\n",
        "    video_frames = sorted(listdir(folder_path), key=lambda x: x.lstrip(\"_\"))\n",
        "    s = Image.open(Path(folder_path).joinpath(video_frames[0])).size\n",
        "\n",
        "    output_path = 'Video_test.avi'\n",
        "    fourcc = cv.VideoWriter_fourcc(*'DIVX')\n",
        "    writer = cv.VideoWriter(str(output_folder) + '/' + output_path, fourcc, framerate, s)\n",
        "\n",
        "    sample = video_frames\n",
        "    total_frames = len(sample)\n",
        "    for i in range(total_frames):\n",
        "      print(i + 1, '/', total_frames)\n",
        "      result = self.get_image_data(Path(folder_path).joinpath(sample[i]))#np.array(Image.open(Path(folder_path).joinpath(sample[i])))\n",
        "      #print(sample[i], ':', result.shape)\n",
        "      writer.write(cv.cvtColor(result,cv.COLOR_RGB2BGR))\n",
        "\n",
        "    writer.release()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQMnQ_x21PyZ"
      },
      "source": [
        "glie = Glie_44()\n",
        "glie.set_model(model2)\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "#    TO TEST THE RUN_ON_IMAGE\n",
        "\n",
        "pred_image = glie.run_on_image_with_path('Glie-44/Model/Data/VisDrone2019-MOT-train/sequences/uav0000013_01073_v/0000001.jpg')\n",
        "plt.figure(figsize=(24,32))\n",
        "plt.imshow(pred_image)\n",
        "\n",
        "pred = glie.pred_on_image_path('Glie-44/Model/Data/VisDrone2019-MOT-train/sequences/uav0000013_01073_v/0000001.jpg')\n",
        "pred\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "glie.run_on_video(video_path='Video_test.avi',output_folder=Path().absolute())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khpQah3A1UB3"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "x = np.array(Image.open('Glie-44/Model/Data/VisDrone2019-MOT-train/sequences/uav0000013_01073_v/0000001.jpg'))\n",
        "shape = x.shape\n",
        "x = np.array([])\n",
        "\n",
        "video_frames = sorted(listdir(folder_path), key=lambda x: x.lstrip(\"_\"))\n",
        "total_frames = len(video_frames)\n",
        "for i in range(total_frames):\n",
        "  x[i] = Image.open(Path().absolute().joinpath('Glie-44/Model/Data/VisDrone2019-MOT-train/sequences/uav0000013_00000_v').joinpath(video_frames[i]))\n",
        "\n",
        "initial_layer = tf.keras.Input(shape=shape, name=\"initial_layer\",dtype=tf.uint8)\n",
        "layer = test(initial_layer)['detection_scores']# ou ['detection_boxes']\n",
        "print(layer)\n",
        "#layer = tf.keras.layers.Flatten()(initial_layer)\n",
        "layer = tf.keras.layers.Flatten()(layer)\n",
        "layer = tf.keras.layers.Dense(100, activation='relu',)(layer)\n",
        "last_layer = tf.keras.layers.Dense(10, activation='softmax')(layer)\n",
        "\n",
        "model = tf.keras.Model(initial_layer, last_layer)\n",
        "\n",
        "\n",
        "model.compile(optimizer=\"adam\", metrics=['accuracy'], loss='categorical_crossentropy')\n",
        "model.summary()\n",
        "\n",
        "model.fit(x=x, y=np.ones((1,10)), batch_size=1, epochs = 1)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}