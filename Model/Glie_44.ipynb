{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Glie_44.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/POE-DAMERON/Glie-44/blob/main/Model/Glie_44.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPx23mf0avpR"
      },
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow_hub as hub\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from os import path, listdir\n",
        "from pathlib import Path\n",
        "import cv2 as cv\n",
        "from google.colab import drive\n",
        "import sys\n",
        "import io\n",
        "import random\n",
        "\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "'''\n",
        "  Downloads Data from the VisDrone dataset.\n",
        "  Input is which dataset to download:\n",
        "    - 0 is the training dataset\n",
        "    - 1 is the developper testing dataset\n",
        "    - 2 is the actual challenge testing dataset\n",
        "    - 3 is the val dataset\n",
        "'''\n",
        "\n",
        "def initialize_training(file = 0):\n",
        "  !git clone https://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@github.com/POE-DAMERON/Glie-44.git\n",
        "  drive.mount('/content/drive')\n",
        "\n",
        "  \n",
        "  if file == 1:\n",
        "    !unzip /content/drive/MyDrive/VisDrone2019-MOT-test-dev.zip\n",
        "  elif file == 2:\n",
        "    !unzip /content/drive/MyDrive/VisDrone2019-MOT-test-challenge.zip\n",
        "  elif file == 3:\n",
        "    !unzip /content/drive/MyDrive/VisDrone2019-MOT-val.zip\n",
        "  else:\n",
        "    !unzip /content/drive/MyDrive/VisDrone2019-MOT-train.zip\n",
        "\n",
        "initialize_training()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDWgZe8DQZS4"
      },
      "source": [
        "**New Model using Pytorch**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23EcvQ0gWTmO"
      },
      "source": [
        "Main.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Saxy2LvOmdbn",
        "outputId": "8479da8d-1d65-47f6-9510-03dcd0b22567"
      },
      "source": [
        "%%shell\n",
        "\n",
        "git clone https://github.com/pytorch/vision.git\n",
        "cd vision\n",
        "git checkout v0.3.0\n",
        "\n",
        "cp references/detection/utils.py ../\n",
        "cp references/detection/transforms.py ../\n",
        "cp references/detection/coco_eval.py ../\n",
        "cp references/detection/engine.py ../\n",
        "cp references/detection/coco_utils.py ../"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'vision' already exists and is not an empty directory.\n",
            "HEAD is now at be376084 version check against PyTorch's CUDA version\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKOtVOkjWSps"
      },
      "source": [
        "import torch\n",
        "from engine import train_one_epoch, evaluate\n",
        "import utils\n",
        "import os\n",
        "import pandas as pd\n",
        "import transforms as T\n",
        "from pathlib import Path\n",
        "import csv\n",
        "import time\n",
        "\n",
        "def get_results(evaluator):\n",
        "  old_stdout = sys.stdout\n",
        "  sys.stdout = buffer = io.StringIO()\n",
        "\n",
        "  result = str(evaluator.coco_eval)\n",
        "  test = evaluator.coco_eval.items()\n",
        "  for iou_type, coco_eval in test:\n",
        "    print(\"IoU metric: {}\".format(iou_type))\n",
        "    try:\n",
        "      print(coco_eval)\n",
        "    except:\n",
        "      pass\n",
        "\n",
        "  sys.stdout = old_stdout\n",
        "\n",
        "  return buffer.getvalue()\n",
        "\n",
        "def add_to_record(arguments, output, is_saved = False, path_to_saved_model = ''):\n",
        "\n",
        "  with open('drive/MyDrive/training.csv', 'a', newline='') as f:\n",
        "    writer = csv.writer(f)\n",
        "\n",
        "    #writer.writerow(['Saved', 'path_to_saved_model', 'number_of_epochs', 'batch_size', 'optimizer', 'learning_rate', 'weight_decay', 'momentum', 'lr_scheduler_step_size', 'lr_scheduler_gamma', 'output'])\n",
        "    writer.writerow([is_saved, path_to_saved_model, arguments['number_of_epochs'], arguments['batch_size'], arguments['optimizer'], arguments['lr'], arguments['weight_decay'], arguments['momentum'], arguments['lr_scheduler_step_size'], arguments['lr_scheduler_gamma'], output])\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "  saving the model will add it to the record\n",
        "\"\"\"\n",
        "\n",
        "def save_model(model, evaluator, arguments, path = ''):\n",
        "\n",
        "  \"\"\"\n",
        "      saves the model and adds to the csv records\n",
        "\n",
        "      2 methods :\n",
        "        - saving the whole model\n",
        "        - saving the weights and info\n",
        "  \"\"\"\n",
        "\n",
        "  if path == '':\n",
        "    path = 'drive/MyDrive/Models/model-' + str(int(time.time())) + '.pth'\n",
        "\n",
        "  torch.save(model,path) \n",
        "\n",
        "  #torch.save(model.state_dict(), path)\n",
        "  add_to_record(arguments = arguments, output = evaluator, is_saved = True, path_to_saved_model = path)\n",
        "  \n",
        "def load_model(path):\n",
        "\n",
        "  model = torch.load(path)\n",
        "\n",
        "  \"\"\"\n",
        "    model = Model()\n",
        "    model.load_state_dict(torch.load(path))\n",
        "  \"\"\"\n",
        "\n",
        "  return model\n",
        "\n",
        "def get_arguments(train_percentage, epochs, batch_size, optimizer,\n",
        "                            lr, momentum, weight_decay, step_size, gamma):\n",
        "  \n",
        "  arguments = {}\n",
        "\n",
        "  arguments['train_percentage'] = train_percentage\n",
        "  if (optimizer == 'adam'):\n",
        "    arguments['optimizer'] = optimizer\n",
        "    arguments['momentum'] = ''\n",
        "  else:\n",
        "    arguments['optimizer'] = 'sgd'\n",
        "    arguments['momentum'] = momentum\n",
        "  arguments['lr'] = lr\n",
        "  arguments['weight_decay'] = weight_decay\n",
        "  arguments['lr_scheduler_step_size'] = step_size\n",
        "  arguments['lr_scheduler_gamma'] = gamma\n",
        "  arguments['number_of_epochs'] = epochs\n",
        "  arguments['batch_size'] = batch_size\n",
        "\n",
        "  return arguments\n",
        "\n",
        "def train_videos(path_to_saved_model = '', train_percentage = .8, test_size = -1,\n",
        "          train_size = -1, batch_size = 2, epochs = 10, optimizer='sgd',\n",
        "          lr = 0.005, momentum = 0.9, weight_decay= 0.0005, step_size = 3,\n",
        "          gamma = 0.1):\n",
        "  \n",
        "  arguments = get_arguments(train_percentage, epochs, batch_size, optimizer,\n",
        "                            lr, momentum, weight_decay, step_size, gamma)\n",
        "  \n",
        "  if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "  else:\n",
        "    device = torch.device('cpu')\n",
        "  \n",
        "  x = VisDroneDataset(Path().absolute().joinpath('VisDrone2019-MOT-train'), Utils.to_tensor())\n",
        "  testing_data = torch.utils.data.DataLoader(x[0])\n",
        "\n",
        "  for i in range(len(x)):\n",
        "\n",
        "    print(\"\\n-----------------------------\\nVideo {} / {}\\n\".format(i+1, len(x)))\n",
        "\n",
        "    X = x[i]\n",
        "\n",
        "    if train_size == -1:\n",
        "      train_sz = int(len(X) * train_percentage)\n",
        "    else:\n",
        "      train_sz = train_size\n",
        "      \n",
        "    x_train, x_test = torch.utils.data.random_split(X, [train_sz, len(X) - train_sz])\n",
        "\n",
        "    if test_size != -1:\n",
        "      x_test = Utils.slice(x_test, 0, test_size)\n",
        "\n",
        "    data_loader = torch.utils.data.DataLoader(\n",
        "          x_train, batch_size=batch_size, shuffle=True, num_workers=2,\n",
        "          collate_fn=utils.collate_fn)\n",
        "    \n",
        "    data_loader_test = torch.utils.data.DataLoader(\n",
        "      x_test, batch_size=1, shuffle=False, num_workers=2,\n",
        "      collate_fn=utils.collate_fn)\n",
        "    \n",
        "    testing_data = data_loader_test\n",
        "    \n",
        "    if str(path_to_saved_model) == '':\n",
        "      model = build_model()\n",
        "    else:\n",
        "      model = load_model(path_to_saved_model)\n",
        "\n",
        "    model.to(device)\n",
        "\n",
        "    params = [p for p in model.parameters() if p.requires_grad]\n",
        "\n",
        "    if (optimizer == 'adam'):\n",
        "      optim = torch.optim.Adam(params, lr=lr, weight_decay=weight_decay)\n",
        "    else:\n",
        "      optim = torch.optim.SGD(params, lr=lr,\n",
        "                              momentum=momentum, weight_decay=weight_decay)\n",
        "\n",
        "    lr_scheduler = torch.optim.lr_scheduler.StepLR(optim,\n",
        "                                                    step_size=step_size,\n",
        "                                                    gamma=gamma)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "          train_one_epoch(model, optim, data_loader, device, epoch, print_freq=10)\n",
        "          lr_scheduler.step()\n",
        "          evaluate(model, testing_data, device=device)\n",
        "  \n",
        "  return model, evaluate(model, testing_data, device=device), arguments\n",
        "\n",
        "def train(path_to_saved_model = '', train_percentage = .8, test_percentage = -1,\n",
        "          test_size = -1, train_size = -1, batch_size = 2, epochs = 10, optimizer='sgd',\n",
        "          lr = 0.005, momentum = 0.9, weight_decay= 0.0005, step_size = 3,\n",
        "          gamma = 0.1, checkpoints=-1):\n",
        "  \n",
        "  arguments = get_arguments(train_percentage, epochs, batch_size, optimizer,\n",
        "                            lr, momentum, weight_decay, step_size, gamma)\n",
        "  \n",
        "  if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "  else:\n",
        "    device = torch.device('cpu')\n",
        "  \n",
        "  X = AllVisDroneVideos(Path().absolute().joinpath('VisDrone2019-MOT-train').joinpath(\"sequences\"), Path().absolute().joinpath('VisDrone2019-MOT-train').joinpath(\"annotations\"), Utils.to_tensor())\n",
        "\n",
        "  if train_size == -1:\n",
        "    train_sz = int(len(X) * train_percentage)\n",
        "  else:\n",
        "    train_sz = train_size\n",
        "  \n",
        "  test_sz = int(len(X) * min(1,max(0, test_percentage)))\n",
        "\n",
        "  x_train, x_test, x_overflow = torch.utils.data.random_split(X, [train_sz, test_sz , len(X) - train_sz - test_sz])\n",
        "\n",
        "  random.shuffle(X.imgs)\n",
        "\n",
        "  x_train = AllVisDroneVideos(Path().absolute().joinpath('VisDrone2019-MOT-train').joinpath(\"sequences\"), Path().absolute().joinpath('VisDrone2019-MOT-train').joinpath(\"annotations\"), Utils.to_tensor(), X.imgs[:train_sz])\n",
        "  x_test = AllVisDroneVideos(Path().absolute().joinpath('VisDrone2019-MOT-train').joinpath(\"sequences\"), Path().absolute().joinpath('VisDrone2019-MOT-train').joinpath(\"annotations\"), Utils.to_tensor(), X.imgs[train_sz:train_sz + test_sz])\n",
        "\n",
        "  if test_size != -1:\n",
        "    x_test = Utils.slice(x_test, 0, test_size)\n",
        "\n",
        "  data_loader = torch.utils.data.DataLoader(\n",
        "      x_train, batch_size=batch_size, shuffle=True, num_workers=2,\n",
        "      collate_fn=utils.collate_fn)\n",
        "    \n",
        "  data_loader_test = torch.utils.data.DataLoader(\n",
        "      x_test, batch_size=1, shuffle=False, num_workers=2,\n",
        "      collate_fn=utils.collate_fn)\n",
        "    \n",
        "  if str(path_to_saved_model) == '':\n",
        "    model = build_model()\n",
        "  else:\n",
        "    model = load_model(path_to_saved_model)\n",
        "\n",
        "  model.to(device)\n",
        "\n",
        "  params = [p for p in model.parameters() if p.requires_grad]\n",
        "\n",
        "  if (optimizer == 'adam'):\n",
        "    optim = torch.optim.Adam(params, lr=lr, weight_decay=weight_decay)\n",
        "  else:\n",
        "    optim = torch.optim.SGD(params, lr=lr,\n",
        "                              momentum=momentum, weight_decay=weight_decay)\n",
        "\n",
        "  lr_scheduler = torch.optim.lr_scheduler.StepLR(optim,\n",
        "                                                    step_size=step_size,\n",
        "                                                    gamma=gamma)\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    train_one_epoch(model, optim, data_loader, device, epoch, print_freq=10)\n",
        "    print('\\n---------\\nTRAIN ONE EPOCH FINISHED')\n",
        "    lr_scheduler.step()\n",
        "    evaluate(model, data_loader_test, device=device)\n",
        "    results = get_results(evaluate(model, data_loader_test, device=device))\n",
        "    if checkpoints != -1 and epoch % checkpoints == 0:\n",
        "      save_model(model, results, arguments, path_to_saved_model)\n",
        "      print('\\nModel Saved\\n')\n",
        "  \n",
        "  return model, results, arguments\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyCvAuqO12L1"
      },
      "source": [
        "import torchvision\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from torchvision.models.detection import FasterRCNN\n",
        "from torchvision.models.detection.rpn import AnchorGenerator\n",
        "\n",
        "def build_model(num_classes = 12):\n",
        "  model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "  in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "  model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
        "\n",
        "  \"\"\"\n",
        "  backbone = torchvision.models.mobilenet_v2(pretrained=True).features\n",
        "  backbone.out_channels = 1280\n",
        "\n",
        "  anchor_generator = AnchorGenerator(sizes=((32, 64, 128, 256, 512),),\n",
        "                                    aspect_ratios=((0.5, 1.0, 2.0),))\n",
        "\n",
        "  roi_pooler = torchvision.ops.MultiScaleRoIAlign(featmap_names=['0'],\n",
        "                                                  output_size=7,\n",
        "                                                  sampling_ratio=2)\n",
        "  return FasterRCNN(backbone,\n",
        "                    num_classes=num_classes,\n",
        "                    rpn_anchor_generator=anchor_generator,\n",
        "                    box_roi_pool=roi_pooler)\n",
        "  \"\"\"\n",
        "  return model"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLmxWKCkRRan"
      },
      "source": [
        "class VisDroneVideo(object):\n",
        "    def __init__(self ,root, target_path, preprocessing = None, imgs = None):\n",
        "        self.root = str(root)\n",
        "        self.preprocessing = preprocessing\n",
        "        if (imgs != None):\n",
        "          self.imgs = imgs\n",
        "        else:\n",
        "          self.imgs = sorted(listdir(Path(root)), key=lambda x: x.lstrip(\"_\"))\n",
        "        self.target = target_path\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        img_path = Path(self.root).joinpath(self.imgs[idx])\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        video_targets = Utils.read_txt_visdrone(self.target)\n",
        "        image_targets = self.clean_targets(video_targets, idx)\n",
        "        image_targets[\"is_crowd\"] = 0\n",
        "        boxes = image_targets[[\"bbox_left\", \"bbox_top\", \"right\", \"bottom\"]]\n",
        "\n",
        "        boxes = boxes.astype('float32')\n",
        "\n",
        "        boxes = torch.as_tensor(boxes.values, dtype=torch.float32)\n",
        "        labels = torch.as_tensor(image_targets.object_category.astype('int64').values, dtype=torch.int64)\n",
        "        crowd = torch.as_tensor(image_targets.is_crowd.values, dtype=torch.int64)\n",
        "\n",
        "        image_id = torch.tensor([idx])\n",
        "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
        "\n",
        "        target = {}\n",
        "        target[\"boxes\"] = boxes\n",
        "        target[\"labels\"] = labels\n",
        "        target[\"image_id\"] = image_id\n",
        "        target[\"area\"] = area\n",
        "        target[\"iscrowd\"] = crowd\n",
        "\n",
        "        if self.preprocessing is not None:\n",
        "            img, target = self.preprocessing(img, target)\n",
        "\n",
        "        return img, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.imgs)\n",
        "\n",
        "    def clean_targets(self, targets, idx):\n",
        "\n",
        "        targets = self.targetsToDataframe(targets)\n",
        "        targets = targets[(targets.object_category != \"0\")]\n",
        "        targets = targets[(targets.frame_index == str(idx+1))]\n",
        "\n",
        "        targets.bbox_top = targets.bbox_top.astype('float32')\n",
        "        targets.bbox_height = targets.bbox_height.astype('float32')\n",
        "        targets.bbox_left = targets.bbox_left.astype('float32')\n",
        "        targets.bbox_width = targets.bbox_width.astype('float32')\n",
        "\n",
        "        targets[\"bottom\"] = targets.bbox_top + targets.bbox_height\n",
        "        targets[\"right\"] = targets.bbox_left + targets.bbox_width\n",
        "\n",
        "        return targets\n",
        "    \n",
        "    def targetsToDataframe(self, array):\n",
        "        columns = [\n",
        "          \"frame_index\",\n",
        "          \"target_id\",\n",
        "          \"bbox_left\",\n",
        "          \"bbox_top\",\n",
        "          \"bbox_width\",\n",
        "          \"bbox_height\",\n",
        "          \"score\",\n",
        "          \"object_category\",\n",
        "          \"truncation\",\n",
        "          \"oclusion\"\n",
        "        ]\n",
        "        return pd.DataFrame(data=array,columns=columns)\n",
        "\n",
        "class AllVisDroneVideos(VisDroneVideo):\n",
        "    def __init__(self,root, targets_path, preprocessing = None, imgs = None):\n",
        "      super().__init__(root, targets_path, preprocessing, imgs)\n",
        "      self.targets = sorted(listdir(Path(targets_path)), key=lambda x: x.lstrip(\"_\"))\n",
        "\n",
        "    def __len__(self):\n",
        "      return super().__len__()\n",
        "\n",
        "    def get_video_name(self, image_path):\n",
        "      return image_path.stem[:-8] + \".txt\", int(image_path.stem[-7:]) -1\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = Path(self.root).joinpath(self.imgs[idx])\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        video_name, image_idx = self.get_video_name(img_path)\n",
        "\n",
        "        video_targets = Utils.read_txt_visdrone(Path(self.target).joinpath(video_name))\n",
        "        image_targets = self.clean_targets(video_targets, image_idx)\n",
        "        image_targets[\"is_crowd\"] = 0\n",
        "        boxes = image_targets[[\"bbox_left\", \"bbox_top\", \"right\", \"bottom\"]]\n",
        "\n",
        "        boxes = boxes.astype('float32')\n",
        "\n",
        "        boxes = torch.as_tensor(boxes.values, dtype=torch.float32)\n",
        "        labels = torch.as_tensor(image_targets.object_category.astype('int64').values, dtype=torch.int64)\n",
        "        crowd = torch.as_tensor(image_targets.is_crowd.values, dtype=torch.int64)\n",
        "\n",
        "        image_id = torch.tensor([idx])\n",
        "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
        "\n",
        "        target = {}\n",
        "        target[\"boxes\"] = boxes\n",
        "        target[\"labels\"] = labels\n",
        "        target[\"image_id\"] = image_id\n",
        "        target[\"area\"] = area\n",
        "        target[\"iscrowd\"] = crowd\n",
        "\n",
        "        if self.preprocessing is not None:\n",
        "            img, target = self.preprocessing(img, target)\n",
        "\n",
        "        return img, target\n",
        "\n",
        "    def get_video_from_idx(self,idx):\n",
        "\n",
        "      video_lengths = [269, 58, 118, 501, 181, 85, 217, 97, 361, 361,\n",
        " 516, 1255, 398, 412, 213, 256, 261, 307, 348, 225, 421, 680, 341, 768, 721,\n",
        " 677, 725, 616, 548, 116, 680, 872, 962, 547, 508, 1424, 500, 210, 346, 556, \n",
        " 414, 230, 185, 403, 632, 127, 426, 369, 196, 277, 196, 691, 421, 219, 462,296]\n",
        "      \n",
        "      for i in range(len(video_lengths)):\n",
        "        if idx<video_lengths[i]:\n",
        "          return i, idx\n",
        "        else:\n",
        "          idx -= video_lengths[i]\n",
        "      return len(video_lengths), idx\n",
        "\n",
        "class VisDroneDataset(object):\n",
        "    def __init__(self, root, preprocessing = None):\n",
        "        self.root = root\n",
        "        self.preprocessing = preprocessing\n",
        "        \n",
        "        self.videos = sorted(listdir(Path(root).joinpath(\"sequences\")), key=lambda x: x.lstrip(\"_\"))\n",
        "        self.targets = sorted(listdir(Path(root).joinpath(\"annotations\")), key=lambda x: x.lstrip(\"_\"))\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "      return VisDroneVideo(Path(self.root).joinpath(\"sequences\").joinpath(self.videos[idx]),Path(self.root).joinpath(\"annotations\").joinpath(self.targets[idx]), self.preprocessing)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.videos)\n",
        "\n",
        "    '''\n",
        "        Concatenates the images of all videos into a large VisDroneVideo class\n",
        "        Allows the model to train on a broader sample of data\n",
        "    \n",
        "\n",
        "    def all_images(self):\n",
        "        large_dataset = VisDroneVideo()\n",
        "\n",
        "        for i in self:\n",
        "          for j in i[0]:\n",
        "            print(j)\n",
        "\n",
        "    '''"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3XhaZ_CZ6Z1"
      },
      "source": [
        "Utils.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfKM3TFaZ6M8"
      },
      "source": [
        "class Utils():\n",
        "\n",
        "  @staticmethod\n",
        "  def to_tensor():\n",
        "    transforms = []\n",
        "    # converts the image, a PIL image, into a PyTorch Tensor\n",
        "    transforms.append(T.ToTensor())\n",
        "    return T.Compose(transforms)\n",
        "\n",
        "  @staticmethod\n",
        "  def read_txt_visdrone(path):\n",
        "      \"\"\"\n",
        "          Input: Path of the txt file with annotations as in the VisDrone dataset\\n\n",
        "          Output: A numpy array containing the information for bounding boxes\n",
        "      \"\"\"\n",
        "      lines = []\n",
        "      with open(path) as f:\n",
        "          lines = f.readlines()\n",
        "          f.close()\n",
        "      df = []\n",
        "      for x in lines:\n",
        "          splitLine = x.split(\",\")\n",
        "          splitLine[-1] = splitLine[-1].split(\"\\n\")[0]\n",
        "          df.append(splitLine)\n",
        "      return df\n",
        "      \n",
        "  @staticmethod\n",
        "  def bottom_right(left,top,width,height):\n",
        "      \"\"\"\n",
        "          Input: co-ordinates for the top left corner of a bounding box and its width and height\\n\n",
        "          Output: co-ordinates for the bottom right corner\n",
        "      \"\"\"\n",
        "      bottom = top + height\n",
        "      right = left + width\n",
        "      return right, bottom\n",
        "\n",
        "  @staticmethod\n",
        "  def slice(array, start, stop):\n",
        "    result = []\n",
        "    for i in range(stop-start):\n",
        "      result.append(array[start + i])\n",
        "    return result"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlCt_fJY74uI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee6c02fe-0635-43de-fcd8-5deee5c6210c"
      },
      "source": [
        "eval = train('drive/MyDrive/Models/model.pth', epochs = 100, train_percentage= .8, gamma=.0001, checkpoints = 5)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: [0]  [ 0/12]  eta: 0:00:20  lr: 0.000459  loss: 1.0700 (1.0700)  loss_classifier: 0.4201 (0.4201)  loss_box_reg: 0.4610 (0.4610)  loss_objectness: 0.0799 (0.0799)  loss_rpn_box_reg: 0.1089 (0.1089)  time: 1.6951  data: 1.0363  max mem: 7250\n",
            "Epoch: [0]  [10/12]  eta: 0:00:01  lr: 0.005000  loss: 1.0700 (1.1202)  loss_classifier: 0.4383 (0.4334)  loss_box_reg: 0.5096 (0.5116)  loss_objectness: 0.0680 (0.0821)  loss_rpn_box_reg: 0.0997 (0.0932)  time: 0.6762  data: 0.1064  max mem: 7250\n",
            "Epoch: [0]  [11/12]  eta: 0:00:00  lr: 0.005000  loss: 1.0700 (1.1265)  loss_classifier: 0.4383 (0.4398)  loss_box_reg: 0.4757 (0.5069)  loss_objectness: 0.0680 (0.0848)  loss_rpn_box_reg: 0.0997 (0.0950)  time: 0.6672  data: 0.0986  max mem: 7250\n",
            "Epoch: [0] Total time: 0:00:08 (0.6732 s / it)\n",
            "\n",
            "---------\n",
            "TRAIN ONE EPOCH FINISHED\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [ 0/24]  eta: 0:00:27  model_time: 0.2324 (0.2324)  evaluator_time: 0.1004 (0.1004)  time: 1.1502  data: 0.8065  max mem: 7250\n",
            "Test:  [23/24]  eta: 0:00:00  model_time: 0.1226 (0.1283)  evaluator_time: 0.0374 (0.0533)  time: 0.1917  data: 0.0143  max mem: 7250\n",
            "Test: Total time: 0:00:05 (0.2384 s / it)\n",
            "Averaged stats: model_time: 0.1226 (0.1283)  evaluator_time: 0.0374 (0.0533)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.07s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.172\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.359\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.142\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.066\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.179\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.403\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.094\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.213\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.268\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.131\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.267\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.459\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [ 0/24]  eta: 0:00:21  model_time: 0.2109 (0.2109)  evaluator_time: 0.0910 (0.0910)  time: 0.9092  data: 0.5935  max mem: 7250\n",
            "Test:  [23/24]  eta: 0:00:00  model_time: 0.1204 (0.1271)  evaluator_time: 0.0369 (0.0660)  time: 0.1940  data: 0.0132  max mem: 7250\n",
            "Test: Total time: 0:00:05 (0.2417 s / it)\n",
            "Averaged stats: model_time: 0.1204 (0.1271)  evaluator_time: 0.0369 (0.0660)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.08s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.172\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.359\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.142\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.066\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.179\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.403\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.094\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.213\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.268\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.131\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.267\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.459\n",
            " Model Saved\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}