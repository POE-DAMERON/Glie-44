{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Glie_44.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/POE-DAMERON/Glie-44/blob/Pytorch/Model/Glie_44.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPx23mf0avpR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67045398-8f0b-4b05-adc4-c110a135b033"
      },
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "import tensorflow_hub as hub\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from os import path, listdir\n",
        "from pathlib import Path\n",
        "import cv2 as cv\n",
        "\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "!git clone https://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@github.com/POE-DAMERON/Glie-44.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Glie-44'...\n",
            "remote: Enumerating objects: 1628, done.\u001b[K\n",
            "remote: Counting objects: 100% (59/59), done.\u001b[K\n",
            "remote: Compressing objects: 100% (46/46), done.\u001b[K\n",
            "remote: Total 1628 (delta 18), reused 20 (delta 4), pack-reused 1569\u001b[K\n",
            "Receiving objects: 100% (1628/1628), 316.41 MiB | 41.59 MiB/s, done.\n",
            "Resolving deltas: 100% (36/36), done.\n",
            "Checking out files: 100% (1507/1507), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwwkaAuJavpY"
      },
      "source": [
        "class Utils():\n",
        "\n",
        "  @staticmethod\n",
        "  def add_blocks(pred, draw, height, width, font_path, precision):\n",
        "    boxes = pred['detection_boxes'].numpy()[0]\n",
        "    classes = pred['detection_classes'].numpy()[0]\n",
        "\n",
        "    boxes[:, 0] *= height\n",
        "    boxes[:, 1] *= width\n",
        "    boxes[:, 2] *= height\n",
        "    boxes[:, 3] *= width\n",
        "    \n",
        "    for i in range(len(boxes)):\n",
        "      if pred['detection_scores'].numpy()[0][i] > precision:\n",
        "        draw.rectangle(Utils.prepare_coords(boxes[i]), outline = Utils.which_color(classes[i]), width = 3)\n",
        "        draw.text((boxes[i][1], boxes[i][0]),str(classes[i])[:-2], fill=(255,255,255), stroke_fill= (0,0,0,255), stroke_width = 2, font= ImageFont.truetype(font_path, 20))\n",
        "\n",
        "  @staticmethod\n",
        "  def which_color(class_id):\n",
        "    color_value = int(class_id) * 9\n",
        "    return (min(color_value, 255), max(min(color_value - 255, 255),0),max(min(color_value - 256 * 2 - 1, 255),0))\n",
        "\n",
        "  @staticmethod\n",
        "  def prepare_coords(array):\n",
        "    return (array[1], array[0], array[3], array[2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kp7cbjDkH6X9"
      },
      "source": [
        "class Glie_44():\n",
        "\n",
        "  def __init__(self, precision = .2, font_path = Path().absolute().joinpath('Glie-44/Model/Data/fonts/Roboto-Regular.ttf')):\n",
        "    self._precision = precision\n",
        "    self._font_path = str(font_path)\n",
        "\n",
        "\n",
        "  def set_font_path(self, font_path):\n",
        "    self._font_path = font_path\n",
        "\n",
        "\n",
        "  def load_model(self):\n",
        "    self._model = hub.load(\"https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2\")\n",
        "\n",
        "  def set_model(self,model):\n",
        "    self._model = model\n",
        "\n",
        "  def get_image_data(self, image_path):\n",
        "    image_data = plt.imread(image_path)\n",
        "    return np.array(image_data)\n",
        "\n",
        "  def pred(self, image_data):\n",
        "    return self._model(image_data)\n",
        "\n",
        "  def pred_on_image_path(self, image_path):\n",
        "    image_data = np.array([self.get_image_data(image_path)])\n",
        "    return self.pred(image_data)\n",
        "  \n",
        "  def run_on_image(self, image_data):\n",
        "    pred = self.pred(np.array([image_data]))\n",
        "\n",
        "    image = Image.fromarray(image_data)\n",
        "    draw = ImageDraw.Draw(image)\n",
        "    Utils.add_blocks(pred,draw, image.size[1], image.size[0], self._font_path, self._precision)\n",
        "\n",
        "    return np.array(image)\n",
        "\n",
        "  def run_on_image_with_path(self, image_path):\n",
        "    pred = self.pred_on_image_path(image_path)\n",
        "\n",
        "    image = Image.open(image_path)\n",
        "    draw = ImageDraw.Draw(image)\n",
        "    Utils.add_blocks(pred,draw, image.size[1], image.size[0], self._font_path, self._precision)\n",
        "\n",
        "    return np.array(image)\n",
        "\n",
        "  # Takes a folder path where the images should be in chronological order to \n",
        "  # detect and compile in a video\n",
        "\n",
        "  def run_on_folder(self, folder_path = Path().absolute().joinpath('Glie-44/Model/Data/VisDrone2019-MOT-train/sequences/uav0000013_00000_v'), output_folder = Path().absolute().joinpath('Glie-44/Model/outputs'), framerate = 20):\n",
        "\n",
        "    video_frames = sorted(listdir(folder_path), key=lambda x: x.lstrip(\"_\"))\n",
        "    s = Image.open(Path(folder_path).joinpath(video_frames[0])).size\n",
        "\n",
        "    output_path = path.basename(folder_path) + '.avi'\n",
        "    fourcc = cv.VideoWriter_fourcc(*'DIVX')\n",
        "    writer = cv.VideoWriter(str(output_folder) + '/' + output_path, fourcc, framerate, s)\n",
        "\n",
        "    sample = video_frames\n",
        "    total_frames = len(sample)\n",
        "    for i in range(total_frames):\n",
        "      #print(i + 1, '/', total_frames)\n",
        "      result = self.run_on_image_with_path(Path(folder_path).joinpath(sample[i]))\n",
        "      #print(sample[i], ':', result.shape)\n",
        "      writer.write(cv.cvtColor(result,cv.COLOR_RGB2BGR))\n",
        "\n",
        "    writer.release()\n",
        "\n",
        "  # Takes a video file to detect objects\n",
        "\n",
        "  def run_on_video(self, video_path, output_folder = Path().absolute().joinpath('Glie-44/Model/outputs'), framerate = 24):\n",
        "    cap = cv.VideoCapture(video_path)\n",
        "\n",
        "    output_path = Path(video_path).stem + '_output.avi'\n",
        "\n",
        "    if (cap.isOpened()):\n",
        "      s = (int(cap.get(3)),int(cap.get(4)))\n",
        "      fourcc = cv.VideoWriter_fourcc(*'DIVX')\n",
        "      writer = cv.VideoWriter(str(output_folder) + '/' + output_path, fourcc, framerate, s)\n",
        "      ret, frame = cap.read()\n",
        "\n",
        "      while ret == True:\n",
        "        result = self.run_on_image(frame)\n",
        "          \n",
        "        writer.write(result)\n",
        "        ret, frame = cap.read()\n",
        "\n",
        "  #  takes a video stream and outputs a video stream with the boxes around the\n",
        "  #  detected objects\n",
        "\n",
        "  def run_on_stream():\n",
        "    pass\n",
        "\n",
        "  def build_video_from_directory(self, folder_path = Path().absolute().joinpath('Glie-44/Model/Data/VisDrone2019-MOT-train/sequences/uav0000013_00000_v'), output_folder = Path().absolute(), framerate = 24):\n",
        "    video_frames = sorted(listdir(folder_path), key=lambda x: x.lstrip(\"_\"))\n",
        "    s = Image.open(Path(folder_path).joinpath(video_frames[0])).size\n",
        "\n",
        "    output_path = 'Video_test.avi'\n",
        "    fourcc = cv.VideoWriter_fourcc(*'DIVX')\n",
        "    writer = cv.VideoWriter(str(output_folder) + '/' + output_path, fourcc, framerate, s)\n",
        "\n",
        "    sample = video_frames\n",
        "    total_frames = len(sample)\n",
        "    for i in range(total_frames):\n",
        "      print(i + 1, '/', total_frames)\n",
        "      result = self.get_image_data(Path(folder_path).joinpath(sample[i]))#np.array(Image.open(Path(folder_path).joinpath(sample[i])))\n",
        "      #print(sample[i], ':', result.shape)\n",
        "      writer.write(cv.cvtColor(result,cv.COLOR_RGB2BGR))\n",
        "\n",
        "    writer.release()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3dTQKkbavpZ"
      },
      "source": [
        "#model2 = hub.load(\"https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2\")\n",
        "model2 = hub.load(\"https://tfhub.dev/tensorflow/centernet/resnet101v1_fpn_512x512/1\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EtmL4UJoavpa"
      },
      "source": [
        "glie = Glie_44()\n",
        "glie.set_model(model2)\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "#    TO TEST THE RUN_ON_IMAGE\n",
        "\n",
        "pred_image = glie.run_on_image_with_path('Glie-44/Model/Data/VisDrone2019-MOT-train/sequences/uav0000013_01073_v/0000001.jpg')\n",
        "plt.figure(figsize=(24,32))\n",
        "plt.imshow(pred_image)\n",
        "\n",
        "pred = glie.pred_on_image_path('Glie-44/Model/Data/VisDrone2019-MOT-train/sequences/uav0000013_01073_v/0000001.jpg')\n",
        "pred\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "glie.run_on_video(video_path='Video_test.avi',output_folder=Path().absolute())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFCDWKdWavpa"
      },
      "source": [
        "#test = hub.KerasLayer(\"https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2\", trainable=True)\n",
        "test = hub.KerasLayer(\"https://tfhub.dev/tensorflow/centernet/resnet101v1_fpn_512x512/1\", trainable=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVCO4OB_b9fC",
        "outputId": "efb4dd22-a722-4ec6-9136-3945f3c8a436"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "x = np.array(Image.open('Glie-44/Model/Data/VisDrone2019-MOT-train/sequences/uav0000013_01073_v/0000001.jpg'))\n",
        "shape = x.shape\n",
        "x = np.array([])\n",
        "\n",
        "video_frames = sorted(listdir(folder_path), key=lambda x: x.lstrip(\"_\"))\n",
        "total_frames = len(video_frames)\n",
        "for i in range(total_frames):\n",
        "  x[i] = Image.open(Path().absolute().joinpath('Glie-44/Model/Data/VisDrone2019-MOT-train/sequences/uav0000013_00000_v').joinpath(video_frames[i]))\n",
        "\n",
        "initial_layer = tf.keras.Input(shape=shape, name=\"initial_layer\",dtype=tf.uint8)\n",
        "layer = test(initial_layer)['detection_scores']# ou ['detection_boxes']\n",
        "print(layer)\n",
        "#layer = tf.keras.layers.Flatten()(initial_layer)\n",
        "layer = tf.keras.layers.Flatten()(layer)\n",
        "layer = tf.keras.layers.Dense(100, activation='relu',)(layer)\n",
        "last_layer = tf.keras.layers.Dense(10, activation='softmax')(layer)\n",
        "\n",
        "model = tf.keras.Model(initial_layer, last_layer)\n",
        "\n",
        "\n",
        "model.compile(optimizer=\"adam\", metrics=['accuracy'], loss='categorical_crossentropy')\n",
        "model.summary()\n",
        "\n",
        "model.fit(x=x, y=np.ones((1,10)), batch_size=1, epochs = 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "KerasTensor(type_spec=TensorSpec(shape=(1, 100), dtype=tf.float32, name=None), name='keras_layer/StatefulPartitionedCall:2', description=\"created by layer 'keras_layer'\")\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "initial_layer (InputLayer)   [(None, 756, 1344, 3)]    0         \n",
            "_________________________________________________________________\n",
            "keras_layer (KerasLayer)     {'detection_boxes': (1, 1 0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (1, 100)                  0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (1, 100)                  10100     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (1, 10)                   1010      \n",
            "=================================================================\n",
            "Total params: 11,110\n",
            "Trainable params: 11,110\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "1/1 [==============================] - 10s 10s/step - loss: 23.3216 - accuracy: 0.0000e+00\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1a89490f10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wd6FAKVtYPk_"
      },
      "source": [
        "class MultipleOutputLayer():\n",
        "  def __init__(self,layer = tf.keras.Input(shape=()), output_key = ''):\n",
        "    self._layer = layer\n",
        "    self._output_key = output_key\n",
        "\n",
        "  def set_output_key(self, key):\n",
        "    self._output_key = key\n",
        "\n",
        "  def get_output_key(self):\n",
        "    return self._output_key\n",
        "  \n",
        "  def set_layer(self, layer):\n",
        "    self._layer = layer\n",
        "\n",
        "  def get_layer(self):\n",
        "    return self._layer\n",
        "\n",
        "class Architecture():\n",
        "\n",
        "  def __init__(self, initial_layer = tf.keras.Input(shape=()), output_layer = tf.keras.layers.Dense(0)):\n",
        "    self._initial_layer = initial_layer\n",
        "    self._mid_layers = []\n",
        "    self._output_layer = output_layer\n",
        "\n",
        "  def set_initial_layer(self, layer):\n",
        "    self._initial_layer = layer\n",
        "\n",
        "  def get_initial_layer(self):\n",
        "    return self._initial_layer\n",
        "\n",
        "  def set_output_layer(self, layer):\n",
        "    self._output_layer = layer\n",
        "\n",
        "  def get_output_layer(self):\n",
        "    return self._output_layer\n",
        "\n",
        "  def get_mid_layers(self):\n",
        "    return self._mid_layers\n",
        "  \n",
        "  def __getitem__(self, layer_number):\n",
        "    return self._mid_layers[layer_number]\n",
        "  \n",
        "  def __setitem__(self, layer_number, data):\n",
        "    self._mid_layers[layer_number] = data\n",
        "  \n",
        "  def compile(self):\n",
        "    try :\n",
        "      mid_layer = self._initial_layer\n",
        "      for layer in self._mid_layers:\n",
        "        if type(layer) == MultipleOutputLayer:\n",
        "          mid_layer = layer.get_layer()(mid_layer)[layer.get_output_key()]\n",
        "        else:\n",
        "          mid_layer = layer(mid_layer)\n",
        "      return (self._initial_layer, self._output_layer(mid_layer))\n",
        "    except Exception as e:\n",
        "      print(f'Sorry. Something went wrong:\\n{e}')\n",
        "      pass\n",
        "\n",
        "\n",
        "class Model(tf.keras.Model):\n",
        "  def __init__(self, compiled_arc):\n",
        "    super().__init__(compiled_arc[0], compiled_arc[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecNkSvaP41QM",
        "outputId": "5cea128e-9981-4ca5-89ac-29ceff812be7"
      },
      "source": [
        "x = np.array(Image.open('Glie-44/Model/Data/VisDrone2019-MOT-train/sequences/uav0000013_01073_v/0000001.jpg'))\n",
        "shape = x.shape\n",
        "\n",
        "arc = Architecture()\n",
        "arc.set_initial_layer(tf.keras.Input(shape=shape, name=\"initial_layer\",dtype=tf.uint8))\n",
        "arc.get_mid_layers().append(MultipleOutputLayer(test, 'detection_scores'))\n",
        "arc.get_mid_layers().append(tf.keras.layers.Flatten())\n",
        "arc.set_output_layer(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "res = arc.compile()\n",
        "res"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<KerasTensor: shape=(None, 756, 1344, 3) dtype=uint8 (created by layer 'initial_layer')>,\n",
              " <KerasTensor: shape=(1, 10) dtype=float32 (created by layer 'dense_11')>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDUCwkZR5OWD",
        "outputId": "f33a5260-b044-4d60-d163-cbdfbe31f4e8"
      },
      "source": [
        "model_test = Model(res)\n",
        "model_test.summary()\n",
        "model_test.compile(optimizer=\"adam\", metrics=['accuracy'], loss='categorical_crossentropy')\n",
        "model_test.predict(np.array([x]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "initial_layer (InputLayer)   [(None, 756, 1344, 3)]    0         \n",
            "_________________________________________________________________\n",
            "keras_layer (KerasLayer)     {'detection_boxes': (1, 1 0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (1, 100)                  0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (1, 10)                   1010      \n",
            "=================================================================\n",
            "Total params: 1,010\n",
            "Trainable params: 1,010\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.09631571, 0.03675139, 0.13114575, 0.13017394, 0.09900831,\n",
              "        0.10070857, 0.17002572, 0.06272071, 0.08706453, 0.08608536]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDWgZe8DQZS4"
      },
      "source": [
        "**New Model using Pytorch**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23EcvQ0gWTmO"
      },
      "source": [
        "Main.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Saxy2LvOmdbn",
        "outputId": "064e171a-5545-4bc3-8e9d-08070358448f"
      },
      "source": [
        "%%shell\n",
        "\n",
        "git clone https://github.com/pytorch/vision.git\n",
        "cd vision\n",
        "git checkout v0.3.0\n",
        "\n",
        "cp references/detection/utils.py ../\n",
        "cp references/detection/transforms.py ../\n",
        "cp references/detection/coco_eval.py ../\n",
        "cp references/detection/engine.py ../\n",
        "cp references/detection/coco_utils.py ../"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'vision'...\n",
            "remote: Enumerating objects: 21990, done.\u001b[K\n",
            "remote: Counting objects: 100% (2771/2771), done.\u001b[K\n",
            "remote: Compressing objects: 100% (635/635), done.\u001b[K\n",
            "remote: Total 21990 (delta 2163), reused 2620 (delta 2068), pack-reused 19219\u001b[K\n",
            "Receiving objects: 100% (21990/21990), 22.12 MiB | 25.00 MiB/s, done.\n",
            "Resolving deltas: 100% (16222/16222), done.\n",
            "Note: checking out 'v0.3.0'.\n",
            "\n",
            "You are in 'detached HEAD' state. You can look around, make experimental\n",
            "changes and commit them, and you can discard any commits you make in this\n",
            "state without impacting any branches by performing another checkout.\n",
            "\n",
            "If you want to create a new branch to retain commits you create, you may\n",
            "do so (now or later) by using -b with the checkout command again. Example:\n",
            "\n",
            "  git checkout -b <new-branch-name>\n",
            "\n",
            "HEAD is now at be376084 version check against PyTorch's CUDA version\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKOtVOkjWSps"
      },
      "source": [
        "import torch\n",
        "from engine import train_one_epoch, evaluate\n",
        "import utils\n",
        "import os\n",
        "import pandas as pd\n",
        "import transforms as T\n",
        "from pathlib import Path\n",
        "\n",
        "def main(train_percentage = .8, num_classes = 12):\n",
        "  if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "  else:\n",
        "    device = torch.device('cpu')\n",
        "  \n",
        "  x = VisDroneDataset(Path().absolute().joinpath('Glie-44/Model/Data/VisDrone2019-MOT-train'), Utils.to_tensor())\n",
        "  X = x[0]\n",
        "\n",
        "  train_size = int(len(X) * train_percentage)\n",
        "\n",
        "  x_train, x_test = torch.utils.data.random_split(X, [train_size, len(X) - train_size])\n",
        "\n",
        "  data_loader = torch.utils.data.DataLoader(\n",
        "        x_train, batch_size=2, shuffle=True, num_workers=2,\n",
        "        collate_fn=utils.collate_fn)\n",
        "  \n",
        "  data_loader_test = torch.utils.data.DataLoader(\n",
        "    x_test, batch_size=1, shuffle=False, num_workers=2,\n",
        "    collate_fn=utils.collate_fn)\n",
        "  \n",
        "  model = build_model(num_classes)\n",
        "\n",
        "  model.to(device)\n",
        "\n",
        "  params = [p for p in model.parameters() if p.requires_grad]\n",
        "  optimizer = torch.optim.SGD(params, lr=0.005,\n",
        "                            momentum=0.9, weight_decay=0.0005)#torch.optim.Adam(model.parameters())\n",
        "  lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n",
        "                                                   step_size=3,\n",
        "                                                   gamma=0.1)\n",
        "  epochs = 10\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "        print('Training epoch : ', epoch)\n",
        "        train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq=10)\n",
        "        print('step')\n",
        "        lr_scheduler.step()\n",
        "        print('evaluating')\n",
        "        evaluate(model, data_loader_test, device=device)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyCvAuqO12L1"
      },
      "source": [
        "import torchvision\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from torchvision.models.detection import FasterRCNN\n",
        "from torchvision.models.detection.rpn import AnchorGenerator\n",
        "\n",
        "def build_model(num_classes = 12):\n",
        "  model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "  in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "  model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
        "\n",
        "  backbone = torchvision.models.mobilenet_v2(pretrained=True).features\n",
        "  backbone.out_channels = 1280\n",
        "\n",
        "  anchor_generator = AnchorGenerator(sizes=((32, 64, 128, 256, 512),),\n",
        "                                    aspect_ratios=((0.5, 1.0, 2.0),))\n",
        "\n",
        "  roi_pooler = torchvision.ops.MultiScaleRoIAlign(featmap_names=['0'],\n",
        "                                                  output_size=7,\n",
        "                                                  sampling_ratio=2)\n",
        "\n",
        "  return FasterRCNN(backbone,\n",
        "                    num_classes=num_classes,\n",
        "                    rpn_anchor_generator=anchor_generator,\n",
        "                    box_roi_pool=roi_pooler)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLmxWKCkRRan"
      },
      "source": [
        "class VisDroneVideo(object):\n",
        "    def __init__(self ,root, target_path, preprocessing = None):\n",
        "        self.root = str(root)\n",
        "        self.preprocessing = preprocessing\n",
        "        \n",
        "        self.imgs = sorted(listdir(Path(root)), key=lambda x: x.lstrip(\"_\"))\n",
        "        self.target = target_path\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = Path(self.root).joinpath(self.imgs[idx])\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        video_targets = Utils.read_txt_visdrone(self.target)\n",
        "        image_targets = self.clean_targets(video_targets, idx)\n",
        "        image_targets[\"is_crowd\"] = 0\n",
        "        boxes = image_targets[[\"bbox_left\", \"bbox_top\", \"right\", \"bottom\"]]\n",
        "\n",
        "        boxes = boxes.astype('float32')\n",
        "\n",
        "        boxes = torch.as_tensor(boxes.values, dtype=torch.float32)\n",
        "        labels = torch.as_tensor(image_targets.object_category.astype('int64').values, dtype=torch.int64)\n",
        "        crowd = torch.as_tensor(image_targets.is_crowd.values, dtype=torch.int64)\n",
        "\n",
        "        image_id = torch.tensor([idx])\n",
        "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
        "\n",
        "        target = {}\n",
        "        target[\"boxes\"] = boxes\n",
        "        target[\"labels\"] = labels\n",
        "        target[\"image_id\"] = image_id\n",
        "        target[\"area\"] = area\n",
        "        target[\"iscrowd\"] = crowd\n",
        "\n",
        "        if self.preprocessing is not None:\n",
        "            img, target = self.preprocessing(img, target)\n",
        "\n",
        "        return img, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.imgs)\n",
        "\n",
        "    def clean_targets(self, targets, idx):\n",
        "\n",
        "        targets = self.targetsToDataframe(targets)\n",
        "        targets = targets[(targets.object_category != \"0\")]\n",
        "        targets = targets[(targets.frame_index == str(idx+1))]\n",
        "\n",
        "        targets.bbox_top = targets.bbox_top.astype('float32')\n",
        "        targets.bbox_height = targets.bbox_height.astype('float32')\n",
        "        targets.bbox_left = targets.bbox_left.astype('float32')\n",
        "        targets.bbox_width = targets.bbox_width.astype('float32')\n",
        "\n",
        "        targets[\"bottom\"] = targets.bbox_top + targets.bbox_height\n",
        "        targets[\"right\"] = targets.bbox_left + targets.bbox_width\n",
        "\n",
        "        return targets\n",
        "    \n",
        "    def targetsToDataframe(self, array):\n",
        "        columns = [\n",
        "          \"frame_index\",\n",
        "          \"target_id\",\n",
        "          \"bbox_left\",\n",
        "          \"bbox_top\",\n",
        "          \"bbox_width\",\n",
        "          \"bbox_height\",\n",
        "          \"score\",\n",
        "          \"object_category\",\n",
        "          \"truncation\",\n",
        "          \"oclusion\"\n",
        "        ]\n",
        "        return pd.DataFrame(data=array,columns=columns)\n",
        "\n",
        "class VisDroneDataset(object):\n",
        "    def __init__(self, root, preprocessing = None):\n",
        "        self.root = root\n",
        "        self.preprocessing = preprocessing\n",
        "        \n",
        "        self.videos = sorted(listdir(Path(root).joinpath(\"sequences\")), key=lambda x: x.lstrip(\"_\"))\n",
        "        self.targets = sorted(listdir(Path(root).joinpath(\"annotations\")), key=lambda x: x.lstrip(\"_\"))\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "      return VisDroneVideo(Path(self.root).joinpath(\"sequences\").joinpath(self.videos[idx]),Path(self.root).joinpath(\"annotations\").joinpath(self.targets[idx]), self.preprocessing)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.videos)\n",
        "\n",
        "    '''\n",
        "        Concatenates the images of all videos into a large VisDroneVideo class\n",
        "        Allows the model to train on a broader sample of data\n",
        "    \n",
        "\n",
        "    def all_images(self):\n",
        "        large_dataset = VisDroneVideo()\n",
        "\n",
        "        for i in self:\n",
        "          for j in i[0]:\n",
        "            print(j)\n",
        "\n",
        "    '''"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3XhaZ_CZ6Z1"
      },
      "source": [
        "Utils.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfKM3TFaZ6M8"
      },
      "source": [
        "class Utils():\n",
        "\n",
        "  @staticmethod\n",
        "  def to_tensor():\n",
        "    transforms = []\n",
        "    # converts the image, a PIL image, into a PyTorch Tensor\n",
        "    transforms.append(T.ToTensor())\n",
        "    return T.Compose(transforms)\n",
        "\n",
        "  @staticmethod\n",
        "  def read_txt_visdrone(path):\n",
        "      \"\"\"\n",
        "          Input: Path of the txt file with annotations as in the VisDrone dataset\\n\n",
        "          Output: A numpy array containing the information for bounding boxes\n",
        "      \"\"\"\n",
        "      lines = []\n",
        "      with open(path) as f:\n",
        "          lines = f.readlines()\n",
        "          f.close()\n",
        "      df = []\n",
        "      for x in lines:\n",
        "          splitLine = x.split(\",\")\n",
        "          splitLine[-1] = splitLine[-1].split(\"\\n\")[0]\n",
        "          df.append(splitLine)\n",
        "      return df\n",
        "      \n",
        "  @staticmethod\n",
        "  def bottom_right(left,top,width,height):\n",
        "      \"\"\"\n",
        "          Input: co-ordinates for the top left corner of a bounding box and its width and height\\n\n",
        "          Output: co-ordinates for the bottom right corner\n",
        "      \"\"\"\n",
        "      bottom = top + height\n",
        "      right = left + width\n",
        "      return right, bottom"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zn4oKgG2g3nu",
        "outputId": "6ef7f0ef-0f28-40a4-b5e2-caaba130f940",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "main()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(tensor([[[0.6353, 0.6353, 0.6353,  ..., 0.1843, 0.1765, 0.1882],\n",
            "         [0.6353, 0.6353, 0.6353,  ..., 0.1725, 0.1686, 0.1843],\n",
            "         [0.6353, 0.6353, 0.6353,  ..., 0.1569, 0.1608, 0.1765],\n",
            "         ...,\n",
            "         [0.1569, 0.1608, 0.1608,  ..., 0.1020, 0.0980, 0.0941],\n",
            "         [0.1569, 0.1608, 0.1608,  ..., 0.0980, 0.0941, 0.0902],\n",
            "         [0.1569, 0.1608, 0.1608,  ..., 0.0941, 0.0902, 0.0824]],\n",
            "\n",
            "        [[0.6863, 0.6863, 0.6863,  ..., 0.2863, 0.2784, 0.2902],\n",
            "         [0.6863, 0.6863, 0.6863,  ..., 0.2745, 0.2706, 0.2863],\n",
            "         [0.6863, 0.6863, 0.6863,  ..., 0.2588, 0.2627, 0.2784],\n",
            "         ...,\n",
            "         [0.2000, 0.2039, 0.2039,  ..., 0.1373, 0.1333, 0.1294],\n",
            "         [0.2000, 0.2039, 0.2039,  ..., 0.1333, 0.1294, 0.1255],\n",
            "         [0.2000, 0.2039, 0.2039,  ..., 0.1294, 0.1255, 0.1176]],\n",
            "\n",
            "        [[0.7216, 0.7216, 0.7216,  ..., 0.1020, 0.0941, 0.1059],\n",
            "         [0.7216, 0.7216, 0.7216,  ..., 0.0902, 0.0863, 0.1020],\n",
            "         [0.7216, 0.7216, 0.7216,  ..., 0.0745, 0.0784, 0.0941],\n",
            "         ...,\n",
            "         [0.0824, 0.0863, 0.0863,  ..., 0.0549, 0.0588, 0.0549],\n",
            "         [0.0824, 0.0863, 0.0863,  ..., 0.0510, 0.0549, 0.0510],\n",
            "         [0.0824, 0.0863, 0.0863,  ..., 0.0471, 0.0510, 0.0431]]]), {'boxes': tensor([[ 147.,  700.,  207.,  755.],\n",
            "        [ 154.,  675.,  204.,  755.],\n",
            "        [ 312.,  459.,  340.,  523.],\n",
            "        [1103.,  657., 1240.,  755.],\n",
            "        [ 293.,  435.,  316.,  519.],\n",
            "        [ 334.,  446.,  357.,  507.],\n",
            "        [1009.,  548., 1071.,  690.],\n",
            "        [ 964.,  503., 1011.,  610.],\n",
            "        [ 974.,  468., 1022.,  551.],\n",
            "        [ 363.,  369.,  382.,  413.],\n",
            "        [ 428.,  426.,  472.,  481.],\n",
            "        [ 599.,  285.,  625.,  349.],\n",
            "        [ 427.,  402.,  461.,  436.],\n",
            "        [ 435.,  392.,  463.,  426.],\n",
            "        [ 442.,  380.,  476.,  419.],\n",
            "        [ 612.,  278.,  635.,  336.],\n",
            "        [ 521.,  353.,  556.,  425.],\n",
            "        [ 581.,  493.,  628.,  586.],\n",
            "        [ 580.,  457.,  642.,  560.],\n",
            "        [ 535.,  456.,  568.,  564.],\n",
            "        [ 542.,  470.,  564.,  515.],\n",
            "        [ 534.,  253.,  554.,  307.],\n",
            "        [ 549.,  683.,  609.,  754.],\n",
            "        [ 557.,  695.,  589.,  736.],\n",
            "        [ 551.,  666.,  606.,  750.],\n",
            "        [ 734.,  475.,  769.,  555.],\n",
            "        [ 733.,  433.,  771.,  527.],\n",
            "        [ 526.,  291.,  552.,  355.],\n",
            "        [ 736.,  255.,  775.,  337.],\n",
            "        [ 553.,  162.,  568.,  196.],\n",
            "        [ 485.,  314.,  513.,  373.],\n",
            "        [ 456.,  341.,  482.,  383.],\n",
            "        [ 467.,  325.,  487.,  373.],\n",
            "        [ 385.,  382.,  415.,  435.]]), 'labels': tensor([ 1,  1,  1, 10,  1,  1, 10, 10, 10,  1,  2,  1,  2,  2,  2,  1, 10, 10,\n",
            "         2,  1,  2,  1, 10,  2,  2,  3,  2,  1,  8,  1,  1,  1,  1,  1]), 'image_id': tensor([175]), 'area': tensor([ 3300.,  4000.,  1792., 13426.,  1932.,  1403.,  8804.,  5029.,  3984.,\n",
            "          836.,  2420.,  1664.,  1156.,   952.,  1326.,  1334.,  2520.,  4371.,\n",
            "         6386.,  3564.,   990.,  1080.,  4260.,  1312.,  4620.,  2800.,  3572.,\n",
            "         1664.,  3198.,   510.,  1652.,  1092.,   960.,  1590.]), 'iscrowd': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0])})\n",
            "Training epoch :  0\n",
            "Epoch: [0]  [  0/108]  eta: 0:02:01  lr: 0.000052  loss: 3.3123 (3.3123)  loss_classifier: 2.3825 (2.3825)  loss_box_reg: 0.0604 (0.0604)  loss_objectness: 0.6924 (0.6924)  loss_rpn_box_reg: 0.1770 (0.1770)  time: 1.1270  data: 0.6152  max mem: 6091\n",
            "Epoch: [0]  [ 10/108]  eta: 0:00:47  lr: 0.000519  loss: 2.8932 (2.7025)  loss_classifier: 2.0175 (1.8082)  loss_box_reg: 0.0547 (0.0588)  loss_objectness: 0.6917 (0.6875)  loss_rpn_box_reg: 0.1601 (0.1479)  time: 0.4823  data: 0.0648  max mem: 6721\n",
            "Epoch: [0]  [ 20/108]  eta: 0:00:40  lr: 0.000985  loss: 1.5832 (2.0944)  loss_classifier: 0.7502 (1.2619)  loss_box_reg: 0.0608 (0.0739)  loss_objectness: 0.6481 (0.6337)  loss_rpn_box_reg: 0.1109 (0.1249)  time: 0.4220  data: 0.0097  max mem: 6721\n",
            "Epoch: [0]  [ 30/108]  eta: 0:00:34  lr: 0.001452  loss: 1.1895 (1.7470)  loss_classifier: 0.5168 (0.9913)  loss_box_reg: 0.1140 (0.0899)  loss_objectness: 0.4770 (0.5557)  loss_rpn_box_reg: 0.0865 (0.1100)  time: 0.4270  data: 0.0095  max mem: 6721\n",
            "Epoch: [0]  [ 40/108]  eta: 0:00:30  lr: 0.001919  loss: 0.9713 (1.5558)  loss_classifier: 0.4266 (0.8561)  loss_box_reg: 0.1536 (0.1146)  loss_objectness: 0.3065 (0.4838)  loss_rpn_box_reg: 0.0786 (0.1013)  time: 0.4276  data: 0.0095  max mem: 6721\n",
            "Epoch: [0]  [ 50/108]  eta: 0:00:25  lr: 0.002386  loss: 0.9005 (1.4252)  loss_classifier: 0.4126 (0.7700)  loss_box_reg: 0.2030 (0.1366)  loss_objectness: 0.2133 (0.4264)  loss_rpn_box_reg: 0.0631 (0.0922)  time: 0.4295  data: 0.0097  max mem: 6721\n",
            "Epoch: [0]  [ 60/108]  eta: 0:00:21  lr: 0.002853  loss: 0.8577 (1.3424)  loss_classifier: 0.4097 (0.7134)  loss_box_reg: 0.2429 (0.1557)  loss_objectness: 0.1852 (0.3864)  loss_rpn_box_reg: 0.0560 (0.0870)  time: 0.4322  data: 0.0101  max mem: 6721\n",
            "Epoch: [0]  [ 70/108]  eta: 0:00:16  lr: 0.003319  loss: 0.9084 (1.2789)  loss_classifier: 0.4086 (0.6706)  loss_box_reg: 0.2536 (0.1725)  loss_objectness: 0.1692 (0.3534)  loss_rpn_box_reg: 0.0542 (0.0824)  time: 0.4341  data: 0.0097  max mem: 6721\n",
            "Epoch: [0]  [ 80/108]  eta: 0:00:12  lr: 0.003786  loss: 0.8611 (1.2281)  loss_classifier: 0.3981 (0.6367)  loss_box_reg: 0.2839 (0.1857)  loss_objectness: 0.1408 (0.3269)  loss_rpn_box_reg: 0.0502 (0.0789)  time: 0.4372  data: 0.0092  max mem: 6721\n",
            "Epoch: [0]  [ 90/108]  eta: 0:00:07  lr: 0.004253  loss: 0.8950 (1.1958)  loss_classifier: 0.3938 (0.6116)  loss_box_reg: 0.3072 (0.2048)  loss_objectness: 0.1277 (0.3038)  loss_rpn_box_reg: 0.0502 (0.0756)  time: 0.4385  data: 0.0096  max mem: 6721\n",
            "Epoch: [0]  [100/108]  eta: 0:00:03  lr: 0.004720  loss: 0.9696 (1.1737)  loss_classifier: 0.4045 (0.5911)  loss_box_reg: 0.4022 (0.2271)  loss_objectness: 0.1032 (0.2829)  loss_rpn_box_reg: 0.0477 (0.0727)  time: 0.4352  data: 0.0097  max mem: 6721\n",
            "Epoch: [0]  [107/108]  eta: 0:00:00  lr: 0.005000  loss: 0.9766 (1.1602)  loss_classifier: 0.4025 (0.5766)  loss_box_reg: 0.4417 (0.2433)  loss_objectness: 0.0896 (0.2699)  loss_rpn_box_reg: 0.0420 (0.0704)  time: 0.4234  data: 0.0094  max mem: 6721\n",
            "Epoch: [0] Total time: 0:00:47 (0.4361 s / it)\n",
            "step\n",
            "evaluating\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [ 0/54]  eta: 0:00:22  model_time: 0.1137 (0.1137)  evaluator_time: 0.0343 (0.0343)  time: 0.4228  data: 0.2705  max mem: 6721\n",
            "Test:  [53/54]  eta: 0:00:00  model_time: 0.0635 (0.0641)  evaluator_time: 0.0410 (0.0451)  time: 0.1242  data: 0.0082  max mem: 6721\n",
            "Test: Total time: 0:00:06 (0.1251 s / it)\n",
            "Averaged stats: model_time: 0.0635 (0.0641)  evaluator_time: 0.0410 (0.0451)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.08s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.015\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.057\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.003\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.020\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.014\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.016\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.011\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.037\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.071\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.060\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.072\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.024\n",
            "Training epoch :  1\n",
            "Epoch: [1]  [  0/108]  eta: 0:01:27  lr: 0.005000  loss: 0.8774 (0.8774)  loss_classifier: 0.3155 (0.3155)  loss_box_reg: 0.4333 (0.4333)  loss_objectness: 0.0873 (0.0873)  loss_rpn_box_reg: 0.0414 (0.0414)  time: 0.8085  data: 0.3678  max mem: 6721\n",
            "Epoch: [1]  [ 10/108]  eta: 0:00:44  lr: 0.005000  loss: 0.9564 (0.9914)  loss_classifier: 0.3571 (0.3634)  loss_box_reg: 0.4869 (0.5040)  loss_objectness: 0.0871 (0.0813)  loss_rpn_box_reg: 0.0414 (0.0426)  time: 0.4499  data: 0.0415  max mem: 6721\n",
            "Epoch: [1]  [ 20/108]  eta: 0:00:38  lr: 0.005000  loss: 0.9584 (0.9701)  loss_classifier: 0.3528 (0.3432)  loss_box_reg: 0.4880 (0.5131)  loss_objectness: 0.0742 (0.0745)  loss_rpn_box_reg: 0.0391 (0.0394)  time: 0.4160  data: 0.0091  max mem: 6721\n",
            "Epoch: [1]  [ 30/108]  eta: 0:00:33  lr: 0.005000  loss: 0.9481 (0.9526)  loss_classifier: 0.3111 (0.3307)  loss_box_reg: 0.5236 (0.5105)  loss_objectness: 0.0659 (0.0734)  loss_rpn_box_reg: 0.0345 (0.0380)  time: 0.4204  data: 0.0094  max mem: 6721\n",
            "Epoch: [1]  [ 40/108]  eta: 0:00:29  lr: 0.005000  loss: 0.8902 (0.9470)  loss_classifier: 0.2946 (0.3229)  loss_box_reg: 0.5232 (0.5161)  loss_objectness: 0.0647 (0.0702)  loss_rpn_box_reg: 0.0343 (0.0377)  time: 0.4249  data: 0.0099  max mem: 6721\n",
            "Epoch: [1]  [ 50/108]  eta: 0:00:24  lr: 0.005000  loss: 0.8902 (0.9456)  loss_classifier: 0.2942 (0.3190)  loss_box_reg: 0.5232 (0.5206)  loss_objectness: 0.0616 (0.0683)  loss_rpn_box_reg: 0.0363 (0.0378)  time: 0.4292  data: 0.0100  max mem: 6721\n",
            "Epoch: [1]  [ 60/108]  eta: 0:00:20  lr: 0.005000  loss: 0.8477 (0.9256)  loss_classifier: 0.2578 (0.3067)  loss_box_reg: 0.4997 (0.5163)  loss_objectness: 0.0531 (0.0657)  loss_rpn_box_reg: 0.0341 (0.0368)  time: 0.4322  data: 0.0096  max mem: 6721\n",
            "Epoch: [1]  [ 70/108]  eta: 0:00:16  lr: 0.005000  loss: 0.8038 (0.9167)  loss_classifier: 0.2342 (0.3000)  loss_box_reg: 0.4837 (0.5160)  loss_objectness: 0.0506 (0.0637)  loss_rpn_box_reg: 0.0342 (0.0370)  time: 0.4331  data: 0.0094  max mem: 6721\n",
            "Epoch: [1]  [ 80/108]  eta: 0:00:12  lr: 0.005000  loss: 0.8775 (0.9189)  loss_classifier: 0.2608 (0.2970)  loss_box_reg: 0.5162 (0.5224)  loss_objectness: 0.0517 (0.0627)  loss_rpn_box_reg: 0.0365 (0.0369)  time: 0.4349  data: 0.0099  max mem: 6721\n",
            "Epoch: [1]  [ 90/108]  eta: 0:00:07  lr: 0.005000  loss: 0.8822 (0.9112)  loss_classifier: 0.2477 (0.2897)  loss_box_reg: 0.5466 (0.5240)  loss_objectness: 0.0487 (0.0610)  loss_rpn_box_reg: 0.0343 (0.0366)  time: 0.4366  data: 0.0099  max mem: 6721\n",
            "Epoch: [1]  [100/108]  eta: 0:00:03  lr: 0.005000  loss: 0.8691 (0.9079)  loss_classifier: 0.2417 (0.2856)  loss_box_reg: 0.5431 (0.5264)  loss_objectness: 0.0465 (0.0597)  loss_rpn_box_reg: 0.0330 (0.0361)  time: 0.4348  data: 0.0095  max mem: 6721\n",
            "Epoch: [1]  [107/108]  eta: 0:00:00  lr: 0.005000  loss: 0.8228 (0.9019)  loss_classifier: 0.2417 (0.2823)  loss_box_reg: 0.5139 (0.5249)  loss_objectness: 0.0465 (0.0587)  loss_rpn_box_reg: 0.0325 (0.0360)  time: 0.4233  data: 0.0091  max mem: 6721\n",
            "Epoch: [1] Total time: 0:00:46 (0.4310 s / it)\n",
            "step\n",
            "evaluating\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py:5170: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self[name] = value\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:53: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  from ipykernel import kernelapp as app\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "creating index...\n",
            "index created!\n",
            "Test:  [ 0/54]  eta: 0:00:36  model_time: 0.1034 (0.1034)  evaluator_time: 0.0464 (0.0464)  time: 0.6687  data: 0.5144  max mem: 6721\n",
            "Test:  [53/54]  eta: 0:00:00  model_time: 0.0585 (0.0624)  evaluator_time: 0.0357 (0.0403)  time: 0.1053  data: 0.0053  max mem: 6721\n",
            "Test: Total time: 0:00:06 (0.1221 s / it)\n",
            "Averaged stats: model_time: 0.0585 (0.0624)  evaluator_time: 0.0357 (0.0403)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.08s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.163\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.377\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.094\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.040\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.159\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.332\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.121\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.213\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.264\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.180\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.260\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.424\n",
            "Training epoch :  2\n",
            "Epoch: [2]  [  0/108]  eta: 0:01:26  lr: 0.005000  loss: 0.6988 (0.6988)  loss_classifier: 0.1741 (0.1741)  loss_box_reg: 0.4710 (0.4710)  loss_objectness: 0.0325 (0.0325)  loss_rpn_box_reg: 0.0212 (0.0212)  time: 0.8049  data: 0.3687  max mem: 6721\n",
            "Epoch: [2]  [ 10/108]  eta: 0:00:44  lr: 0.005000  loss: 0.8301 (0.8200)  loss_classifier: 0.2251 (0.2329)  loss_box_reg: 0.5101 (0.5167)  loss_objectness: 0.0375 (0.0422)  loss_rpn_box_reg: 0.0306 (0.0283)  time: 0.4512  data: 0.0413  max mem: 6721\n",
            "Epoch: [2]  [ 20/108]  eta: 0:00:38  lr: 0.005000  loss: 0.7985 (0.8031)  loss_classifier: 0.2186 (0.2199)  loss_box_reg: 0.5153 (0.5129)  loss_objectness: 0.0375 (0.0420)  loss_rpn_box_reg: 0.0282 (0.0283)  time: 0.4181  data: 0.0090  max mem: 6721\n",
            "Epoch: [2]  [ 30/108]  eta: 0:00:33  lr: 0.005000  loss: 0.7703 (0.8000)  loss_classifier: 0.2095 (0.2197)  loss_box_reg: 0.5145 (0.5108)  loss_objectness: 0.0354 (0.0413)  loss_rpn_box_reg: 0.0277 (0.0283)  time: 0.4226  data: 0.0099  max mem: 6721\n",
            "Epoch: [2]  [ 40/108]  eta: 0:00:29  lr: 0.005000  loss: 0.7917 (0.8078)  loss_classifier: 0.2095 (0.2199)  loss_box_reg: 0.5145 (0.5182)  loss_objectness: 0.0386 (0.0412)  loss_rpn_box_reg: 0.0285 (0.0286)  time: 0.4262  data: 0.0103  max mem: 6721\n",
            "Epoch: [2]  [ 50/108]  eta: 0:00:25  lr: 0.005000  loss: 0.8216 (0.8035)  loss_classifier: 0.2139 (0.2189)  loss_box_reg: 0.5368 (0.5156)  loss_objectness: 0.0384 (0.0406)  loss_rpn_box_reg: 0.0322 (0.0285)  time: 0.4290  data: 0.0097  max mem: 6721\n",
            "Epoch: [2]  [ 60/108]  eta: 0:00:20  lr: 0.005000  loss: 0.7619 (0.7961)  loss_classifier: 0.1999 (0.2162)  loss_box_reg: 0.4833 (0.5125)  loss_objectness: 0.0355 (0.0395)  loss_rpn_box_reg: 0.0256 (0.0279)  time: 0.4309  data: 0.0092  max mem: 6721\n",
            "Epoch: [2]  [ 70/108]  eta: 0:00:16  lr: 0.005000  loss: 0.7793 (0.7941)  loss_classifier: 0.1999 (0.2143)  loss_box_reg: 0.4986 (0.5125)  loss_objectness: 0.0364 (0.0393)  loss_rpn_box_reg: 0.0265 (0.0280)  time: 0.4340  data: 0.0093  max mem: 6721\n",
            "Epoch: [2]  [ 80/108]  eta: 0:00:12  lr: 0.005000  loss: 0.7061 (0.7823)  loss_classifier: 0.1731 (0.2089)  loss_box_reg: 0.4896 (0.5080)  loss_objectness: 0.0310 (0.0380)  loss_rpn_box_reg: 0.0256 (0.0274)  time: 0.4366  data: 0.0095  max mem: 6721\n",
            "Epoch: [2]  [ 90/108]  eta: 0:00:07  lr: 0.005000  loss: 0.6977 (0.7729)  loss_classifier: 0.1697 (0.2040)  loss_box_reg: 0.4759 (0.5049)  loss_objectness: 0.0291 (0.0370)  loss_rpn_box_reg: 0.0216 (0.0270)  time: 0.4355  data: 0.0097  max mem: 6721\n",
            "Epoch: [2]  [100/108]  eta: 0:00:03  lr: 0.005000  loss: 0.7705 (0.7780)  loss_classifier: 0.1914 (0.2052)  loss_box_reg: 0.5186 (0.5083)  loss_objectness: 0.0331 (0.0369)  loss_rpn_box_reg: 0.0279 (0.0275)  time: 0.4334  data: 0.0096  max mem: 6721\n",
            "Epoch: [2]  [107/108]  eta: 0:00:00  lr: 0.005000  loss: 0.7694 (0.7756)  loss_classifier: 0.1926 (0.2041)  loss_box_reg: 0.5041 (0.5072)  loss_objectness: 0.0331 (0.0367)  loss_rpn_box_reg: 0.0288 (0.0276)  time: 0.4226  data: 0.0095  max mem: 6721\n",
            "Epoch: [2] Total time: 0:00:46 (0.4315 s / it)\n",
            "step\n",
            "evaluating\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [ 0/54]  eta: 0:00:21  model_time: 0.1109 (0.1109)  evaluator_time: 0.0531 (0.0531)  time: 0.4001  data: 0.2304  max mem: 6721\n",
            "Test:  [53/54]  eta: 0:00:00  model_time: 0.0581 (0.0610)  evaluator_time: 0.0345 (0.0383)  time: 0.1028  data: 0.0055  max mem: 6721\n",
            "Test: Total time: 0:00:06 (0.1166 s / it)\n",
            "Averaged stats: model_time: 0.0581 (0.0610)  evaluator_time: 0.0345 (0.0383)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.09s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.291\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.688\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.183\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.216\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.301\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.518\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.249\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.395\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.443\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.307\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.462\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.548\n",
            "Training epoch :  3\n",
            "Epoch: [3]  [  0/108]  eta: 0:01:27  lr: 0.000500  loss: 0.9120 (0.9120)  loss_classifier: 0.2679 (0.2679)  loss_box_reg: 0.5778 (0.5778)  loss_objectness: 0.0381 (0.0381)  loss_rpn_box_reg: 0.0281 (0.0281)  time: 0.8137  data: 0.3676  max mem: 6721\n",
            "Epoch: [3]  [ 10/108]  eta: 0:00:44  lr: 0.000500  loss: 0.7674 (0.7539)  loss_classifier: 0.1869 (0.2011)  loss_box_reg: 0.5155 (0.4972)  loss_objectness: 0.0312 (0.0332)  loss_rpn_box_reg: 0.0224 (0.0225)  time: 0.4517  data: 0.0411  max mem: 6721\n",
            "Epoch: [3]  [ 20/108]  eta: 0:00:38  lr: 0.000500  loss: 0.6530 (0.7080)  loss_classifier: 0.1652 (0.1836)  loss_box_reg: 0.4473 (0.4707)  loss_objectness: 0.0306 (0.0337)  loss_rpn_box_reg: 0.0194 (0.0200)  time: 0.4180  data: 0.0093  max mem: 6721\n",
            "Epoch: [3]  [ 30/108]  eta: 0:00:33  lr: 0.000500  loss: 0.6397 (0.6984)  loss_classifier: 0.1613 (0.1786)  loss_box_reg: 0.4439 (0.4666)  loss_objectness: 0.0340 (0.0333)  loss_rpn_box_reg: 0.0175 (0.0199)  time: 0.4217  data: 0.0100  max mem: 6721\n",
            "Epoch: [3]  [ 40/108]  eta: 0:00:29  lr: 0.000500  loss: 0.6030 (0.6762)  loss_classifier: 0.1607 (0.1715)  loss_box_reg: 0.4056 (0.4536)  loss_objectness: 0.0297 (0.0319)  loss_rpn_box_reg: 0.0159 (0.0191)  time: 0.4252  data: 0.0096  max mem: 6721\n",
            "Epoch: [3]  [ 50/108]  eta: 0:00:24  lr: 0.000500  loss: 0.6019 (0.6661)  loss_classifier: 0.1569 (0.1698)  loss_box_reg: 0.4083 (0.4462)  loss_objectness: 0.0265 (0.0313)  loss_rpn_box_reg: 0.0158 (0.0189)  time: 0.4285  data: 0.0098  max mem: 6721\n",
            "Epoch: [3]  [ 60/108]  eta: 0:00:20  lr: 0.000500  loss: 0.6200 (0.6542)  loss_classifier: 0.1484 (0.1664)  loss_box_reg: 0.4147 (0.4389)  loss_objectness: 0.0269 (0.0308)  loss_rpn_box_reg: 0.0162 (0.0181)  time: 0.4309  data: 0.0100  max mem: 6721\n",
            "Epoch: [3]  [ 70/108]  eta: 0:00:16  lr: 0.000500  loss: 0.6160 (0.6498)  loss_classifier: 0.1482 (0.1641)  loss_box_reg: 0.4145 (0.4376)  loss_objectness: 0.0273 (0.0303)  loss_rpn_box_reg: 0.0150 (0.0178)  time: 0.4335  data: 0.0096  max mem: 6721\n",
            "Epoch: [3]  [ 80/108]  eta: 0:00:12  lr: 0.000500  loss: 0.5879 (0.6434)  loss_classifier: 0.1424 (0.1609)  loss_box_reg: 0.4114 (0.4354)  loss_objectness: 0.0253 (0.0297)  loss_rpn_box_reg: 0.0142 (0.0173)  time: 0.4361  data: 0.0095  max mem: 6721\n",
            "Epoch: [3]  [ 90/108]  eta: 0:00:07  lr: 0.000500  loss: 0.5724 (0.6380)  loss_classifier: 0.1294 (0.1587)  loss_box_reg: 0.4091 (0.4320)  loss_objectness: 0.0277 (0.0302)  loss_rpn_box_reg: 0.0133 (0.0170)  time: 0.4368  data: 0.0096  max mem: 6721\n",
            "Epoch: [3]  [100/108]  eta: 0:00:03  lr: 0.000500  loss: 0.6029 (0.6348)  loss_classifier: 0.1321 (0.1578)  loss_box_reg: 0.4065 (0.4304)  loss_objectness: 0.0296 (0.0297)  loss_rpn_box_reg: 0.0157 (0.0169)  time: 0.4340  data: 0.0097  max mem: 6721\n",
            "Epoch: [3]  [107/108]  eta: 0:00:00  lr: 0.000500  loss: 0.6253 (0.6348)  loss_classifier: 0.1533 (0.1575)  loss_box_reg: 0.4454 (0.4304)  loss_objectness: 0.0296 (0.0301)  loss_rpn_box_reg: 0.0163 (0.0168)  time: 0.4222  data: 0.0092  max mem: 6721\n",
            "Epoch: [3] Total time: 0:00:46 (0.4315 s / it)\n",
            "step\n",
            "evaluating\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [ 0/54]  eta: 0:00:21  model_time: 0.1212 (0.1212)  evaluator_time: 0.0377 (0.0377)  time: 0.3979  data: 0.2300  max mem: 6721\n",
            "Test:  [53/54]  eta: 0:00:00  model_time: 0.0581 (0.0610)  evaluator_time: 0.0370 (0.0402)  time: 0.1047  data: 0.0058  max mem: 6721\n",
            "Test: Total time: 0:00:06 (0.1181 s / it)\n",
            "Averaged stats: model_time: 0.0581 (0.0610)  evaluator_time: 0.0370 (0.0402)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.09s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.399\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.790\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.359\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.239\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.392\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.665\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.312\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.480\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.528\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.392\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.525\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.691\n",
            "Training epoch :  4\n",
            "Epoch: [4]  [  0/108]  eta: 0:01:23  lr: 0.000500  loss: 0.6457 (0.6457)  loss_classifier: 0.1586 (0.1586)  loss_box_reg: 0.4444 (0.4444)  loss_objectness: 0.0269 (0.0269)  loss_rpn_box_reg: 0.0158 (0.0158)  time: 0.7729  data: 0.3428  max mem: 6721\n",
            "Epoch: [4]  [ 10/108]  eta: 0:00:44  lr: 0.000500  loss: 0.6010 (0.6147)  loss_classifier: 0.1556 (0.1531)  loss_box_reg: 0.4123 (0.4181)  loss_objectness: 0.0281 (0.0280)  loss_rpn_box_reg: 0.0156 (0.0156)  time: 0.4523  data: 0.0428  max mem: 6721\n",
            "Epoch: [4]  [ 20/108]  eta: 0:00:38  lr: 0.000500  loss: 0.5993 (0.6100)  loss_classifier: 0.1553 (0.1526)  loss_box_reg: 0.4075 (0.4132)  loss_objectness: 0.0292 (0.0294)  loss_rpn_box_reg: 0.0144 (0.0148)  time: 0.4194  data: 0.0111  max mem: 6721\n",
            "Epoch: [4]  [ 30/108]  eta: 0:00:33  lr: 0.000500  loss: 0.5776 (0.6026)  loss_classifier: 0.1392 (0.1487)  loss_box_reg: 0.4059 (0.4106)  loss_objectness: 0.0292 (0.0288)  loss_rpn_box_reg: 0.0140 (0.0145)  time: 0.4212  data: 0.0094  max mem: 6721\n",
            "Epoch: [4]  [ 40/108]  eta: 0:00:29  lr: 0.000500  loss: 0.5943 (0.5995)  loss_classifier: 0.1384 (0.1474)  loss_box_reg: 0.4140 (0.4096)  loss_objectness: 0.0257 (0.0280)  loss_rpn_box_reg: 0.0146 (0.0145)  time: 0.4258  data: 0.0095  max mem: 6721\n",
            "Epoch: [4]  [ 50/108]  eta: 0:00:25  lr: 0.000500  loss: 0.5920 (0.5916)  loss_classifier: 0.1363 (0.1436)  loss_box_reg: 0.4137 (0.4059)  loss_objectness: 0.0249 (0.0278)  loss_rpn_box_reg: 0.0154 (0.0143)  time: 0.4295  data: 0.0096  max mem: 6721\n",
            "Epoch: [4]  [ 60/108]  eta: 0:00:20  lr: 0.000500  loss: 0.5920 (0.5912)  loss_classifier: 0.1363 (0.1443)  loss_box_reg: 0.4137 (0.4045)  loss_objectness: 0.0266 (0.0281)  loss_rpn_box_reg: 0.0152 (0.0144)  time: 0.4298  data: 0.0095  max mem: 6721\n",
            "Epoch: [4]  [ 70/108]  eta: 0:00:16  lr: 0.000500  loss: 0.6222 (0.5921)  loss_classifier: 0.1510 (0.1443)  loss_box_reg: 0.4177 (0.4051)  loss_objectness: 0.0297 (0.0283)  loss_rpn_box_reg: 0.0146 (0.0144)  time: 0.4328  data: 0.0096  max mem: 6721\n",
            "Epoch: [4]  [ 80/108]  eta: 0:00:12  lr: 0.000500  loss: 0.5762 (0.5907)  loss_classifier: 0.1414 (0.1440)  loss_box_reg: 0.4111 (0.4044)  loss_objectness: 0.0276 (0.0281)  loss_rpn_box_reg: 0.0135 (0.0143)  time: 0.4378  data: 0.0099  max mem: 6721\n",
            "Epoch: [4]  [ 90/108]  eta: 0:00:07  lr: 0.000500  loss: 0.5215 (0.5845)  loss_classifier: 0.1261 (0.1419)  loss_box_reg: 0.3694 (0.4007)  loss_objectness: 0.0265 (0.0278)  loss_rpn_box_reg: 0.0117 (0.0141)  time: 0.4372  data: 0.0101  max mem: 6721\n",
            "Epoch: [4]  [100/108]  eta: 0:00:03  lr: 0.000500  loss: 0.5659 (0.5852)  loss_classifier: 0.1375 (0.1417)  loss_box_reg: 0.3801 (0.4014)  loss_objectness: 0.0250 (0.0279)  loss_rpn_box_reg: 0.0136 (0.0142)  time: 0.4345  data: 0.0102  max mem: 6721\n",
            "Epoch: [4]  [107/108]  eta: 0:00:00  lr: 0.000500  loss: 0.5947 (0.5870)  loss_classifier: 0.1399 (0.1423)  loss_box_reg: 0.4152 (0.4023)  loss_objectness: 0.0265 (0.0280)  loss_rpn_box_reg: 0.0150 (0.0144)  time: 0.4230  data: 0.0096  max mem: 6721\n",
            "Epoch: [4] Total time: 0:00:46 (0.4316 s / it)\n",
            "step\n",
            "evaluating\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [ 0/54]  eta: 0:00:22  model_time: 0.1097 (0.1097)  evaluator_time: 0.0428 (0.0428)  time: 0.4092  data: 0.2490  max mem: 6721\n",
            "Test:  [53/54]  eta: 0:00:00  model_time: 0.0585 (0.0617)  evaluator_time: 0.0360 (0.0415)  time: 0.1044  data: 0.0049  max mem: 6721\n",
            "Test: Total time: 0:00:06 (0.1192 s / it)\n",
            "Averaged stats: model_time: 0.0585 (0.0617)  evaluator_time: 0.0360 (0.0415)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.08s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.424\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.797\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.399\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.251\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.428\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.674\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.324\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.508\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.552\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.375\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.561\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.699\n",
            "Training epoch :  5\n",
            "Epoch: [5]  [  0/108]  eta: 0:01:26  lr: 0.000500  loss: 0.6568 (0.6568)  loss_classifier: 0.1596 (0.1596)  loss_box_reg: 0.4463 (0.4463)  loss_objectness: 0.0347 (0.0347)  loss_rpn_box_reg: 0.0162 (0.0162)  time: 0.7964  data: 0.3660  max mem: 6721\n",
            "Epoch: [5]  [ 10/108]  eta: 0:00:44  lr: 0.000500  loss: 0.5509 (0.5474)  loss_classifier: 0.1328 (0.1333)  loss_box_reg: 0.3702 (0.3775)  loss_objectness: 0.0225 (0.0238)  loss_rpn_box_reg: 0.0121 (0.0129)  time: 0.4525  data: 0.0421  max mem: 6721\n",
            "Epoch: [5]  [ 20/108]  eta: 0:00:38  lr: 0.000500  loss: 0.5545 (0.5857)  loss_classifier: 0.1346 (0.1412)  loss_box_reg: 0.3772 (0.4049)  loss_objectness: 0.0225 (0.0255)  loss_rpn_box_reg: 0.0121 (0.0141)  time: 0.4184  data: 0.0096  max mem: 6721\n",
            "Epoch: [5]  [ 30/108]  eta: 0:00:33  lr: 0.000500  loss: 0.5373 (0.5691)  loss_classifier: 0.1354 (0.1378)  loss_box_reg: 0.3710 (0.3938)  loss_objectness: 0.0242 (0.0242)  loss_rpn_box_reg: 0.0123 (0.0133)  time: 0.4210  data: 0.0093  max mem: 6721\n",
            "Epoch: [5]  [ 40/108]  eta: 0:00:29  lr: 0.000500  loss: 0.5250 (0.5709)  loss_classifier: 0.1284 (0.1360)  loss_box_reg: 0.3598 (0.3965)  loss_objectness: 0.0253 (0.0249)  loss_rpn_box_reg: 0.0123 (0.0134)  time: 0.4253  data: 0.0093  max mem: 6721\n",
            "Epoch: [5]  [ 50/108]  eta: 0:00:24  lr: 0.000500  loss: 0.5528 (0.5670)  loss_classifier: 0.1236 (0.1344)  loss_box_reg: 0.3796 (0.3932)  loss_objectness: 0.0301 (0.0261)  loss_rpn_box_reg: 0.0126 (0.0133)  time: 0.4288  data: 0.0097  max mem: 6721\n",
            "Epoch: [5]  [ 60/108]  eta: 0:00:20  lr: 0.000500  loss: 0.5372 (0.5679)  loss_classifier: 0.1244 (0.1345)  loss_box_reg: 0.3792 (0.3935)  loss_objectness: 0.0301 (0.0266)  loss_rpn_box_reg: 0.0126 (0.0133)  time: 0.4305  data: 0.0098  max mem: 6721\n",
            "Epoch: [5]  [ 70/108]  eta: 0:00:16  lr: 0.000500  loss: 0.5414 (0.5666)  loss_classifier: 0.1349 (0.1345)  loss_box_reg: 0.3809 (0.3923)  loss_objectness: 0.0251 (0.0264)  loss_rpn_box_reg: 0.0131 (0.0133)  time: 0.4334  data: 0.0099  max mem: 6721\n",
            "Epoch: [5]  [ 80/108]  eta: 0:00:12  lr: 0.000500  loss: 0.5513 (0.5679)  loss_classifier: 0.1393 (0.1355)  loss_box_reg: 0.3841 (0.3931)  loss_objectness: 0.0221 (0.0261)  loss_rpn_box_reg: 0.0131 (0.0133)  time: 0.4378  data: 0.0104  max mem: 6721\n",
            "Epoch: [5]  [ 90/108]  eta: 0:00:07  lr: 0.000500  loss: 0.5707 (0.5742)  loss_classifier: 0.1449 (0.1380)  loss_box_reg: 0.3942 (0.3965)  loss_objectness: 0.0256 (0.0263)  loss_rpn_box_reg: 0.0124 (0.0135)  time: 0.4390  data: 0.0109  max mem: 6721\n",
            "Epoch: [5]  [100/108]  eta: 0:00:03  lr: 0.000500  loss: 0.5707 (0.5733)  loss_classifier: 0.1434 (0.1376)  loss_box_reg: 0.3932 (0.3959)  loss_objectness: 0.0258 (0.0263)  loss_rpn_box_reg: 0.0130 (0.0135)  time: 0.4363  data: 0.0111  max mem: 6721\n",
            "Epoch: [5]  [107/108]  eta: 0:00:00  lr: 0.000500  loss: 0.5514 (0.5714)  loss_classifier: 0.1285 (0.1367)  loss_box_reg: 0.3876 (0.3950)  loss_objectness: 0.0261 (0.0264)  loss_rpn_box_reg: 0.0124 (0.0134)  time: 0.4235  data: 0.0101  max mem: 6721\n",
            "Epoch: [5] Total time: 0:00:46 (0.4319 s / it)\n",
            "step\n",
            "evaluating\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [ 0/54]  eta: 0:00:22  model_time: 0.1148 (0.1148)  evaluator_time: 0.0285 (0.0285)  time: 0.4142  data: 0.2666  max mem: 6721\n",
            "Test:  [53/54]  eta: 0:00:00  model_time: 0.0593 (0.0616)  evaluator_time: 0.0357 (0.0385)  time: 0.1052  data: 0.0067  max mem: 6721\n",
            "Test: Total time: 0:00:06 (0.1188 s / it)\n",
            "Averaged stats: model_time: 0.0593 (0.0616)  evaluator_time: 0.0357 (0.0385)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.09s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.441\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.793\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.419\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.260\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.436\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.761\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.338\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.531\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.572\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.399\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.578\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.775\n",
            "Training epoch :  6\n",
            "Epoch: [6]  [  0/108]  eta: 0:01:27  lr: 0.000050  loss: 0.5975 (0.5975)  loss_classifier: 0.1394 (0.1394)  loss_box_reg: 0.4072 (0.4072)  loss_objectness: 0.0336 (0.0336)  loss_rpn_box_reg: 0.0174 (0.0174)  time: 0.8071  data: 0.3772  max mem: 6721\n",
            "Epoch: [6]  [ 10/108]  eta: 0:00:44  lr: 0.000050  loss: 0.5304 (0.5481)  loss_classifier: 0.1279 (0.1298)  loss_box_reg: 0.3723 (0.3810)  loss_objectness: 0.0269 (0.0254)  loss_rpn_box_reg: 0.0129 (0.0120)  time: 0.4498  data: 0.0429  max mem: 6721\n",
            "Epoch: [6]  [ 20/108]  eta: 0:00:38  lr: 0.000050  loss: 0.5368 (0.5737)  loss_classifier: 0.1398 (0.1407)  loss_box_reg: 0.3723 (0.3937)  loss_objectness: 0.0269 (0.0268)  loss_rpn_box_reg: 0.0109 (0.0125)  time: 0.4175  data: 0.0094  max mem: 6721\n",
            "Epoch: [6]  [ 30/108]  eta: 0:00:33  lr: 0.000050  loss: 0.5779 (0.5698)  loss_classifier: 0.1407 (0.1378)  loss_box_reg: 0.3844 (0.3926)  loss_objectness: 0.0283 (0.0268)  loss_rpn_box_reg: 0.0111 (0.0127)  time: 0.4212  data: 0.0092  max mem: 6721\n",
            "Epoch: [6]  [ 40/108]  eta: 0:00:29  lr: 0.000050  loss: 0.5241 (0.5587)  loss_classifier: 0.1291 (0.1338)  loss_box_reg: 0.3745 (0.3859)  loss_objectness: 0.0271 (0.0265)  loss_rpn_box_reg: 0.0117 (0.0125)  time: 0.4243  data: 0.0092  max mem: 6721\n",
            "Epoch: [6]  [ 50/108]  eta: 0:00:24  lr: 0.000050  loss: 0.5204 (0.5503)  loss_classifier: 0.1193 (0.1301)  loss_box_reg: 0.3522 (0.3810)  loss_objectness: 0.0267 (0.0270)  loss_rpn_box_reg: 0.0111 (0.0122)  time: 0.4280  data: 0.0094  max mem: 6721\n",
            "Epoch: [6]  [ 60/108]  eta: 0:00:20  lr: 0.000050  loss: 0.5228 (0.5518)  loss_classifier: 0.1193 (0.1298)  loss_box_reg: 0.3577 (0.3823)  loss_objectness: 0.0295 (0.0273)  loss_rpn_box_reg: 0.0111 (0.0124)  time: 0.4306  data: 0.0095  max mem: 6721\n",
            "Epoch: [6]  [ 70/108]  eta: 0:00:16  lr: 0.000050  loss: 0.5723 (0.5543)  loss_classifier: 0.1297 (0.1306)  loss_box_reg: 0.3839 (0.3839)  loss_objectness: 0.0277 (0.0273)  loss_rpn_box_reg: 0.0119 (0.0124)  time: 0.4325  data: 0.0095  max mem: 6721\n",
            "Epoch: [6]  [ 80/108]  eta: 0:00:12  lr: 0.000050  loss: 0.5603 (0.5525)  loss_classifier: 0.1297 (0.1302)  loss_box_reg: 0.3835 (0.3829)  loss_objectness: 0.0234 (0.0270)  loss_rpn_box_reg: 0.0119 (0.0124)  time: 0.4346  data: 0.0096  max mem: 6721\n",
            "Epoch: [6]  [ 90/108]  eta: 0:00:07  lr: 0.000050  loss: 0.5440 (0.5539)  loss_classifier: 0.1273 (0.1310)  loss_box_reg: 0.3785 (0.3834)  loss_objectness: 0.0232 (0.0270)  loss_rpn_box_reg: 0.0127 (0.0125)  time: 0.4361  data: 0.0095  max mem: 6721\n",
            "Epoch: [6]  [100/108]  eta: 0:00:03  lr: 0.000050  loss: 0.5503 (0.5516)  loss_classifier: 0.1273 (0.1301)  loss_box_reg: 0.3785 (0.3823)  loss_objectness: 0.0240 (0.0268)  loss_rpn_box_reg: 0.0126 (0.0124)  time: 0.4354  data: 0.0104  max mem: 6721\n",
            "Epoch: [6]  [107/108]  eta: 0:00:00  lr: 0.000050  loss: 0.5141 (0.5472)  loss_classifier: 0.1118 (0.1288)  loss_box_reg: 0.3629 (0.3798)  loss_objectness: 0.0223 (0.0263)  loss_rpn_box_reg: 0.0114 (0.0122)  time: 0.4230  data: 0.0102  max mem: 6721\n",
            "Epoch: [6] Total time: 0:00:46 (0.4308 s / it)\n",
            "step\n",
            "evaluating\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [ 0/54]  eta: 0:00:22  model_time: 0.1226 (0.1226)  evaluator_time: 0.0259 (0.0259)  time: 0.4155  data: 0.2624  max mem: 6721\n",
            "Test:  [53/54]  eta: 0:00:00  model_time: 0.0604 (0.0608)  evaluator_time: 0.0369 (0.0408)  time: 0.1069  data: 0.0055  max mem: 6721\n",
            "Test: Total time: 0:00:06 (0.1184 s / it)\n",
            "Averaged stats: model_time: 0.0604 (0.0608)  evaluator_time: 0.0369 (0.0408)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.09s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.455\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.794\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.436\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.289\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.448\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.787\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.346\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.531\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.573\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.441\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.571\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.799\n",
            "Training epoch :  7\n",
            "Epoch: [7]  [  0/108]  eta: 0:01:25  lr: 0.000050  loss: 0.5821 (0.5821)  loss_classifier: 0.1340 (0.1340)  loss_box_reg: 0.4096 (0.4096)  loss_objectness: 0.0257 (0.0257)  loss_rpn_box_reg: 0.0129 (0.0129)  time: 0.7951  data: 0.3630  max mem: 6721\n",
            "Epoch: [7]  [ 10/108]  eta: 0:00:44  lr: 0.000050  loss: 0.5339 (0.5375)  loss_classifier: 0.1340 (0.1331)  loss_box_reg: 0.3641 (0.3674)  loss_objectness: 0.0257 (0.0246)  loss_rpn_box_reg: 0.0126 (0.0123)  time: 0.4513  data: 0.0427  max mem: 6721\n",
            "Epoch: [7]  [ 20/108]  eta: 0:00:38  lr: 0.000050  loss: 0.5363 (0.5454)  loss_classifier: 0.1319 (0.1314)  loss_box_reg: 0.3734 (0.3771)  loss_objectness: 0.0222 (0.0248)  loss_rpn_box_reg: 0.0115 (0.0120)  time: 0.4179  data: 0.0100  max mem: 6721\n",
            "Epoch: [7]  [ 30/108]  eta: 0:00:33  lr: 0.000050  loss: 0.5405 (0.5543)  loss_classifier: 0.1316 (0.1333)  loss_box_reg: 0.3827 (0.3837)  loss_objectness: 0.0235 (0.0248)  loss_rpn_box_reg: 0.0124 (0.0124)  time: 0.4215  data: 0.0092  max mem: 6721\n",
            "Epoch: [7]  [ 40/108]  eta: 0:00:29  lr: 0.000050  loss: 0.5676 (0.5602)  loss_classifier: 0.1343 (0.1336)  loss_box_reg: 0.3909 (0.3877)  loss_objectness: 0.0258 (0.0263)  loss_rpn_box_reg: 0.0127 (0.0127)  time: 0.4260  data: 0.0094  max mem: 6721\n",
            "Epoch: [7]  [ 50/108]  eta: 0:00:24  lr: 0.000050  loss: 0.5929 (0.5586)  loss_classifier: 0.1307 (0.1324)  loss_box_reg: 0.4019 (0.3869)  loss_objectness: 0.0273 (0.0267)  loss_rpn_box_reg: 0.0125 (0.0125)  time: 0.4285  data: 0.0096  max mem: 6721\n",
            "Epoch: [7]  [ 60/108]  eta: 0:00:20  lr: 0.000050  loss: 0.5234 (0.5481)  loss_classifier: 0.1257 (0.1299)  loss_box_reg: 0.3627 (0.3798)  loss_objectness: 0.0247 (0.0261)  loss_rpn_box_reg: 0.0118 (0.0123)  time: 0.4308  data: 0.0095  max mem: 6721\n",
            "Epoch: [7]  [ 70/108]  eta: 0:00:16  lr: 0.000050  loss: 0.5043 (0.5452)  loss_classifier: 0.1171 (0.1295)  loss_box_reg: 0.3461 (0.3771)  loss_objectness: 0.0251 (0.0264)  loss_rpn_box_reg: 0.0104 (0.0122)  time: 0.4342  data: 0.0098  max mem: 6721\n",
            "Epoch: [7]  [ 80/108]  eta: 0:00:12  lr: 0.000050  loss: 0.5117 (0.5448)  loss_classifier: 0.1223 (0.1293)  loss_box_reg: 0.3588 (0.3766)  loss_objectness: 0.0289 (0.0267)  loss_rpn_box_reg: 0.0111 (0.0122)  time: 0.4354  data: 0.0096  max mem: 6721\n",
            "Epoch: [7]  [ 90/108]  eta: 0:00:07  lr: 0.000050  loss: 0.5255 (0.5466)  loss_classifier: 0.1225 (0.1301)  loss_box_reg: 0.3789 (0.3781)  loss_objectness: 0.0230 (0.0262)  loss_rpn_box_reg: 0.0115 (0.0122)  time: 0.4343  data: 0.0093  max mem: 6721\n",
            "Epoch: [7]  [100/108]  eta: 0:00:03  lr: 0.000050  loss: 0.5305 (0.5470)  loss_classifier: 0.1259 (0.1305)  loss_box_reg: 0.3789 (0.3785)  loss_objectness: 0.0215 (0.0258)  loss_rpn_box_reg: 0.0126 (0.0122)  time: 0.4323  data: 0.0094  max mem: 6721\n",
            "Epoch: [7]  [107/108]  eta: 0:00:00  lr: 0.000050  loss: 0.5305 (0.5477)  loss_classifier: 0.1244 (0.1309)  loss_box_reg: 0.3719 (0.3788)  loss_objectness: 0.0244 (0.0259)  loss_rpn_box_reg: 0.0126 (0.0122)  time: 0.4201  data: 0.0091  max mem: 6721\n",
            "Epoch: [7] Total time: 0:00:46 (0.4306 s / it)\n",
            "step\n",
            "evaluating\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [ 0/54]  eta: 0:00:21  model_time: 0.1107 (0.1107)  evaluator_time: 0.0341 (0.0341)  time: 0.4025  data: 0.2533  max mem: 6721\n",
            "Test:  [53/54]  eta: 0:00:00  model_time: 0.0581 (0.0610)  evaluator_time: 0.0369 (0.0398)  time: 0.1032  data: 0.0051  max mem: 6721\n",
            "Test: Total time: 0:00:06 (0.1174 s / it)\n",
            "Averaged stats: model_time: 0.0581 (0.0610)  evaluator_time: 0.0369 (0.0398)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.08s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.437\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.804\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.396\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.295\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.438\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.729\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.336\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.519\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.562\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.442\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.566\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.739\n",
            "Training epoch :  8\n",
            "Epoch: [8]  [  0/108]  eta: 0:01:22  lr: 0.000050  loss: 0.5137 (0.5137)  loss_classifier: 0.1141 (0.1141)  loss_box_reg: 0.3713 (0.3713)  loss_objectness: 0.0171 (0.0171)  loss_rpn_box_reg: 0.0112 (0.0112)  time: 0.7672  data: 0.3550  max mem: 6721\n",
            "Epoch: [8]  [ 10/108]  eta: 0:00:44  lr: 0.000050  loss: 0.5302 (0.5076)  loss_classifier: 0.1163 (0.1195)  loss_box_reg: 0.3702 (0.3556)  loss_objectness: 0.0225 (0.0224)  loss_rpn_box_reg: 0.0098 (0.0101)  time: 0.4511  data: 0.0423  max mem: 6721\n",
            "Epoch: [8]  [ 20/108]  eta: 0:00:38  lr: 0.000050  loss: 0.5482 (0.5393)  loss_classifier: 0.1311 (0.1284)  loss_box_reg: 0.3744 (0.3763)  loss_objectness: 0.0245 (0.0233)  loss_rpn_box_reg: 0.0116 (0.0114)  time: 0.4204  data: 0.0105  max mem: 6721\n",
            "Epoch: [8]  [ 30/108]  eta: 0:00:33  lr: 0.000050  loss: 0.5539 (0.5521)  loss_classifier: 0.1327 (0.1327)  loss_box_reg: 0.3821 (0.3819)  loss_objectness: 0.0271 (0.0255)  loss_rpn_box_reg: 0.0123 (0.0119)  time: 0.4229  data: 0.0096  max mem: 6721\n",
            "Epoch: [8]  [ 40/108]  eta: 0:00:29  lr: 0.000050  loss: 0.5322 (0.5403)  loss_classifier: 0.1207 (0.1293)  loss_box_reg: 0.3637 (0.3735)  loss_objectness: 0.0294 (0.0256)  loss_rpn_box_reg: 0.0121 (0.0118)  time: 0.4259  data: 0.0096  max mem: 6721\n",
            "Epoch: [8]  [ 50/108]  eta: 0:00:24  lr: 0.000050  loss: 0.5325 (0.5417)  loss_classifier: 0.1192 (0.1295)  loss_box_reg: 0.3637 (0.3735)  loss_objectness: 0.0296 (0.0269)  loss_rpn_box_reg: 0.0118 (0.0118)  time: 0.4271  data: 0.0095  max mem: 6721\n",
            "Epoch: [8]  [ 60/108]  eta: 0:00:20  lr: 0.000050  loss: 0.5690 (0.5398)  loss_classifier: 0.1346 (0.1287)  loss_box_reg: 0.3792 (0.3727)  loss_objectness: 0.0286 (0.0266)  loss_rpn_box_reg: 0.0114 (0.0119)  time: 0.4317  data: 0.0097  max mem: 6721\n",
            "Epoch: [8]  [ 70/108]  eta: 0:00:16  lr: 0.000050  loss: 0.5311 (0.5407)  loss_classifier: 0.1421 (0.1290)  loss_box_reg: 0.3614 (0.3735)  loss_objectness: 0.0207 (0.0261)  loss_rpn_box_reg: 0.0111 (0.0120)  time: 0.4349  data: 0.0097  max mem: 6721\n",
            "Epoch: [8]  [ 80/108]  eta: 0:00:12  lr: 0.000050  loss: 0.5231 (0.5378)  loss_classifier: 0.1236 (0.1286)  loss_box_reg: 0.3605 (0.3713)  loss_objectness: 0.0228 (0.0261)  loss_rpn_box_reg: 0.0109 (0.0118)  time: 0.4353  data: 0.0097  max mem: 6721\n",
            "Epoch: [8]  [ 90/108]  eta: 0:00:07  lr: 0.000050  loss: 0.5031 (0.5350)  loss_classifier: 0.1154 (0.1271)  loss_box_reg: 0.3547 (0.3697)  loss_objectness: 0.0248 (0.0265)  loss_rpn_box_reg: 0.0097 (0.0117)  time: 0.4359  data: 0.0098  max mem: 6721\n",
            "Epoch: [8]  [100/108]  eta: 0:00:03  lr: 0.000050  loss: 0.5445 (0.5421)  loss_classifier: 0.1306 (0.1287)  loss_box_reg: 0.3863 (0.3747)  loss_objectness: 0.0264 (0.0266)  loss_rpn_box_reg: 0.0125 (0.0121)  time: 0.4322  data: 0.0097  max mem: 6721\n",
            "Epoch: [8]  [107/108]  eta: 0:00:00  lr: 0.000050  loss: 0.5743 (0.5424)  loss_classifier: 0.1322 (0.1282)  loss_box_reg: 0.4121 (0.3755)  loss_objectness: 0.0240 (0.0265)  loss_rpn_box_reg: 0.0126 (0.0121)  time: 0.4212  data: 0.0092  max mem: 6721\n",
            "Epoch: [8] Total time: 0:00:46 (0.4311 s / it)\n",
            "step\n",
            "evaluating\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [ 0/54]  eta: 0:00:21  model_time: 0.1162 (0.1162)  evaluator_time: 0.0309 (0.0309)  time: 0.4044  data: 0.2527  max mem: 6721\n",
            "Test:  [53/54]  eta: 0:00:00  model_time: 0.0602 (0.0623)  evaluator_time: 0.0359 (0.0390)  time: 0.1048  data: 0.0058  max mem: 6721\n",
            "Test: Total time: 0:00:06 (0.1173 s / it)\n",
            "Averaged stats: model_time: 0.0602 (0.0623)  evaluator_time: 0.0359 (0.0390)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.09s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.444\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.804\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.406\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.270\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.438\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.765\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.338\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.524\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.568\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.421\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.572\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.781\n",
            "Training epoch :  9\n",
            "Epoch: [9]  [  0/108]  eta: 0:01:25  lr: 0.000005  loss: 0.4666 (0.4666)  loss_classifier: 0.1059 (0.1059)  loss_box_reg: 0.3256 (0.3256)  loss_objectness: 0.0231 (0.0231)  loss_rpn_box_reg: 0.0120 (0.0120)  time: 0.7919  data: 0.3874  max mem: 6721\n",
            "Epoch: [9]  [ 10/108]  eta: 0:00:44  lr: 0.000005  loss: 0.5171 (0.5206)  loss_classifier: 0.1180 (0.1219)  loss_box_reg: 0.3649 (0.3655)  loss_objectness: 0.0231 (0.0223)  loss_rpn_box_reg: 0.0110 (0.0110)  time: 0.4536  data: 0.0452  max mem: 6721\n",
            "Epoch: [9]  [ 20/108]  eta: 0:00:38  lr: 0.000005  loss: 0.5138 (0.5318)  loss_classifier: 0.1180 (0.1240)  loss_box_reg: 0.3639 (0.3710)  loss_objectness: 0.0235 (0.0250)  loss_rpn_box_reg: 0.0110 (0.0118)  time: 0.4181  data: 0.0103  max mem: 6721\n",
            "Epoch: [9]  [ 30/108]  eta: 0:00:33  lr: 0.000005  loss: 0.5219 (0.5384)  loss_classifier: 0.1221 (0.1259)  loss_box_reg: 0.3692 (0.3758)  loss_objectness: 0.0237 (0.0248)  loss_rpn_box_reg: 0.0119 (0.0119)  time: 0.4197  data: 0.0095  max mem: 6721\n",
            "Epoch: [9]  [ 40/108]  eta: 0:00:29  lr: 0.000005  loss: 0.5515 (0.5414)  loss_classifier: 0.1283 (0.1273)  loss_box_reg: 0.3797 (0.3776)  loss_objectness: 0.0235 (0.0246)  loss_rpn_box_reg: 0.0126 (0.0119)  time: 0.4246  data: 0.0093  max mem: 6721\n",
            "Epoch: [9]  [ 50/108]  eta: 0:00:24  lr: 0.000005  loss: 0.5515 (0.5455)  loss_classifier: 0.1286 (0.1295)  loss_box_reg: 0.3867 (0.3791)  loss_objectness: 0.0224 (0.0248)  loss_rpn_box_reg: 0.0116 (0.0120)  time: 0.4268  data: 0.0094  max mem: 6721\n",
            "Epoch: [9]  [ 60/108]  eta: 0:00:20  lr: 0.000005  loss: 0.5634 (0.5468)  loss_classifier: 0.1286 (0.1292)  loss_box_reg: 0.3858 (0.3803)  loss_objectness: 0.0265 (0.0253)  loss_rpn_box_reg: 0.0125 (0.0120)  time: 0.4285  data: 0.0096  max mem: 6721\n",
            "Epoch: [9]  [ 70/108]  eta: 0:00:16  lr: 0.000005  loss: 0.5317 (0.5461)  loss_classifier: 0.1210 (0.1285)  loss_box_reg: 0.3798 (0.3802)  loss_objectness: 0.0285 (0.0253)  loss_rpn_box_reg: 0.0122 (0.0120)  time: 0.4323  data: 0.0096  max mem: 6721\n",
            "Epoch: [9]  [ 80/108]  eta: 0:00:12  lr: 0.000005  loss: 0.5198 (0.5452)  loss_classifier: 0.1213 (0.1287)  loss_box_reg: 0.3697 (0.3789)  loss_objectness: 0.0271 (0.0254)  loss_rpn_box_reg: 0.0115 (0.0121)  time: 0.4363  data: 0.0094  max mem: 6721\n",
            "Epoch: [9]  [ 90/108]  eta: 0:00:07  lr: 0.000005  loss: 0.5137 (0.5439)  loss_classifier: 0.1236 (0.1286)  loss_box_reg: 0.3590 (0.3780)  loss_objectness: 0.0234 (0.0252)  loss_rpn_box_reg: 0.0118 (0.0122)  time: 0.4382  data: 0.0094  max mem: 6721\n",
            "Epoch: [9]  [100/108]  eta: 0:00:03  lr: 0.000005  loss: 0.5321 (0.5441)  loss_classifier: 0.1294 (0.1287)  loss_box_reg: 0.3725 (0.3779)  loss_objectness: 0.0234 (0.0254)  loss_rpn_box_reg: 0.0114 (0.0120)  time: 0.4364  data: 0.0093  max mem: 6721\n",
            "Epoch: [9]  [107/108]  eta: 0:00:00  lr: 0.000005  loss: 0.5029 (0.5398)  loss_classifier: 0.1141 (0.1274)  loss_box_reg: 0.3489 (0.3754)  loss_objectness: 0.0191 (0.0250)  loss_rpn_box_reg: 0.0104 (0.0120)  time: 0.4248  data: 0.0090  max mem: 6721\n",
            "Epoch: [9] Total time: 0:00:46 (0.4311 s / it)\n",
            "step\n",
            "evaluating\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [ 0/54]  eta: 0:00:21  model_time: 0.1109 (0.1109)  evaluator_time: 0.0341 (0.0341)  time: 0.4045  data: 0.2542  max mem: 6721\n",
            "Test:  [53/54]  eta: 0:00:00  model_time: 0.0584 (0.0612)  evaluator_time: 0.0354 (0.0394)  time: 0.1050  data: 0.0066  max mem: 6721\n",
            "Test: Total time: 0:00:06 (0.1179 s / it)\n",
            "Averaged stats: model_time: 0.0584 (0.0612)  evaluator_time: 0.0354 (0.0394)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.09s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.445\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.803\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.410\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.275\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.435\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.761\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.338\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.527\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.570\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.423\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.569\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.770\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}