{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Glie_44.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/POE-DAMERON/Glie-44/blob/main/Model/Glie_44.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPx23mf0avpR"
      },
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow_hub as hub\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from os import path, listdir\n",
        "from pathlib import Path\n",
        "import cv2 as cv\n",
        "from google.colab import drive\n",
        "import sys\n",
        "import io\n",
        "import random\n",
        "\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "'''\n",
        "  Downloads Data from the VisDrone dataset.\n",
        "  Input is which dataset to download:\n",
        "    - 0 is the training dataset\n",
        "    - 1 is the developper testing dataset\n",
        "    - 2 is the actual challenge testing dataset\n",
        "    - 3 is the val dataset\n",
        "'''\n",
        "\n",
        "def initialize_training(file = 0):\n",
        "  !git clone https://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@github.com/POE-DAMERON/Glie-44.git\n",
        "  drive.mount('/content/drive')\n",
        "\n",
        "  \n",
        "  if file == 1:\n",
        "    !unzip /content/drive/MyDrive/VisDrone2019-MOT-test-dev.zip\n",
        "  elif file == 2:\n",
        "    !unzip /content/drive/MyDrive/VisDrone2019-MOT-test-challenge.zip\n",
        "  elif file == 3:\n",
        "    !unzip /content/drive/MyDrive/VisDrone2019-MOT-val.zip\n",
        "  else:\n",
        "    !unzip /content/drive/MyDrive/VisDrone2019-MOT-train.zip\n",
        "\n",
        "initialize_training()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDWgZe8DQZS4"
      },
      "source": [
        "**New Model using Pytorch**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23EcvQ0gWTmO"
      },
      "source": [
        "Main.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Saxy2LvOmdbn",
        "outputId": "8479da8d-1d65-47f6-9510-03dcd0b22567"
      },
      "source": [
        "%%shell\n",
        "\n",
        "git clone https://github.com/pytorch/vision.git\n",
        "cd vision\n",
        "git checkout v0.3.0\n",
        "\n",
        "cp references/detection/utils.py ../\n",
        "cp references/detection/transforms.py ../\n",
        "cp references/detection/coco_eval.py ../\n",
        "cp references/detection/engine.py ../\n",
        "cp references/detection/coco_utils.py ../"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'vision' already exists and is not an empty directory.\n",
            "HEAD is now at be376084 version check against PyTorch's CUDA version\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKOtVOkjWSps"
      },
      "source": [
        "import torch\n",
        "from engine import train_one_epoch, evaluate\n",
        "import utils\n",
        "import os\n",
        "import pandas as pd\n",
        "import transforms as T\n",
        "from pathlib import Path\n",
        "import csv\n",
        "import time\n",
        "\n",
        "def get_results(evaluator):\n",
        "  old_stdout = sys.stdout\n",
        "  sys.stdout = buffer = io.StringIO()\n",
        "\n",
        "  result = str(evaluator.coco_eval)\n",
        "  test = evaluator.coco_eval.items()\n",
        "  for iou_type, coco_eval in test:\n",
        "    print(\"IoU metric: {}\".format(iou_type))\n",
        "    try:\n",
        "      print(coco_eval)\n",
        "    except:\n",
        "      pass\n",
        "\n",
        "  sys.stdout = old_stdout\n",
        "\n",
        "  return buffer.getvalue()\n",
        "\n",
        "def add_to_record(arguments, output, is_saved = False, path_to_saved_model = ''):\n",
        "\n",
        "  with open('drive/MyDrive/training.csv', 'a', newline='') as f:\n",
        "    writer = csv.writer(f)\n",
        "\n",
        "    #writer.writerow(['Saved', 'path_to_saved_model', 'number_of_epochs', 'batch_size', 'optimizer', 'learning_rate', 'weight_decay', 'momentum', 'lr_scheduler_step_size', 'lr_scheduler_gamma', 'output'])\n",
        "    writer.writerow([is_saved, path_to_saved_model, arguments['number_of_epochs'], arguments['batch_size'], arguments['optimizer'], arguments['lr'], arguments['weight_decay'], arguments['momentum'], arguments['lr_scheduler_step_size'], arguments['lr_scheduler_gamma'], output])\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "  saving the model will add it to the record\n",
        "\"\"\"\n",
        "\n",
        "def save_model(model, evaluator, arguments, path = ''):\n",
        "\n",
        "  \"\"\"\n",
        "      saves the model and adds to the csv records\n",
        "\n",
        "      2 methods :\n",
        "        - saving the whole model\n",
        "        - saving the weights and info\n",
        "  \"\"\"\n",
        "\n",
        "  if path == '':\n",
        "    path = 'drive/MyDrive/Models/model-' + str(int(time.time())) + '.pth'\n",
        "\n",
        "  torch.save(model,path) \n",
        "\n",
        "  #torch.save(model.state_dict(), path)\n",
        "  add_to_record(arguments = arguments, output = evaluator, is_saved = True, path_to_saved_model = path)\n",
        "  \n",
        "def load_model(path):\n",
        "\n",
        "  model = torch.load(path)\n",
        "\n",
        "  \"\"\"\n",
        "    model = Model()\n",
        "    model.load_state_dict(torch.load(path))\n",
        "  \"\"\"\n",
        "\n",
        "  return model\n",
        "\n",
        "def get_arguments(train_percentage, epochs, batch_size, optimizer,\n",
        "                            lr, momentum, weight_decay, step_size, gamma):\n",
        "  \n",
        "  arguments = {}\n",
        "\n",
        "  arguments['train_percentage'] = train_percentage\n",
        "  if (optimizer == 'adam'):\n",
        "    arguments['optimizer'] = optimizer\n",
        "    arguments['momentum'] = ''\n",
        "  else:\n",
        "    arguments['optimizer'] = 'sgd'\n",
        "    arguments['momentum'] = momentum\n",
        "  arguments['lr'] = lr\n",
        "  arguments['weight_decay'] = weight_decay\n",
        "  arguments['lr_scheduler_step_size'] = step_size\n",
        "  arguments['lr_scheduler_gamma'] = gamma\n",
        "  arguments['number_of_epochs'] = epochs\n",
        "  arguments['batch_size'] = batch_size\n",
        "\n",
        "  return arguments\n",
        "\n",
        "def train_videos(path_to_saved_model = '', train_percentage = .8, test_size = -1,\n",
        "          train_size = -1, batch_size = 2, epochs = 10, optimizer='sgd',\n",
        "          lr = 0.005, momentum = 0.9, weight_decay= 0.0005, step_size = 3,\n",
        "          gamma = 0.1):\n",
        "  \n",
        "  arguments = get_arguments(train_percentage, epochs, batch_size, optimizer,\n",
        "                            lr, momentum, weight_decay, step_size, gamma)\n",
        "  \n",
        "  if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "  else:\n",
        "    device = torch.device('cpu')\n",
        "  \n",
        "  x = VisDroneDataset(Path().absolute().joinpath('VisDrone2019-MOT-train'), Utils.to_tensor())\n",
        "  testing_data = torch.utils.data.DataLoader(x[0])\n",
        "\n",
        "  for i in range(len(x)):\n",
        "\n",
        "    print(\"\\n-----------------------------\\nVideo {} / {}\\n\".format(i+1, len(x)))\n",
        "\n",
        "    X = x[i]\n",
        "\n",
        "    if train_size == -1:\n",
        "      train_sz = int(len(X) * train_percentage)\n",
        "    else:\n",
        "      train_sz = train_size\n",
        "      \n",
        "    x_train, x_test = torch.utils.data.random_split(X, [train_sz, len(X) - train_sz])\n",
        "\n",
        "    if test_size != -1:\n",
        "      x_test = Utils.slice(x_test, 0, test_size)\n",
        "\n",
        "    data_loader = torch.utils.data.DataLoader(\n",
        "          x_train, batch_size=batch_size, shuffle=True, num_workers=2,\n",
        "          collate_fn=utils.collate_fn)\n",
        "    \n",
        "    data_loader_test = torch.utils.data.DataLoader(\n",
        "      x_test, batch_size=1, shuffle=False, num_workers=2,\n",
        "      collate_fn=utils.collate_fn)\n",
        "    \n",
        "    testing_data = data_loader_test\n",
        "    \n",
        "    if str(path_to_saved_model) == '':\n",
        "      model = build_model()\n",
        "    else:\n",
        "      model = load_model(path_to_saved_model)\n",
        "\n",
        "    model.to(device)\n",
        "\n",
        "    params = [p for p in model.parameters() if p.requires_grad]\n",
        "\n",
        "    if (optimizer == 'adam'):\n",
        "      optim = torch.optim.Adam(params, lr=lr, weight_decay=weight_decay)\n",
        "    else:\n",
        "      optim = torch.optim.SGD(params, lr=lr,\n",
        "                              momentum=momentum, weight_decay=weight_decay)\n",
        "\n",
        "    lr_scheduler = torch.optim.lr_scheduler.StepLR(optim,\n",
        "                                                    step_size=step_size,\n",
        "                                                    gamma=gamma)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "          train_one_epoch(model, optim, data_loader, device, epoch, print_freq=10)\n",
        "          lr_scheduler.step()\n",
        "          evaluate(model, testing_data, device=device)\n",
        "  \n",
        "  return model, evaluate(model, testing_data, device=device), arguments\n",
        "\n",
        "def train(path_to_saved_model = '', train_percentage = .8, test_percentage = -1,\n",
        "          test_size = -1, train_size = -1, batch_size = 2, epochs = 10, optimizer='sgd',\n",
        "          lr = 0.005, momentum = 0.9, weight_decay= 0.0005, step_size = 3,\n",
        "          gamma = 0.1):\n",
        "  \n",
        "  arguments = get_arguments(train_percentage, epochs, batch_size, optimizer,\n",
        "                            lr, momentum, weight_decay, step_size, gamma)\n",
        "  \n",
        "  if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "  else:\n",
        "    device = torch.device('cpu')\n",
        "  \n",
        "  X = AllVisDroneVideos(Path().absolute().joinpath('VisDrone2019-MOT-train').joinpath(\"sequences\"), Path().absolute().joinpath('VisDrone2019-MOT-train').joinpath(\"annotations\"), Utils.to_tensor())\n",
        "\n",
        "  if train_size == -1:\n",
        "    train_sz = int(len(X) * train_percentage)\n",
        "  else:\n",
        "    train_sz = train_size\n",
        "  \n",
        "  test_sz = int(len(X) * min(1,max(0, test_percentage)))\n",
        "\n",
        "  x_train, x_test, x_overflow = torch.utils.data.random_split(X, [train_sz, test_sz , len(X) - train_sz - test_sz])\n",
        "\n",
        "  random.shuffle(X.imgs)\n",
        "\n",
        "  x_train = AllVisDroneVideos(Path().absolute().joinpath('VisDrone2019-MOT-train').joinpath(\"sequences\"), Path().absolute().joinpath('VisDrone2019-MOT-train').joinpath(\"annotations\"), Utils.to_tensor(), X.imgs[:train_sz])\n",
        "  x_test = AllVisDroneVideos(Path().absolute().joinpath('VisDrone2019-MOT-train').joinpath(\"sequences\"), Path().absolute().joinpath('VisDrone2019-MOT-train').joinpath(\"annotations\"), Utils.to_tensor(), X.imgs[train_sz:train_sz + test_sz])\n",
        "\n",
        "  if test_size != -1:\n",
        "    x_test = Utils.slice(x_test, 0, test_size)\n",
        "\n",
        "  data_loader = torch.utils.data.DataLoader(\n",
        "      x_train, batch_size=batch_size, shuffle=True, num_workers=2,\n",
        "      collate_fn=utils.collate_fn)\n",
        "    \n",
        "  data_loader_test = torch.utils.data.DataLoader(\n",
        "      x_test, batch_size=1, shuffle=False, num_workers=2,\n",
        "      collate_fn=utils.collate_fn)\n",
        "    \n",
        "  if str(path_to_saved_model) == '':\n",
        "    model = build_model()\n",
        "  else:\n",
        "    model = load_model(path_to_saved_model)\n",
        "\n",
        "  model.to(device)\n",
        "\n",
        "  params = [p for p in model.parameters() if p.requires_grad]\n",
        "\n",
        "  if (optimizer == 'adam'):\n",
        "    optim = torch.optim.Adam(params, lr=lr, weight_decay=weight_decay)\n",
        "  else:\n",
        "    optim = torch.optim.SGD(params, lr=lr,\n",
        "                              momentum=momentum, weight_decay=weight_decay)\n",
        "\n",
        "  lr_scheduler = torch.optim.lr_scheduler.StepLR(optim,\n",
        "                                                    step_size=step_size,\n",
        "                                                    gamma=gamma)\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    train_one_epoch(model, optim, data_loader, device, epoch, print_freq=10)\n",
        "    print('\\n---------\\nTRAIN ONE EPOCH FINISHED')\n",
        "    lr_scheduler.step()\n",
        "    evaluate(model, data_loader_test, device=device)\n",
        "    results = get_results(evaluate(model, data_loader_test, device=device))\n",
        "    #print(results)\n",
        "  \n",
        "  return model, results, arguments\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyCvAuqO12L1"
      },
      "source": [
        "import torchvision\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from torchvision.models.detection import FasterRCNN\n",
        "from torchvision.models.detection.rpn import AnchorGenerator\n",
        "\n",
        "def build_model(num_classes = 12):\n",
        "  model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "  in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "  model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
        "\n",
        "  \"\"\"\n",
        "  backbone = torchvision.models.mobilenet_v2(pretrained=True).features\n",
        "  backbone.out_channels = 1280\n",
        "\n",
        "  anchor_generator = AnchorGenerator(sizes=((32, 64, 128, 256, 512),),\n",
        "                                    aspect_ratios=((0.5, 1.0, 2.0),))\n",
        "\n",
        "  roi_pooler = torchvision.ops.MultiScaleRoIAlign(featmap_names=['0'],\n",
        "                                                  output_size=7,\n",
        "                                                  sampling_ratio=2)\n",
        "  return FasterRCNN(backbone,\n",
        "                    num_classes=num_classes,\n",
        "                    rpn_anchor_generator=anchor_generator,\n",
        "                    box_roi_pool=roi_pooler)\n",
        "  \"\"\"\n",
        "  return model"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLmxWKCkRRan"
      },
      "source": [
        "class VisDroneVideo(object):\n",
        "    def __init__(self ,root, target_path, preprocessing = None, imgs = None):\n",
        "        self.root = str(root)\n",
        "        self.preprocessing = preprocessing\n",
        "        if (imgs != None):\n",
        "          self.imgs = imgs\n",
        "        else:\n",
        "          self.imgs = sorted(listdir(Path(root)), key=lambda x: x.lstrip(\"_\"))\n",
        "        self.target = target_path\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        img_path = Path(self.root).joinpath(self.imgs[idx])\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        video_targets = Utils.read_txt_visdrone(self.target)\n",
        "        image_targets = self.clean_targets(video_targets, idx)\n",
        "        image_targets[\"is_crowd\"] = 0\n",
        "        boxes = image_targets[[\"bbox_left\", \"bbox_top\", \"right\", \"bottom\"]]\n",
        "\n",
        "        boxes = boxes.astype('float32')\n",
        "\n",
        "        boxes = torch.as_tensor(boxes.values, dtype=torch.float32)\n",
        "        labels = torch.as_tensor(image_targets.object_category.astype('int64').values, dtype=torch.int64)\n",
        "        crowd = torch.as_tensor(image_targets.is_crowd.values, dtype=torch.int64)\n",
        "\n",
        "        image_id = torch.tensor([idx])\n",
        "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
        "\n",
        "        target = {}\n",
        "        target[\"boxes\"] = boxes\n",
        "        target[\"labels\"] = labels\n",
        "        target[\"image_id\"] = image_id\n",
        "        target[\"area\"] = area\n",
        "        target[\"iscrowd\"] = crowd\n",
        "\n",
        "        if self.preprocessing is not None:\n",
        "            img, target = self.preprocessing(img, target)\n",
        "\n",
        "        return img, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.imgs)\n",
        "\n",
        "    def clean_targets(self, targets, idx):\n",
        "\n",
        "        targets = self.targetsToDataframe(targets)\n",
        "        targets = targets[(targets.object_category != \"0\")]\n",
        "        targets = targets[(targets.frame_index == str(idx+1))]\n",
        "\n",
        "        targets.bbox_top = targets.bbox_top.astype('float32')\n",
        "        targets.bbox_height = targets.bbox_height.astype('float32')\n",
        "        targets.bbox_left = targets.bbox_left.astype('float32')\n",
        "        targets.bbox_width = targets.bbox_width.astype('float32')\n",
        "\n",
        "        targets[\"bottom\"] = targets.bbox_top + targets.bbox_height\n",
        "        targets[\"right\"] = targets.bbox_left + targets.bbox_width\n",
        "\n",
        "        return targets\n",
        "    \n",
        "    def targetsToDataframe(self, array):\n",
        "        columns = [\n",
        "          \"frame_index\",\n",
        "          \"target_id\",\n",
        "          \"bbox_left\",\n",
        "          \"bbox_top\",\n",
        "          \"bbox_width\",\n",
        "          \"bbox_height\",\n",
        "          \"score\",\n",
        "          \"object_category\",\n",
        "          \"truncation\",\n",
        "          \"oclusion\"\n",
        "        ]\n",
        "        return pd.DataFrame(data=array,columns=columns)\n",
        "\n",
        "class AllVisDroneVideos(VisDroneVideo):\n",
        "    def __init__(self,root, targets_path, preprocessing = None, imgs = None):\n",
        "      super().__init__(root, targets_path, preprocessing, imgs)\n",
        "      self.targets = sorted(listdir(Path(targets_path)), key=lambda x: x.lstrip(\"_\"))\n",
        "\n",
        "    def __len__(self):\n",
        "      return super().__len__()\n",
        "\n",
        "    def get_video_name(self, image_path):\n",
        "      return image_path.stem[:-8] + \".txt\", int(image_path.stem[-7:]) -1\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = Path(self.root).joinpath(self.imgs[idx])\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        video_name, image_idx = self.get_video_name(img_path)\n",
        "\n",
        "        video_targets = Utils.read_txt_visdrone(Path(self.target).joinpath(video_name))\n",
        "        image_targets = self.clean_targets(video_targets, image_idx)\n",
        "        image_targets[\"is_crowd\"] = 0\n",
        "        boxes = image_targets[[\"bbox_left\", \"bbox_top\", \"right\", \"bottom\"]]\n",
        "\n",
        "        boxes = boxes.astype('float32')\n",
        "\n",
        "        boxes = torch.as_tensor(boxes.values, dtype=torch.float32)\n",
        "        labels = torch.as_tensor(image_targets.object_category.astype('int64').values, dtype=torch.int64)\n",
        "        crowd = torch.as_tensor(image_targets.is_crowd.values, dtype=torch.int64)\n",
        "\n",
        "        image_id = torch.tensor([idx])\n",
        "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
        "\n",
        "        target = {}\n",
        "        target[\"boxes\"] = boxes\n",
        "        target[\"labels\"] = labels\n",
        "        target[\"image_id\"] = image_id\n",
        "        target[\"area\"] = area\n",
        "        target[\"iscrowd\"] = crowd\n",
        "\n",
        "        if self.preprocessing is not None:\n",
        "            img, target = self.preprocessing(img, target)\n",
        "\n",
        "        return img, target\n",
        "\n",
        "    def get_video_from_idx(self,idx):\n",
        "\n",
        "      video_lengths = [269, 58, 118, 501, 181, 85, 217, 97, 361, 361,\n",
        " 516, 1255, 398, 412, 213, 256, 261, 307, 348, 225, 421, 680, 341, 768, 721,\n",
        " 677, 725, 616, 548, 116, 680, 872, 962, 547, 508, 1424, 500, 210, 346, 556, \n",
        " 414, 230, 185, 403, 632, 127, 426, 369, 196, 277, 196, 691, 421, 219, 462,296]\n",
        "      \n",
        "      for i in range(len(video_lengths)):\n",
        "        if idx<video_lengths[i]:\n",
        "          return i, idx\n",
        "        else:\n",
        "          idx -= video_lengths[i]\n",
        "      return len(video_lengths), idx\n",
        "\n",
        "class VisDroneDataset(object):\n",
        "    def __init__(self, root, preprocessing = None):\n",
        "        self.root = root\n",
        "        self.preprocessing = preprocessing\n",
        "        \n",
        "        self.videos = sorted(listdir(Path(root).joinpath(\"sequences\")), key=lambda x: x.lstrip(\"_\"))\n",
        "        self.targets = sorted(listdir(Path(root).joinpath(\"annotations\")), key=lambda x: x.lstrip(\"_\"))\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "      return VisDroneVideo(Path(self.root).joinpath(\"sequences\").joinpath(self.videos[idx]),Path(self.root).joinpath(\"annotations\").joinpath(self.targets[idx]), self.preprocessing)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.videos)\n",
        "\n",
        "    '''\n",
        "        Concatenates the images of all videos into a large VisDroneVideo class\n",
        "        Allows the model to train on a broader sample of data\n",
        "    \n",
        "\n",
        "    def all_images(self):\n",
        "        large_dataset = VisDroneVideo()\n",
        "\n",
        "        for i in self:\n",
        "          for j in i[0]:\n",
        "            print(j)\n",
        "\n",
        "    '''"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3XhaZ_CZ6Z1"
      },
      "source": [
        "Utils.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfKM3TFaZ6M8"
      },
      "source": [
        "class Utils():\n",
        "\n",
        "  @staticmethod\n",
        "  def to_tensor():\n",
        "    transforms = []\n",
        "    # converts the image, a PIL image, into a PyTorch Tensor\n",
        "    transforms.append(T.ToTensor())\n",
        "    return T.Compose(transforms)\n",
        "\n",
        "  @staticmethod\n",
        "  def read_txt_visdrone(path):\n",
        "      \"\"\"\n",
        "          Input: Path of the txt file with annotations as in the VisDrone dataset\\n\n",
        "          Output: A numpy array containing the information for bounding boxes\n",
        "      \"\"\"\n",
        "      lines = []\n",
        "      with open(path) as f:\n",
        "          lines = f.readlines()\n",
        "          f.close()\n",
        "      df = []\n",
        "      for x in lines:\n",
        "          splitLine = x.split(\",\")\n",
        "          splitLine[-1] = splitLine[-1].split(\"\\n\")[0]\n",
        "          df.append(splitLine)\n",
        "      return df\n",
        "      \n",
        "  @staticmethod\n",
        "  def bottom_right(left,top,width,height):\n",
        "      \"\"\"\n",
        "          Input: co-ordinates for the top left corner of a bounding box and its width and height\\n\n",
        "          Output: co-ordinates for the bottom right corner\n",
        "      \"\"\"\n",
        "      bottom = top + height\n",
        "      right = left + width\n",
        "      return right, bottom\n",
        "\n",
        "  @staticmethod\n",
        "  def slice(array, start, stop):\n",
        "    result = []\n",
        "    for i in range(stop-start):\n",
        "      result.append(array[start + i])\n",
        "    return result"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zn4oKgG2g3nu",
        "outputId": "39eb6d99-0560-4f26-f695-9d822f82c0fe"
      },
      "source": [
        "eval = train(epochs = 2, train_percentage= .01, test_percentage=.01)\n",
        "add_to_record(arguments = eval[2], output = eval[1],is_saved = False)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: [0]  [  0/121]  eta: 0:03:43  lr: 0.000047  loss: 3.9957 (3.9957)  loss_classifier: 2.6050 (2.6050)  loss_box_reg: 0.5796 (0.5796)  loss_objectness: 0.6471 (0.6471)  loss_rpn_box_reg: 0.1640 (0.1640)  time: 1.8506  data: 1.1572  max mem: 3978\n",
            "Epoch: [0]  [ 10/121]  eta: 0:01:19  lr: 0.000463  loss: 3.4476 (3.2931)  loss_classifier: 2.3598 (2.1352)  loss_box_reg: 0.7372 (0.7107)  loss_objectness: 0.2495 (0.2630)  loss_rpn_box_reg: 0.1750 (0.1841)  time: 0.7124  data: 0.1191  max mem: 3978\n",
            "Epoch: [0]  [ 20/121]  eta: 0:01:06  lr: 0.000879  loss: 2.3285 (2.6872)  loss_classifier: 1.2194 (1.5797)  loss_box_reg: 0.7270 (0.7128)  loss_objectness: 0.1765 (0.2317)  loss_rpn_box_reg: 0.1575 (0.1630)  time: 0.5944  data: 0.0163  max mem: 3978\n",
            "Epoch: [0]  [ 30/121]  eta: 0:00:57  lr: 0.001295  loss: 1.9071 (2.4139)  loss_classifier: 0.8411 (1.3235)  loss_box_reg: 0.6774 (0.6996)  loss_objectness: 0.1639 (0.2174)  loss_rpn_box_reg: 0.1781 (0.1735)  time: 0.5907  data: 0.0164  max mem: 3978\n",
            "Epoch: [0]  [ 40/121]  eta: 0:00:50  lr: 0.001712  loss: 1.8493 (2.2690)  loss_classifier: 0.7895 (1.1880)  loss_box_reg: 0.7051 (0.7027)  loss_objectness: 0.1611 (0.2133)  loss_rpn_box_reg: 0.1502 (0.1649)  time: 0.5901  data: 0.0154  max mem: 3978\n",
            "Epoch: [0]  [ 50/121]  eta: 0:00:44  lr: 0.002128  loss: 1.7435 (2.1511)  loss_classifier: 0.6855 (1.0885)  loss_box_reg: 0.6743 (0.6910)  loss_objectness: 0.1544 (0.2063)  loss_rpn_box_reg: 0.1502 (0.1653)  time: 0.5989  data: 0.0171  max mem: 3978\n",
            "Epoch: [0]  [ 60/121]  eta: 0:00:37  lr: 0.002544  loss: 1.6478 (2.0509)  loss_classifier: 0.6620 (1.0180)  loss_box_reg: 0.6413 (0.6803)  loss_objectness: 0.1381 (0.1916)  loss_rpn_box_reg: 0.1702 (0.1610)  time: 0.6101  data: 0.0185  max mem: 3978\n",
            "Epoch: [0]  [ 70/121]  eta: 0:00:31  lr: 0.002960  loss: 1.5393 (1.9762)  loss_classifier: 0.6225 (0.9608)  loss_box_reg: 0.5773 (0.6621)  loss_objectness: 0.1219 (0.1888)  loss_rpn_box_reg: 0.1578 (0.1644)  time: 0.6097  data: 0.0174  max mem: 3978\n",
            "Epoch: [0]  [ 80/121]  eta: 0:00:25  lr: 0.003377  loss: 1.5865 (1.9345)  loss_classifier: 0.6315 (0.9238)  loss_box_reg: 0.5637 (0.6554)  loss_objectness: 0.1470 (0.1869)  loss_rpn_box_reg: 0.1793 (0.1684)  time: 0.6048  data: 0.0162  max mem: 3978\n",
            "Epoch: [0]  [ 90/121]  eta: 0:00:19  lr: 0.003793  loss: 1.4512 (1.8675)  loss_classifier: 0.5517 (0.8773)  loss_box_reg: 0.5658 (0.6426)  loss_objectness: 0.1518 (0.1818)  loss_rpn_box_reg: 0.1533 (0.1658)  time: 0.6030  data: 0.0160  max mem: 3978\n",
            "Epoch: [0]  [100/121]  eta: 0:00:12  lr: 0.004209  loss: 1.3247 (1.8169)  loss_classifier: 0.5062 (0.8434)  loss_box_reg: 0.5279 (0.6361)  loss_objectness: 0.0964 (0.1727)  loss_rpn_box_reg: 0.1399 (0.1646)  time: 0.6034  data: 0.0161  max mem: 3978\n",
            "Epoch: [0]  [110/121]  eta: 0:00:06  lr: 0.004625  loss: 1.3741 (1.7788)  loss_classifier: 0.5551 (0.8182)  loss_box_reg: 0.5468 (0.6310)  loss_objectness: 0.0831 (0.1662)  loss_rpn_box_reg: 0.1430 (0.1633)  time: 0.6039  data: 0.0158  max mem: 3978\n",
            "Epoch: [0]  [120/121]  eta: 0:00:00  lr: 0.005000  loss: 1.4165 (1.7459)  loss_classifier: 0.5594 (0.7950)  loss_box_reg: 0.5495 (0.6248)  loss_objectness: 0.1097 (0.1630)  loss_rpn_box_reg: 0.1532 (0.1631)  time: 0.6083  data: 0.0152  max mem: 3978\n",
            "Epoch: [0] Total time: 0:01:14 (0.6130 s / it)\n",
            "\n",
            "---------\n",
            "TRAIN ONE EPOCH FINISHED\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py:5170: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self[name] = value\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:56: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:95: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "creating index...\n",
            "index created!\n",
            "Test:  [  0/242]  eta: 0:03:51  model_time: 0.2234 (0.2234)  evaluator_time: 0.1119 (0.1119)  time: 0.9567  data: 0.6094  max mem: 3978\n",
            "Test:  [100/242]  eta: 0:00:34  model_time: 0.1258 (0.1291)  evaluator_time: 0.0709 (0.0802)  time: 0.2492  data: 0.0280  max mem: 3978\n",
            "Test:  [200/242]  eta: 0:00:10  model_time: 0.1261 (0.1285)  evaluator_time: 0.0885 (0.0812)  time: 0.2376  data: 0.0160  max mem: 3978\n",
            "Test:  [241/242]  eta: 0:00:00  model_time: 0.1261 (0.1287)  evaluator_time: 0.0633 (0.0819)  time: 0.2409  data: 0.0216  max mem: 3978\n",
            "Test: Total time: 0:00:58 (0.2424 s / it)\n",
            "Averaged stats: model_time: 0.1261 (0.1287)  evaluator_time: 0.0633 (0.0819)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.41s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.059\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.141\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.044\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.029\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.062\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.174\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.019\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.074\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.109\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.068\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.108\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.235\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [  0/242]  eta: 0:03:33  model_time: 0.1950 (0.1950)  evaluator_time: 0.0732 (0.0732)  time: 0.8816  data: 0.6060  max mem: 3978\n",
            "Test:  [100/242]  eta: 0:00:34  model_time: 0.1246 (0.1286)  evaluator_time: 0.0678 (0.0800)  time: 0.2466  data: 0.0196  max mem: 3978\n",
            "Test:  [200/242]  eta: 0:00:10  model_time: 0.1267 (0.1284)  evaluator_time: 0.0789 (0.0823)  time: 0.2419  data: 0.0199  max mem: 3978\n",
            "Test:  [241/242]  eta: 0:00:00  model_time: 0.1261 (0.1286)  evaluator_time: 0.0595 (0.0833)  time: 0.2442  data: 0.0231  max mem: 3978\n",
            "Test: Total time: 0:00:59 (0.2448 s / it)\n",
            "Averaged stats: model_time: 0.1261 (0.1286)  evaluator_time: 0.0595 (0.0833)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.42s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.059\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.141\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.044\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.029\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.062\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.174\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.019\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.074\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.109\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.068\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.108\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.235\n",
            "Epoch: [1]  [  0/121]  eta: 0:02:16  lr: 0.005000  loss: 1.6719 (1.6719)  loss_classifier: 0.6679 (0.6679)  loss_box_reg: 0.7127 (0.7127)  loss_objectness: 0.0897 (0.0897)  loss_rpn_box_reg: 0.2015 (0.2015)  time: 1.1315  data: 0.5239  max mem: 3978\n",
            "Epoch: [1]  [ 10/121]  eta: 0:01:17  lr: 0.005000  loss: 1.3903 (1.3778)  loss_classifier: 0.5244 (0.5475)  loss_box_reg: 0.5698 (0.5695)  loss_objectness: 0.0897 (0.1012)  loss_rpn_box_reg: 0.1562 (0.1596)  time: 0.6971  data: 0.0915  max mem: 3978\n",
            "Epoch: [1]  [ 20/121]  eta: 0:01:06  lr: 0.005000  loss: 1.3531 (1.3680)  loss_classifier: 0.5179 (0.5284)  loss_box_reg: 0.5698 (0.5695)  loss_objectness: 0.1033 (0.1110)  loss_rpn_box_reg: 0.1504 (0.1591)  time: 0.6332  data: 0.0316  max mem: 3978\n",
            "Epoch: [1]  [ 30/121]  eta: 0:00:58  lr: 0.005000  loss: 1.3055 (1.3374)  loss_classifier: 0.5257 (0.5185)  loss_box_reg: 0.5551 (0.5654)  loss_objectness: 0.0988 (0.1048)  loss_rpn_box_reg: 0.1503 (0.1487)  time: 0.6113  data: 0.0163  max mem: 3978\n",
            "Epoch: [1]  [ 40/121]  eta: 0:00:51  lr: 0.005000  loss: 1.3055 (1.3231)  loss_classifier: 0.5158 (0.5092)  loss_box_reg: 0.5449 (0.5597)  loss_objectness: 0.0976 (0.1077)  loss_rpn_box_reg: 0.1352 (0.1464)  time: 0.6112  data: 0.0157  max mem: 3978\n",
            "Epoch: [1]  [ 50/121]  eta: 0:00:44  lr: 0.005000  loss: 1.2861 (1.3012)  loss_classifier: 0.4876 (0.4989)  loss_box_reg: 0.5376 (0.5521)  loss_objectness: 0.1112 (0.1046)  loss_rpn_box_reg: 0.1254 (0.1457)  time: 0.6113  data: 0.0146  max mem: 3978\n",
            "Epoch: [1]  [ 60/121]  eta: 0:00:38  lr: 0.005000  loss: 1.2504 (1.2845)  loss_classifier: 0.4587 (0.4912)  loss_box_reg: 0.5320 (0.5502)  loss_objectness: 0.0797 (0.1026)  loss_rpn_box_reg: 0.1209 (0.1406)  time: 0.6098  data: 0.0146  max mem: 3978\n",
            "Epoch: [1]  [ 70/121]  eta: 0:00:31  lr: 0.005000  loss: 1.2667 (1.2891)  loss_classifier: 0.4823 (0.4993)  loss_box_reg: 0.5366 (0.5480)  loss_objectness: 0.0832 (0.1009)  loss_rpn_box_reg: 0.1166 (0.1409)  time: 0.6138  data: 0.0156  max mem: 3978\n",
            "Epoch: [1]  [ 80/121]  eta: 0:00:25  lr: 0.005000  loss: 1.2667 (1.2818)  loss_classifier: 0.5028 (0.4973)  loss_box_reg: 0.5206 (0.5463)  loss_objectness: 0.0832 (0.0991)  loss_rpn_box_reg: 0.1197 (0.1391)  time: 0.6150  data: 0.0162  max mem: 3978\n",
            "Epoch: [1]  [ 90/121]  eta: 0:00:19  lr: 0.005000  loss: 1.2128 (1.2706)  loss_classifier: 0.4629 (0.4911)  loss_box_reg: 0.5095 (0.5438)  loss_objectness: 0.0690 (0.0969)  loss_rpn_box_reg: 0.1314 (0.1388)  time: 0.6159  data: 0.0153  max mem: 3978\n",
            "Epoch: [1]  [100/121]  eta: 0:00:13  lr: 0.005000  loss: 1.2128 (1.2673)  loss_classifier: 0.4534 (0.4897)  loss_box_reg: 0.5176 (0.5429)  loss_objectness: 0.0738 (0.0960)  loss_rpn_box_reg: 0.1321 (0.1388)  time: 0.6269  data: 0.0182  max mem: 3978\n",
            "Epoch: [1]  [110/121]  eta: 0:00:06  lr: 0.005000  loss: 1.2378 (1.2627)  loss_classifier: 0.4590 (0.4896)  loss_box_reg: 0.5166 (0.5410)  loss_objectness: 0.0779 (0.0937)  loss_rpn_box_reg: 0.1199 (0.1384)  time: 0.6268  data: 0.0193  max mem: 3978\n",
            "Epoch: [1]  [120/121]  eta: 0:00:00  lr: 0.005000  loss: 1.2206 (1.2540)  loss_classifier: 0.4834 (0.4873)  loss_box_reg: 0.5006 (0.5372)  loss_objectness: 0.0668 (0.0918)  loss_rpn_box_reg: 0.1255 (0.1377)  time: 0.6157  data: 0.0157  max mem: 3978\n",
            "Epoch: [1] Total time: 0:01:15 (0.6237 s / it)\n",
            "\n",
            "---------\n",
            "TRAIN ONE EPOCH FINISHED\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [  0/242]  eta: 0:03:55  model_time: 0.2092 (0.2092)  evaluator_time: 0.1099 (0.1099)  time: 0.9727  data: 0.6391  max mem: 3978\n",
            "Test:  [100/242]  eta: 0:00:33  model_time: 0.1266 (0.1308)  evaluator_time: 0.0584 (0.0718)  time: 0.2337  data: 0.0158  max mem: 3978\n",
            "Test:  [200/242]  eta: 0:00:09  model_time: 0.1274 (0.1299)  evaluator_time: 0.0689 (0.0709)  time: 0.2355  data: 0.0293  max mem: 3978\n",
            "Test:  [241/242]  eta: 0:00:00  model_time: 0.1279 (0.1303)  evaluator_time: 0.0535 (0.0711)  time: 0.2360  data: 0.0303  max mem: 3978\n",
            "Test: Total time: 0:00:57 (0.2356 s / it)\n",
            "Averaged stats: model_time: 0.1279 (0.1303)  evaluator_time: 0.0535 (0.0711)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.45s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.097\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.216\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.075\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.058\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.094\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.208\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.053\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.153\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.198\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.133\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.190\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.344\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [  0/242]  eta: 0:03:51  model_time: 0.1989 (0.1989)  evaluator_time: 0.1099 (0.1099)  time: 0.9551  data: 0.6387  max mem: 3978\n",
            "Test:  [100/242]  eta: 0:00:33  model_time: 0.1282 (0.1302)  evaluator_time: 0.0669 (0.0716)  time: 0.2317  data: 0.0158  max mem: 3978\n",
            "Test:  [200/242]  eta: 0:00:09  model_time: 0.1268 (0.1297)  evaluator_time: 0.0662 (0.0726)  time: 0.2371  data: 0.0255  max mem: 3978\n",
            "Test:  [241/242]  eta: 0:00:00  model_time: 0.1261 (0.1297)  evaluator_time: 0.0472 (0.0728)  time: 0.2333  data: 0.0232  max mem: 3978\n",
            "Test: Total time: 0:00:57 (0.2364 s / it)\n",
            "Averaged stats: model_time: 0.1261 (0.1297)  evaluator_time: 0.0472 (0.0728)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.45s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.097\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.216\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.075\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.058\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.094\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.208\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.053\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.153\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.198\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.133\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.190\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.344\n",
            "Epoch: [0]  [  0/121]  eta: 0:02:30  lr: 0.000047  loss: 3.8438 (3.8438)  loss_classifier: 2.6787 (2.6787)  loss_box_reg: 0.8221 (0.8221)  loss_objectness: 0.1606 (0.1606)  loss_rpn_box_reg: 0.1825 (0.1825)  time: 1.2465  data: 0.5685  max mem: 3978\n",
            "Epoch: [0]  [ 10/121]  eta: 0:01:16  lr: 0.000463  loss: 3.7847 (3.4821)  loss_classifier: 2.4347 (2.2989)  loss_box_reg: 0.7789 (0.8072)  loss_objectness: 0.1606 (0.2280)  loss_rpn_box_reg: 0.1645 (0.1481)  time: 0.6887  data: 0.0741  max mem: 3978\n",
            "Epoch: [0]  [ 20/121]  eta: 0:01:05  lr: 0.000879  loss: 2.1035 (2.7460)  loss_classifier: 1.2933 (1.6655)  loss_box_reg: 0.7498 (0.7716)  loss_objectness: 0.1317 (0.1744)  loss_rpn_box_reg: 0.1462 (0.1344)  time: 0.6231  data: 0.0218  max mem: 3995\n",
            "Epoch: [0]  [ 30/121]  eta: 0:00:58  lr: 0.001295  loss: 1.8763 (2.4353)  loss_classifier: 0.8255 (1.3680)  loss_box_reg: 0.7387 (0.7614)  loss_objectness: 0.1248 (0.1651)  loss_rpn_box_reg: 0.1204 (0.1409)  time: 0.6135  data: 0.0179  max mem: 3995\n",
            "Epoch: [0]  [ 40/121]  eta: 0:00:51  lr: 0.001712  loss: 1.7331 (2.2306)  loss_classifier: 0.6838 (1.1907)  loss_box_reg: 0.7391 (0.7508)  loss_objectness: 0.1184 (0.1503)  loss_rpn_box_reg: 0.1464 (0.1389)  time: 0.6113  data: 0.0160  max mem: 3995\n",
            "Epoch: [0]  [ 50/121]  eta: 0:00:44  lr: 0.002128  loss: 1.5609 (2.0878)  loss_classifier: 0.6108 (1.0699)  loss_box_reg: 0.6878 (0.7320)  loss_objectness: 0.1013 (0.1491)  loss_rpn_box_reg: 0.1287 (0.1368)  time: 0.6114  data: 0.0145  max mem: 3995\n",
            "Epoch: [0]  [ 60/121]  eta: 0:00:38  lr: 0.002544  loss: 1.4991 (1.9934)  loss_classifier: 0.5824 (0.9933)  loss_box_reg: 0.6415 (0.7154)  loss_objectness: 0.1275 (0.1499)  loss_rpn_box_reg: 0.1222 (0.1347)  time: 0.6130  data: 0.0136  max mem: 3995\n",
            "Epoch: [0]  [ 70/121]  eta: 0:00:31  lr: 0.002960  loss: 1.3850 (1.8963)  loss_classifier: 0.5168 (0.9263)  loss_box_reg: 0.5977 (0.6945)  loss_objectness: 0.1159 (0.1450)  loss_rpn_box_reg: 0.1005 (0.1305)  time: 0.6100  data: 0.0138  max mem: 3995\n",
            "Epoch: [0]  [ 80/121]  eta: 0:00:25  lr: 0.003377  loss: 1.4171 (1.8425)  loss_classifier: 0.5449 (0.8819)  loss_box_reg: 0.5977 (0.6837)  loss_objectness: 0.1152 (0.1439)  loss_rpn_box_reg: 0.1213 (0.1330)  time: 0.6130  data: 0.0150  max mem: 3995\n",
            "Epoch: [0]  [ 90/121]  eta: 0:00:19  lr: 0.003793  loss: 1.3776 (1.7830)  loss_classifier: 0.5393 (0.8387)  loss_box_reg: 0.5821 (0.6683)  loss_objectness: 0.1269 (0.1429)  loss_rpn_box_reg: 0.1458 (0.1330)  time: 0.6179  data: 0.0156  max mem: 3995\n",
            "Epoch: [0]  [100/121]  eta: 0:00:13  lr: 0.004209  loss: 1.3324 (1.7390)  loss_classifier: 0.5083 (0.8079)  loss_box_reg: 0.5658 (0.6578)  loss_objectness: 0.1269 (0.1411)  loss_rpn_box_reg: 0.1332 (0.1322)  time: 0.6190  data: 0.0162  max mem: 3995\n",
            "Epoch: [0]  [110/121]  eta: 0:00:06  lr: 0.004625  loss: 1.3057 (1.6999)  loss_classifier: 0.4885 (0.7777)  loss_box_reg: 0.5399 (0.6495)  loss_objectness: 0.1204 (0.1387)  loss_rpn_box_reg: 0.1341 (0.1339)  time: 0.6174  data: 0.0158  max mem: 3995\n",
            "Epoch: [0]  [120/121]  eta: 0:00:00  lr: 0.005000  loss: 1.3221 (1.6692)  loss_classifier: 0.5021 (0.7568)  loss_box_reg: 0.5581 (0.6439)  loss_objectness: 0.0983 (0.1371)  loss_rpn_box_reg: 0.1336 (0.1314)  time: 0.6119  data: 0.0142  max mem: 3995\n",
            "Epoch: [0] Total time: 0:01:15 (0.6212 s / it)\n",
            "\n",
            "---------\n",
            "TRAIN ONE EPOCH FINISHED\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [  0/242]  eta: 0:06:03  model_time: 0.1815 (0.1815)  evaluator_time: 0.3804 (0.3804)  time: 1.5013  data: 0.9257  max mem: 3995\n",
            "Test:  [100/242]  eta: 0:00:33  model_time: 0.1277 (0.1297)  evaluator_time: 0.0602 (0.0673)  time: 0.2238  data: 0.0246  max mem: 3995\n",
            "Test:  [200/242]  eta: 0:00:09  model_time: 0.1285 (0.1298)  evaluator_time: 0.0615 (0.0662)  time: 0.2340  data: 0.0169  max mem: 3995\n",
            "Test:  [241/242]  eta: 0:00:00  model_time: 0.1273 (0.1297)  evaluator_time: 0.0441 (0.0673)  time: 0.2472  data: 0.0371  max mem: 3995\n",
            "Test: Total time: 0:00:56 (0.2317 s / it)\n",
            "Averaged stats: model_time: 0.1273 (0.1297)  evaluator_time: 0.0441 (0.0673)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.41s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.070\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.165\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.050\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.033\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.064\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.139\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.037\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.108\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.146\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.075\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.134\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.243\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [  0/242]  eta: 0:06:33  model_time: 0.1953 (0.1953)  evaluator_time: 0.4000 (0.4000)  time: 1.6253  data: 1.0160  max mem: 3995\n",
            "Test:  [100/242]  eta: 0:00:33  model_time: 0.1270 (0.1296)  evaluator_time: 0.0554 (0.0658)  time: 0.2205  data: 0.0173  max mem: 3995\n",
            "Test:  [200/242]  eta: 0:00:09  model_time: 0.1276 (0.1293)  evaluator_time: 0.0628 (0.0659)  time: 0.2393  data: 0.0204  max mem: 3995\n",
            "Test:  [241/242]  eta: 0:00:00  model_time: 0.1273 (0.1292)  evaluator_time: 0.0508 (0.0674)  time: 0.2414  data: 0.0307  max mem: 3995\n",
            "Test: Total time: 0:00:55 (0.2303 s / it)\n",
            "Averaged stats: model_time: 0.1273 (0.1292)  evaluator_time: 0.0508 (0.0674)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.42s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.070\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.165\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.050\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.033\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.064\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.139\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.037\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.108\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.146\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.075\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.134\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.243\n",
            "Epoch: [1]  [  0/121]  eta: 0:02:24  lr: 0.005000  loss: 1.1972 (1.1972)  loss_classifier: 0.4973 (0.4973)  loss_box_reg: 0.5318 (0.5318)  loss_objectness: 0.0915 (0.0915)  loss_rpn_box_reg: 0.0765 (0.0765)  time: 1.1980  data: 0.5468  max mem: 3995\n",
            "Epoch: [1]  [ 10/121]  eta: 0:01:14  lr: 0.005000  loss: 1.2656 (1.2584)  loss_classifier: 0.5019 (0.5171)  loss_box_reg: 0.5318 (0.5475)  loss_objectness: 0.0923 (0.0863)  loss_rpn_box_reg: 0.0899 (0.1075)  time: 0.6707  data: 0.0652  max mem: 3995\n",
            "Epoch: [1]  [ 20/121]  eta: 0:01:04  lr: 0.005000  loss: 1.2611 (1.2240)  loss_classifier: 0.4999 (0.4971)  loss_box_reg: 0.5366 (0.5395)  loss_objectness: 0.0680 (0.0770)  loss_rpn_box_reg: 0.1062 (0.1104)  time: 0.6140  data: 0.0162  max mem: 3995\n",
            "Epoch: [1]  [ 30/121]  eta: 0:00:57  lr: 0.005000  loss: 1.1952 (1.2283)  loss_classifier: 0.4718 (0.4911)  loss_box_reg: 0.5523 (0.5437)  loss_objectness: 0.0619 (0.0767)  loss_rpn_box_reg: 0.1227 (0.1167)  time: 0.6108  data: 0.0156  max mem: 3995\n",
            "Epoch: [1]  [ 40/121]  eta: 0:00:50  lr: 0.005000  loss: 1.1347 (1.1830)  loss_classifier: 0.4414 (0.4636)  loss_box_reg: 0.5196 (0.5323)  loss_objectness: 0.0579 (0.0743)  loss_rpn_box_reg: 0.0958 (0.1127)  time: 0.6108  data: 0.0159  max mem: 3995\n",
            "Epoch: [1]  [ 50/121]  eta: 0:00:44  lr: 0.005000  loss: 1.1230 (1.1843)  loss_classifier: 0.4266 (0.4628)  loss_box_reg: 0.5034 (0.5338)  loss_objectness: 0.0738 (0.0783)  loss_rpn_box_reg: 0.0853 (0.1095)  time: 0.6113  data: 0.0151  max mem: 3995\n",
            "Epoch: [1]  [ 60/121]  eta: 0:00:37  lr: 0.005000  loss: 1.1792 (1.1698)  loss_classifier: 0.4756 (0.4555)  loss_box_reg: 0.5160 (0.5287)  loss_objectness: 0.0899 (0.0775)  loss_rpn_box_reg: 0.1063 (0.1081)  time: 0.6124  data: 0.0143  max mem: 3995\n",
            "Epoch: [1]  [ 70/121]  eta: 0:00:31  lr: 0.005000  loss: 1.0865 (1.1622)  loss_classifier: 0.4284 (0.4518)  loss_box_reg: 0.5159 (0.5270)  loss_objectness: 0.0565 (0.0766)  loss_rpn_box_reg: 0.1104 (0.1067)  time: 0.6162  data: 0.0171  max mem: 3995\n",
            "Epoch: [1]  [ 80/121]  eta: 0:00:25  lr: 0.005000  loss: 1.1682 (1.1738)  loss_classifier: 0.4650 (0.4579)  loss_box_reg: 0.5153 (0.5284)  loss_objectness: 0.0611 (0.0788)  loss_rpn_box_reg: 0.1107 (0.1087)  time: 0.6222  data: 0.0176  max mem: 3995\n",
            "Epoch: [1]  [ 90/121]  eta: 0:00:19  lr: 0.005000  loss: 1.1777 (1.1613)  loss_classifier: 0.4650 (0.4503)  loss_box_reg: 0.5028 (0.5210)  loss_objectness: 0.0795 (0.0800)  loss_rpn_box_reg: 0.1055 (0.1100)  time: 0.6286  data: 0.0163  max mem: 3995\n",
            "Epoch: [1]  [100/121]  eta: 0:00:13  lr: 0.005000  loss: 1.1229 (1.1596)  loss_classifier: 0.4165 (0.4489)  loss_box_reg: 0.4805 (0.5206)  loss_objectness: 0.0610 (0.0788)  loss_rpn_box_reg: 0.1055 (0.1113)  time: 0.6287  data: 0.0168  max mem: 3995\n",
            "Epoch: [1]  [110/121]  eta: 0:00:06  lr: 0.005000  loss: 1.1584 (1.1608)  loss_classifier: 0.4576 (0.4503)  loss_box_reg: 0.5075 (0.5197)  loss_objectness: 0.0657 (0.0791)  loss_rpn_box_reg: 0.1068 (0.1118)  time: 0.6228  data: 0.0158  max mem: 3995\n",
            "Epoch: [1]  [120/121]  eta: 0:00:00  lr: 0.005000  loss: 1.1584 (1.1542)  loss_classifier: 0.4249 (0.4483)  loss_box_reg: 0.5075 (0.5184)  loss_objectness: 0.0657 (0.0773)  loss_rpn_box_reg: 0.0994 (0.1101)  time: 0.6151  data: 0.0143  max mem: 3995\n",
            "Epoch: [1] Total time: 0:01:15 (0.6228 s / it)\n",
            "\n",
            "---------\n",
            "TRAIN ONE EPOCH FINISHED\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [  0/242]  eta: 0:04:56  model_time: 0.1979 (0.1979)  evaluator_time: 0.3454 (0.3454)  time: 1.2266  data: 0.6690  max mem: 3995\n",
            "Test:  [100/242]  eta: 0:00:31  model_time: 0.1259 (0.1302)  evaluator_time: 0.0624 (0.0609)  time: 0.2207  data: 0.0235  max mem: 3995\n",
            "Test:  [200/242]  eta: 0:00:09  model_time: 0.1292 (0.1298)  evaluator_time: 0.0512 (0.0604)  time: 0.2351  data: 0.0278  max mem: 3995\n",
            "Test:  [241/242]  eta: 0:00:00  model_time: 0.1281 (0.1299)  evaluator_time: 0.0451 (0.0607)  time: 0.2346  data: 0.0291  max mem: 3995\n",
            "Test: Total time: 0:00:54 (0.2234 s / it)\n",
            "Averaged stats: model_time: 0.1281 (0.1299)  evaluator_time: 0.0451 (0.0607)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.41s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.108\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.239\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.084\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.047\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.095\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.220\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.063\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.156\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.198\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.114\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.177\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.309\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [  0/242]  eta: 0:05:24  model_time: 0.1882 (0.1882)  evaluator_time: 0.2796 (0.2796)  time: 1.3411  data: 0.8593  max mem: 3995\n",
            "Test:  [100/242]  eta: 0:00:31  model_time: 0.1260 (0.1293)  evaluator_time: 0.0500 (0.0606)  time: 0.2139  data: 0.0146  max mem: 3995\n",
            "Test:  [200/242]  eta: 0:00:09  model_time: 0.1279 (0.1291)  evaluator_time: 0.0550 (0.0605)  time: 0.2320  data: 0.0236  max mem: 3995\n",
            "Test:  [241/242]  eta: 0:00:00  model_time: 0.1276 (0.1292)  evaluator_time: 0.0483 (0.0615)  time: 0.2394  data: 0.0332  max mem: 3995\n",
            "Test: Total time: 0:00:54 (0.2232 s / it)\n",
            "Averaged stats: model_time: 0.1276 (0.1292)  evaluator_time: 0.0483 (0.0615)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.42s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.108\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.239\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.084\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.047\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.095\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.220\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.063\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.156\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.198\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.114\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.177\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.309\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlCt_fJY74uI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "424d5eab-c5cf-40cb-d275-145cca424c60"
      },
      "source": [
        "# if a model is saved:\n",
        "\n",
        "eval = train('drive/MyDrive/Models/model.pth',epochs = 2, train_percentage= .01, test_percentage=.01, gamma=.0001)\n",
        "\n",
        "save_model(eval[0], eval[1], eval[2], 'drive/MyDrive/Models/model.pth')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: [0]  [  0/121]  eta: 0:02:50  lr: 0.000047  loss: 3.1745 (3.1745)  loss_classifier: 2.1115 (2.1115)  loss_box_reg: 0.8876 (0.8876)  loss_objectness: 0.0644 (0.0644)  loss_rpn_box_reg: 0.1111 (0.1111)  time: 1.4057  data: 0.7539  max mem: 3112\n",
            "Epoch: [0]  [ 10/121]  eta: 0:01:14  lr: 0.000463  loss: 3.1582 (3.0457)  loss_classifier: 1.8906 (1.7987)  loss_box_reg: 0.8180 (0.8120)  loss_objectness: 0.2198 (0.2554)  loss_rpn_box_reg: 0.1870 (0.1796)  time: 0.6714  data: 0.0867  max mem: 4127\n",
            "Epoch: [0]  [ 20/121]  eta: 0:01:04  lr: 0.000879  loss: 2.3565 (2.5773)  loss_classifier: 1.1070 (1.4154)  loss_box_reg: 0.7818 (0.7808)  loss_objectness: 0.1625 (0.2244)  loss_rpn_box_reg: 0.1406 (0.1567)  time: 0.5955  data: 0.0176  max mem: 4188\n",
            "Epoch: [0]  [ 30/121]  eta: 0:00:56  lr: 0.001295  loss: 1.9072 (2.3240)  loss_classifier: 0.8569 (1.2049)  loss_box_reg: 0.7185 (0.7488)  loss_objectness: 0.1634 (0.2100)  loss_rpn_box_reg: 0.1361 (0.1603)  time: 0.5978  data: 0.0165  max mem: 4188\n",
            "Epoch: [0]  [ 40/121]  eta: 0:00:49  lr: 0.001712  loss: 1.7731 (2.1706)  loss_classifier: 0.7141 (1.0750)  loss_box_reg: 0.7161 (0.7360)  loss_objectness: 0.1608 (0.1980)  loss_rpn_box_reg: 0.1490 (0.1616)  time: 0.5991  data: 0.0170  max mem: 4188\n",
            "Epoch: [0]  [ 50/121]  eta: 0:00:43  lr: 0.002128  loss: 1.5783 (2.0488)  loss_classifier: 0.6303 (0.9829)  loss_box_reg: 0.6861 (0.7189)  loss_objectness: 0.1334 (0.1878)  loss_rpn_box_reg: 0.1490 (0.1591)  time: 0.5976  data: 0.0170  max mem: 4188\n",
            "Epoch: [0]  [ 60/121]  eta: 0:00:37  lr: 0.002544  loss: 1.5100 (1.9486)  loss_classifier: 0.5937 (0.9133)  loss_box_reg: 0.6132 (0.6969)  loss_objectness: 0.1326 (0.1835)  loss_rpn_box_reg: 0.1434 (0.1549)  time: 0.5950  data: 0.0152  max mem: 4188\n",
            "Epoch: [0]  [ 70/121]  eta: 0:00:31  lr: 0.002960  loss: 1.3935 (1.8652)  loss_classifier: 0.5700 (0.8592)  loss_box_reg: 0.5663 (0.6797)  loss_objectness: 0.1237 (0.1753)  loss_rpn_box_reg: 0.1259 (0.1510)  time: 0.5933  data: 0.0141  max mem: 4188\n",
            "Epoch: [0]  [ 80/121]  eta: 0:00:24  lr: 0.003377  loss: 1.3935 (1.8168)  loss_classifier: 0.5542 (0.8284)  loss_box_reg: 0.5852 (0.6730)  loss_objectness: 0.1137 (0.1676)  loss_rpn_box_reg: 0.1217 (0.1479)  time: 0.5985  data: 0.0147  max mem: 4201\n",
            "Epoch: [0]  [ 90/121]  eta: 0:00:18  lr: 0.003793  loss: 1.3536 (1.7643)  loss_classifier: 0.5725 (0.7948)  loss_box_reg: 0.5577 (0.6592)  loss_objectness: 0.1169 (0.1641)  loss_rpn_box_reg: 0.1177 (0.1462)  time: 0.6036  data: 0.0155  max mem: 4201\n",
            "Epoch: [0]  [100/121]  eta: 0:00:12  lr: 0.004209  loss: 1.3498 (1.7181)  loss_classifier: 0.5337 (0.7671)  loss_box_reg: 0.5459 (0.6460)  loss_objectness: 0.1207 (0.1599)  loss_rpn_box_reg: 0.1239 (0.1451)  time: 0.6082  data: 0.0166  max mem: 4201\n",
            "Epoch: [0]  [110/121]  eta: 0:00:06  lr: 0.004625  loss: 1.3293 (1.6684)  loss_classifier: 0.5110 (0.7391)  loss_box_reg: 0.5399 (0.6333)  loss_objectness: 0.0910 (0.1527)  loss_rpn_box_reg: 0.1248 (0.1433)  time: 0.6074  data: 0.0172  max mem: 4201\n",
            "Epoch: [0]  [120/121]  eta: 0:00:00  lr: 0.005000  loss: 1.3293 (1.6421)  loss_classifier: 0.5026 (0.7204)  loss_box_reg: 0.5225 (0.6271)  loss_objectness: 0.0845 (0.1503)  loss_rpn_box_reg: 0.1313 (0.1442)  time: 0.6009  data: 0.0158  max mem: 4201\n",
            "Epoch: [0] Total time: 0:01:13 (0.6070 s / it)\n",
            "\n",
            "---------\n",
            "TRAIN ONE EPOCH FINISHED\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py:5170: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self[name] = value\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "creating index...\n",
            "index created!\n",
            "Test:  [  0/242]  eta: 0:02:40  model_time: 0.1799 (0.1799)  evaluator_time: 0.0549 (0.0549)  time: 0.6641  data: 0.4209  max mem: 4201\n",
            "Test:  [100/242]  eta: 0:00:32  model_time: 0.1250 (0.1274)  evaluator_time: 0.0408 (0.0692)  time: 0.2149  data: 0.0212  max mem: 4201\n",
            "Test:  [200/242]  eta: 0:00:09  model_time: 0.1247 (0.1274)  evaluator_time: 0.0393 (0.0680)  time: 0.2134  data: 0.0195  max mem: 4201\n",
            "Test:  [241/242]  eta: 0:00:00  model_time: 0.1236 (0.1276)  evaluator_time: 0.0382 (0.0663)  time: 0.2265  data: 0.0129  max mem: 4201\n",
            "Test: Total time: 0:00:53 (0.2218 s / it)\n",
            "Averaged stats: model_time: 0.1236 (0.1276)  evaluator_time: 0.0382 (0.0663)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.41s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.082\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.184\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.059\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.035\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.078\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.176\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.038\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.113\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.156\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.085\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.152\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.272\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:56: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:95: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "creating index...\n",
            "index created!\n",
            "Test:  [  0/242]  eta: 0:02:39  model_time: 0.1779 (0.1779)  evaluator_time: 0.0362 (0.0362)  time: 0.6578  data: 0.4351  max mem: 4201\n",
            "Test:  [100/242]  eta: 0:00:32  model_time: 0.1241 (0.1269)  evaluator_time: 0.0410 (0.0681)  time: 0.2090  data: 0.0176  max mem: 4201\n",
            "Test:  [200/242]  eta: 0:00:09  model_time: 0.1252 (0.1280)  evaluator_time: 0.0477 (0.0673)  time: 0.2165  data: 0.0145  max mem: 4201\n",
            "Test:  [241/242]  eta: 0:00:00  model_time: 0.1238 (0.1278)  evaluator_time: 0.0305 (0.0662)  time: 0.2254  data: 0.0129  max mem: 4201\n",
            "Test: Total time: 0:00:53 (0.2221 s / it)\n",
            "Averaged stats: model_time: 0.1238 (0.1278)  evaluator_time: 0.0305 (0.0662)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.41s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.082\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.184\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.059\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.035\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.078\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.176\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.038\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.113\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.156\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.085\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.152\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.272\n",
            "Epoch: [1]  [  0/121]  eta: 0:02:27  lr: 0.005000  loss: 0.8861 (0.8861)  loss_classifier: 0.2568 (0.2568)  loss_box_reg: 0.4154 (0.4154)  loss_objectness: 0.0231 (0.0231)  loss_rpn_box_reg: 0.1909 (0.1909)  time: 1.2166  data: 0.5913  max mem: 4201\n",
            "Epoch: [1]  [ 10/121]  eta: 0:01:14  lr: 0.005000  loss: 1.2203 (1.2388)  loss_classifier: 0.4883 (0.4878)  loss_box_reg: 0.4946 (0.5228)  loss_objectness: 0.0882 (0.0885)  loss_rpn_box_reg: 0.1256 (0.1397)  time: 0.6682  data: 0.0703  max mem: 4201\n",
            "Epoch: [1]  [ 20/121]  eta: 0:01:04  lr: 0.005000  loss: 1.2516 (1.2745)  loss_classifier: 0.5070 (0.5117)  loss_box_reg: 0.5301 (0.5402)  loss_objectness: 0.0876 (0.0878)  loss_rpn_box_reg: 0.1248 (0.1348)  time: 0.6107  data: 0.0164  max mem: 4201\n",
            "Epoch: [1]  [ 30/121]  eta: 0:00:57  lr: 0.005000  loss: 1.2516 (1.2354)  loss_classifier: 0.5070 (0.4938)  loss_box_reg: 0.5169 (0.5280)  loss_objectness: 0.0863 (0.0889)  loss_rpn_box_reg: 0.1224 (0.1246)  time: 0.6102  data: 0.0161  max mem: 4201\n",
            "Epoch: [1]  [ 40/121]  eta: 0:00:50  lr: 0.005000  loss: 1.2830 (1.2454)  loss_classifier: 0.4639 (0.4870)  loss_box_reg: 0.5236 (0.5404)  loss_objectness: 0.0925 (0.0917)  loss_rpn_box_reg: 0.0964 (0.1263)  time: 0.6149  data: 0.0169  max mem: 4201\n",
            "Epoch: [1]  [ 50/121]  eta: 0:00:44  lr: 0.005000  loss: 1.2928 (1.2509)  loss_classifier: 0.4824 (0.4899)  loss_box_reg: 0.5485 (0.5353)  loss_objectness: 0.1067 (0.0961)  loss_rpn_box_reg: 0.1196 (0.1296)  time: 0.6154  data: 0.0149  max mem: 4201\n",
            "Epoch: [1]  [ 60/121]  eta: 0:00:37  lr: 0.005000  loss: 1.1814 (1.2326)  loss_classifier: 0.4408 (0.4785)  loss_box_reg: 0.5066 (0.5345)  loss_objectness: 0.0987 (0.0938)  loss_rpn_box_reg: 0.1120 (0.1257)  time: 0.6099  data: 0.0136  max mem: 4201\n",
            "Epoch: [1]  [ 70/121]  eta: 0:00:31  lr: 0.005000  loss: 1.1034 (1.2052)  loss_classifier: 0.4128 (0.4677)  loss_box_reg: 0.5024 (0.5256)  loss_objectness: 0.0682 (0.0890)  loss_rpn_box_reg: 0.0981 (0.1230)  time: 0.6064  data: 0.0138  max mem: 4201\n",
            "Epoch: [1]  [ 80/121]  eta: 0:00:25  lr: 0.005000  loss: 1.1518 (1.2136)  loss_classifier: 0.4432 (0.4690)  loss_box_reg: 0.5146 (0.5295)  loss_objectness: 0.0568 (0.0892)  loss_rpn_box_reg: 0.1233 (0.1259)  time: 0.6148  data: 0.0143  max mem: 4304\n",
            "Epoch: [1]  [ 90/121]  eta: 0:00:19  lr: 0.005000  loss: 1.2580 (1.2017)  loss_classifier: 0.4580 (0.4618)  loss_box_reg: 0.5428 (0.5286)  loss_objectness: 0.0713 (0.0870)  loss_rpn_box_reg: 0.1261 (0.1242)  time: 0.6144  data: 0.0147  max mem: 4304\n",
            "Epoch: [1]  [100/121]  eta: 0:00:12  lr: 0.005000  loss: 1.1792 (1.2036)  loss_classifier: 0.4363 (0.4616)  loss_box_reg: 0.5428 (0.5298)  loss_objectness: 0.0787 (0.0880)  loss_rpn_box_reg: 0.1266 (0.1243)  time: 0.6141  data: 0.0159  max mem: 4304\n",
            "Epoch: [1]  [110/121]  eta: 0:00:06  lr: 0.005000  loss: 1.2109 (1.2056)  loss_classifier: 0.4562 (0.4653)  loss_box_reg: 0.5460 (0.5292)  loss_objectness: 0.0804 (0.0875)  loss_rpn_box_reg: 0.1188 (0.1236)  time: 0.6196  data: 0.0169  max mem: 4304\n",
            "Epoch: [1]  [120/121]  eta: 0:00:00  lr: 0.005000  loss: 1.1903 (1.2011)  loss_classifier: 0.4931 (0.4644)  loss_box_reg: 0.4918 (0.5251)  loss_objectness: 0.0789 (0.0877)  loss_rpn_box_reg: 0.1144 (0.1239)  time: 0.6147  data: 0.0149  max mem: 4304\n",
            "Epoch: [1] Total time: 0:01:14 (0.6190 s / it)\n",
            "\n",
            "---------\n",
            "TRAIN ONE EPOCH FINISHED\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [  0/242]  eta: 0:02:47  model_time: 0.1900 (0.1900)  evaluator_time: 0.0606 (0.0606)  time: 0.6918  data: 0.4325  max mem: 4304\n",
            "Test:  [100/242]  eta: 0:00:32  model_time: 0.1261 (0.1292)  evaluator_time: 0.0382 (0.0663)  time: 0.2110  data: 0.0212  max mem: 4304\n",
            "Test:  [200/242]  eta: 0:00:09  model_time: 0.1275 (0.1293)  evaluator_time: 0.0309 (0.0662)  time: 0.2152  data: 0.0129  max mem: 4304\n",
            "Test:  [241/242]  eta: 0:00:00  model_time: 0.1260 (0.1291)  evaluator_time: 0.0375 (0.0649)  time: 0.2232  data: 0.0145  max mem: 4304\n",
            "Test: Total time: 0:00:53 (0.2225 s / it)\n",
            "Averaged stats: model_time: 0.1260 (0.1291)  evaluator_time: 0.0375 (0.0649)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.42s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.131\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.277\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.103\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.062\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.120\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.268\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.071\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.186\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.235\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.138\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.216\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.418\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [  0/242]  eta: 0:03:49  model_time: 0.1904 (0.1904)  evaluator_time: 0.0340 (0.0340)  time: 0.9486  data: 0.7152  max mem: 4304\n",
            "Test:  [100/242]  eta: 0:00:32  model_time: 0.1257 (0.1289)  evaluator_time: 0.0411 (0.0693)  time: 0.2129  data: 0.0215  max mem: 4304\n",
            "Test:  [200/242]  eta: 0:00:09  model_time: 0.1264 (0.1286)  evaluator_time: 0.0439 (0.0658)  time: 0.2145  data: 0.0213  max mem: 4304\n",
            "Test:  [241/242]  eta: 0:00:00  model_time: 0.1256 (0.1286)  evaluator_time: 0.0376 (0.0642)  time: 0.2202  data: 0.0146  max mem: 4304\n",
            "Test: Total time: 0:00:54 (0.2235 s / it)\n",
            "Averaged stats: model_time: 0.1256 (0.1286)  evaluator_time: 0.0376 (0.0642)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.42s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.131\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.277\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.103\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.062\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.120\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.268\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.071\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.186\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.235\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.138\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.216\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.418\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}