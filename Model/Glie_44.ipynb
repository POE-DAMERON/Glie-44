{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Glie_44.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/POE-DAMERON/Glie-44/blob/main/Model/Glie_44.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPx23mf0avpR"
      },
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow_hub as hub\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from os import path, listdir\n",
        "from pathlib import Path\n",
        "import cv2 as cv\n",
        "from google.colab import drive\n",
        "import sys\n",
        "import io\n",
        "import random\n",
        "\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "'''\n",
        "  Downloads Data from the VisDrone dataset.\n",
        "  Input is which dataset to download:\n",
        "    - 0 is the training dataset\n",
        "    - 1 is the developper testing dataset\n",
        "    - 2 is the actual challenge testing dataset\n",
        "    - 3 is the val dataset\n",
        "'''\n",
        "\n",
        "def initialize_training(file = 0):\n",
        "  !git clone https://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@github.com/POE-DAMERON/Glie-44.git\n",
        "  drive.mount('/content/drive')\n",
        "\n",
        "  \n",
        "  if file == 1:\n",
        "    !unzip /content/drive/MyDrive/VisDrone2019-MOT-test-dev.zip\n",
        "  elif file == 2:\n",
        "    !unzip /content/drive/MyDrive/VisDrone2019-MOT-test-challenge.zip\n",
        "  elif file == 3:\n",
        "    !unzip /content/drive/MyDrive/VisDrone2019-MOT-val.zip\n",
        "  else:\n",
        "    !unzip /content/drive/MyDrive/VisDrone2019-MOT-train.zip\n",
        "\n",
        "initialize_training()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDWgZe8DQZS4"
      },
      "source": [
        "**New Model using Pytorch**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23EcvQ0gWTmO"
      },
      "source": [
        "Main.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Saxy2LvOmdbn",
        "outputId": "1dff5b2e-2892-4423-bfb3-e3d6e6a80d69"
      },
      "source": [
        "%%shell\n",
        "\n",
        "git clone https://github.com/pytorch/vision.git\n",
        "cd vision\n",
        "git checkout v0.3.0\n",
        "\n",
        "cp references/detection/utils.py ../\n",
        "cp references/detection/transforms.py ../\n",
        "cp references/detection/coco_eval.py ../\n",
        "cp references/detection/engine.py ../\n",
        "cp references/detection/coco_utils.py ../"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'vision' already exists and is not an empty directory.\n",
            "HEAD is now at be376084 version check against PyTorch's CUDA version\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKOtVOkjWSps"
      },
      "source": [
        "import torch\n",
        "from engine import train_one_epoch, evaluate\n",
        "import utils\n",
        "import os\n",
        "import pandas as pd\n",
        "import transforms as T\n",
        "from pathlib import Path\n",
        "import csv\n",
        "import time\n",
        "import json\n",
        "\n",
        "def get_results(evaluator):\n",
        "  old_stdout = sys.stdout\n",
        "  sys.stdout = buffer = io.StringIO()\n",
        "\n",
        "  result = str(evaluator.coco_eval)\n",
        "  test = evaluator.coco_eval.items()\n",
        "  for iou_type, coco_eval in test:\n",
        "    print(\"IoU metric: {}\".format(iou_type))\n",
        "    try:\n",
        "      print(coco_eval)\n",
        "    except:\n",
        "      pass\n",
        "\n",
        "  sys.stdout = old_stdout\n",
        "\n",
        "  return buffer.getvalue()\n",
        "\n",
        "def add_to_record(arguments, output, is_saved = False, path_to_saved_model = ''):\n",
        "\n",
        "  with open('drive/MyDrive/training.csv', 'a', newline='') as f:\n",
        "    writer = csv.writer(f)\n",
        "\n",
        "    #writer.writerow(['Saved', 'path_to_saved_model', 'number_of_epochs', 'batch_size', 'optimizer', 'learning_rate', 'weight_decay', 'momentum', 'lr_scheduler_step_size', 'lr_scheduler_gamma', 'output'])\n",
        "    writer.writerow([is_saved, path_to_saved_model, arguments['number_of_epochs'], arguments['batch_size'], arguments['optimizer'], arguments['lr'], arguments['weight_decay'], arguments['momentum'], arguments['lr_scheduler_step_size'], arguments['lr_scheduler_gamma'], output])\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "  saving the model will add it to the record\n",
        "\"\"\"\n",
        "\n",
        "def save_model(model, evaluator, arguments, path = ''):\n",
        "\n",
        "  \"\"\"\n",
        "      saves the model and adds to the csv records\n",
        "\n",
        "      2 methods :\n",
        "        - saving the whole model\n",
        "        - saving the weights and info\n",
        "  \"\"\"\n",
        "\n",
        "  if path == '':\n",
        "    path = 'drive/MyDrive/Models/model-' + str(int(time.time())) + '.pth'\n",
        "\n",
        "  torch.save(model,path) \n",
        "\n",
        "  #torch.save(model.state_dict(), path)\n",
        "  add_to_record(arguments = arguments, output = evaluator, is_saved = True, path_to_saved_model = path)\n",
        "  \n",
        "def load_model(path):\n",
        "\n",
        "  model = torch.load(path)\n",
        "\n",
        "  \"\"\"\n",
        "    model = Model()\n",
        "    model.load_state_dict(torch.load(path))\n",
        "  \"\"\"\n",
        "\n",
        "  return model\n",
        "\n",
        "def save_checkpoints(dicti, path = 'drive/MyDrive/Checkpoints/checkpoint.txt'):\n",
        "  with open(path, 'w') as f:\n",
        "    f.write(json.dumps(dicti))\n",
        "\n",
        "def load_checkpoints(path = 'drive/MyDrive/Checkpoints/checkpoint.txt'):\n",
        "  dicti = {}\n",
        "  with open(path, 'r') as f:\n",
        "    dicti = json.loads(f.read())\n",
        "  return dicti\n",
        "\n",
        "def get_arguments(train_percentage, epochs, batch_size, optimizer,\n",
        "                            lr, momentum, weight_decay, step_size, gamma):\n",
        "  \n",
        "  arguments = {}\n",
        "\n",
        "  arguments['train_percentage'] = train_percentage\n",
        "  if (optimizer == 'adam'):\n",
        "    arguments['optimizer'] = optimizer\n",
        "    arguments['momentum'] = ''\n",
        "  else:\n",
        "    arguments['optimizer'] = 'sgd'\n",
        "    arguments['momentum'] = momentum\n",
        "  arguments['lr'] = lr\n",
        "  arguments['weight_decay'] = weight_decay\n",
        "  arguments['lr_scheduler_step_size'] = step_size\n",
        "  arguments['lr_scheduler_gamma'] = gamma\n",
        "  arguments['number_of_epochs'] = epochs\n",
        "  arguments['batch_size'] = batch_size\n",
        "\n",
        "  return arguments\n",
        "\n",
        "def train_videos(path_to_saved_model = '', train_percentage = .8, test_size = -1,\n",
        "          train_size = -1, batch_size = 2, epochs = 10, optimizer='sgd',\n",
        "          lr = 0.005, momentum = 0.9, weight_decay= 0.0005, step_size = 3,\n",
        "          gamma = 0.1):\n",
        "  \n",
        "  arguments = get_arguments(train_percentage, epochs, batch_size, optimizer,\n",
        "                            lr, momentum, weight_decay, step_size, gamma)\n",
        "  \n",
        "  if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "  else:\n",
        "    device = torch.device('cpu')\n",
        "  \n",
        "  x = VisDroneDataset(Path().absolute().joinpath('VisDrone2019-MOT-train'), Utils.to_tensor())\n",
        "  testing_data = torch.utils.data.DataLoader(x[0])\n",
        "\n",
        "  for i in range(len(x)):\n",
        "\n",
        "    print(\"\\n-----------------------------\\nVideo {} / {}\\n\".format(i+1, len(x)))\n",
        "\n",
        "    X = x[i]\n",
        "\n",
        "    if train_size == -1:\n",
        "      train_sz = int(len(X) * train_percentage)\n",
        "    else:\n",
        "      train_sz = train_size\n",
        "      \n",
        "    x_train, x_test = torch.utils.data.random_split(X, [train_sz, len(X) - train_sz])\n",
        "\n",
        "    if test_size != -1:\n",
        "      x_test = Utils.slice(x_test, 0, test_size)\n",
        "\n",
        "    data_loader = torch.utils.data.DataLoader(\n",
        "          x_train, batch_size=batch_size, shuffle=True, num_workers=2,\n",
        "          collate_fn=utils.collate_fn)\n",
        "    \n",
        "    data_loader_test = torch.utils.data.DataLoader(\n",
        "      x_test, batch_size=1, shuffle=False, num_workers=2,\n",
        "      collate_fn=utils.collate_fn)\n",
        "    \n",
        "    testing_data = data_loader_test\n",
        "    \n",
        "    if str(path_to_saved_model) == '':\n",
        "      model = build_model()\n",
        "    else:\n",
        "      model = load_model(path_to_saved_model)\n",
        "\n",
        "    model.to(device)\n",
        "\n",
        "    params = [p for p in model.parameters() if p.requires_grad]\n",
        "\n",
        "    if (optimizer == 'adam'):\n",
        "      optim = torch.optim.Adam(params, lr=lr, weight_decay=weight_decay)\n",
        "    else:\n",
        "      optim = torch.optim.SGD(params, lr=lr,\n",
        "                              momentum=momentum, weight_decay=weight_decay)\n",
        "\n",
        "    lr_scheduler = torch.optim.lr_scheduler.StepLR(optim,\n",
        "                                                    step_size=step_size,\n",
        "                                                    gamma=gamma)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "          train_one_epoch(model, optim, data_loader, device, epoch, print_freq=10)\n",
        "          lr_scheduler.step()\n",
        "          evaluate(model, testing_data, device=device)\n",
        "  \n",
        "  return model, evaluate(model, testing_data, device=device), arguments\n",
        "\n",
        "def train(path_to_saved_model = '', train_percentage = .8, test_percentage = -1,\n",
        "          test_size = -1, train_size = -1, batch_size = 2, epochs = 10, cur_epoch=0, optimizer='sgd',\n",
        "          lr = 0.005, momentum = 0.9, weight_decay= 0.0005, step_size = 3,\n",
        "          gamma = 0.1, checkpoints=-1, load_checkpoint=False):\n",
        "  \n",
        "  arguments = get_arguments(train_percentage, epochs, batch_size, optimizer,\n",
        "                            lr, momentum, weight_decay, step_size, gamma)\n",
        "  \n",
        "  if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "  else:\n",
        "    device = torch.device('cpu')\n",
        "  \n",
        "  X = AllVisDroneVideos(Path().absolute().joinpath('VisDrone2019-MOT-train').joinpath(\"sequences\"), Path().absolute().joinpath('VisDrone2019-MOT-train').joinpath(\"annotations\"), Utils.to_tensor())\n",
        "\n",
        "  \n",
        "    \n",
        "  if str(path_to_saved_model) == '':\n",
        "    model = build_model()\n",
        "  else:\n",
        "    model = load_model(path_to_saved_model)\n",
        "\n",
        "  if load_checkpoint:\n",
        "    checkpoint = load_checkpoints()\n",
        "    gamma = checkpoint['gamma']\n",
        "    cur_epoch = checkpoint['cur_epoch']\n",
        "\n",
        "  model.to(device)\n",
        "\n",
        "  params = [p for p in model.parameters() if p.requires_grad]\n",
        "\n",
        "  if (optimizer == 'adam'):\n",
        "    optim = torch.optim.Adam(params, lr=lr, weight_decay=weight_decay)\n",
        "  else:\n",
        "    optim = torch.optim.SGD(params, lr=lr,\n",
        "                              momentum=momentum, weight_decay=weight_decay)\n",
        "\n",
        "  lr_scheduler = torch.optim.lr_scheduler.StepLR(optim,\n",
        "                                                    step_size=step_size,\n",
        "                                                    gamma=gamma)\n",
        "\n",
        "  for epoch in range(cur_epoch + 1,epochs):\n",
        "    \n",
        "    \"\"\"\n",
        "      Shuffles the data\n",
        "    \"\"\"\n",
        "\n",
        "    if train_size == -1:\n",
        "      train_sz = int(len(X) * train_percentage)\n",
        "    else:\n",
        "      train_sz = train_size\n",
        "    \n",
        "    if test_percentage == -1:\n",
        "        test_sz = len(X) - train_sz\n",
        "    else:\n",
        "        test_sz = int(len(X) * min(1,max(0, test_percentage)))\n",
        "\n",
        "    #x_train, x_test, x_overflow = torch.utils.data.random_split(X, [train_sz, test_sz , len(X) - train_sz - test_sz])\n",
        "\n",
        "    random.shuffle(X.imgs)\n",
        "\n",
        "    x_train = AllVisDroneVideos(Path().absolute().joinpath('VisDrone2019-MOT-train').joinpath(\"sequences\"), Path().absolute().joinpath('VisDrone2019-MOT-train').joinpath(\"annotations\"), Utils.to_tensor(), X.imgs[:train_sz])\n",
        "    x_test = AllVisDroneVideos(Path().absolute().joinpath('VisDrone2019-MOT-train').joinpath(\"sequences\"), Path().absolute().joinpath('VisDrone2019-MOT-train').joinpath(\"annotations\"), Utils.to_tensor(), X.imgs[train_sz:train_sz + test_sz])\n",
        "\n",
        "    if test_size != -1:\n",
        "      x_test = Utils.slice(x_test, 0, test_size)\n",
        "\n",
        "    data_loader = torch.utils.data.DataLoader(\n",
        "        x_train, batch_size=batch_size, shuffle=True, num_workers=2,\n",
        "        collate_fn=utils.collate_fn)\n",
        "      \n",
        "    data_loader_test = torch.utils.data.DataLoader(\n",
        "        x_test, batch_size=1, shuffle=False, num_workers=2,\n",
        "        collate_fn=utils.collate_fn)\n",
        "    \n",
        "    train_one_epoch(model, optim, data_loader, device, epoch, print_freq=10)\n",
        "    print('\\n---------\\nTRAIN ONE EPOCH FINISHED\\n')\n",
        "    lr_scheduler.step()\n",
        "    #evaluate(model, data_loader_test, device=device)\n",
        "    results = get_results(evaluate(model, data_loader_test, device=device))\n",
        "    if checkpoints != -1 and epoch % checkpoints == 0:\n",
        "      save_model(model, results, arguments, path_to_saved_model)\n",
        "      save_checkpoints({'cur_epoch': epoch, 'gamma': gamma})\n",
        "      print('\\nModel Saved\\n')\n",
        "  \n",
        "  return model, results, arguments\n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyCvAuqO12L1"
      },
      "source": [
        "import torchvision\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from torchvision.models.detection import FasterRCNN\n",
        "from torchvision.models.detection.rpn import AnchorGenerator\n",
        "\n",
        "def build_model(num_classes = 12):\n",
        "  model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "  in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "  model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
        "\n",
        "  \"\"\"\n",
        "  backbone = torchvision.models.mobilenet_v2(pretrained=True).features\n",
        "  backbone.out_channels = 1280\n",
        "\n",
        "  anchor_generator = AnchorGenerator(sizes=((32, 64, 128, 256, 512),),\n",
        "                                    aspect_ratios=((0.5, 1.0, 2.0),))\n",
        "\n",
        "  roi_pooler = torchvision.ops.MultiScaleRoIAlign(featmap_names=['0'],\n",
        "                                                  output_size=7,\n",
        "                                                  sampling_ratio=2)\n",
        "  return FasterRCNN(backbone,\n",
        "                    num_classes=num_classes,\n",
        "                    rpn_anchor_generator=anchor_generator,\n",
        "                    box_roi_pool=roi_pooler)\n",
        "  \"\"\"\n",
        "  return model"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLmxWKCkRRan"
      },
      "source": [
        "class VisDroneVideo(object):\n",
        "    def __init__(self ,root, target_path, preprocessing = None, imgs = None):\n",
        "        self.root = str(root)\n",
        "        self.preprocessing = preprocessing\n",
        "        if (imgs != None):\n",
        "          self.imgs = imgs\n",
        "        else:\n",
        "          self.imgs = sorted(listdir(Path(root)), key=lambda x: x.lstrip(\"_\"))\n",
        "        self.target = target_path\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        img_path = Path(self.root).joinpath(self.imgs[idx])\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        video_targets = Utils.read_txt_visdrone(self.target)\n",
        "        image_targets = self.clean_targets(video_targets, idx)\n",
        "        image_targets[\"is_crowd\"] = 0\n",
        "        boxes = image_targets[[\"bbox_left\", \"bbox_top\", \"right\", \"bottom\"]]\n",
        "\n",
        "        boxes = boxes.astype('float32')\n",
        "\n",
        "        boxes = torch.as_tensor(boxes.values, dtype=torch.float32)\n",
        "        labels = torch.as_tensor(image_targets.object_category.astype('int64').values, dtype=torch.int64)\n",
        "        crowd = torch.as_tensor(image_targets.is_crowd.values, dtype=torch.int64)\n",
        "\n",
        "        image_id = torch.tensor([idx])\n",
        "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
        "\n",
        "        target = {}\n",
        "        target[\"boxes\"] = boxes\n",
        "        target[\"labels\"] = labels\n",
        "        target[\"image_id\"] = image_id\n",
        "        target[\"area\"] = area\n",
        "        target[\"iscrowd\"] = crowd\n",
        "\n",
        "        if self.preprocessing is not None:\n",
        "            img, target = self.preprocessing(img, target)\n",
        "\n",
        "        return img, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.imgs)\n",
        "\n",
        "    def clean_targets(self, targets, idx):\n",
        "\n",
        "        targets = self.targetsToDataframe(targets)\n",
        "        targets = targets[(targets.object_category != \"0\")]\n",
        "        targets = targets[(targets.frame_index == str(idx+1))]\n",
        "\n",
        "        targets.bbox_top = targets.bbox_top.astype('float32')\n",
        "        targets.bbox_height = targets.bbox_height.astype('float32')\n",
        "        targets.bbox_left = targets.bbox_left.astype('float32')\n",
        "        targets.bbox_width = targets.bbox_width.astype('float32')\n",
        "\n",
        "        targets[\"bottom\"] = targets.bbox_top + targets.bbox_height\n",
        "        targets[\"right\"] = targets.bbox_left + targets.bbox_width\n",
        "\n",
        "        return targets\n",
        "    \n",
        "    def targetsToDataframe(self, array):\n",
        "        columns = [\n",
        "          \"frame_index\",\n",
        "          \"target_id\",\n",
        "          \"bbox_left\",\n",
        "          \"bbox_top\",\n",
        "          \"bbox_width\",\n",
        "          \"bbox_height\",\n",
        "          \"score\",\n",
        "          \"object_category\",\n",
        "          \"truncation\",\n",
        "          \"oclusion\"\n",
        "        ]\n",
        "        return pd.DataFrame(data=array,columns=columns)\n",
        "\n",
        "class AllVisDroneVideos(VisDroneVideo):\n",
        "    def __init__(self,root, targets_path, preprocessing = None, imgs = None):\n",
        "      super().__init__(root, targets_path, preprocessing, imgs)\n",
        "      self.targets = sorted(listdir(Path(targets_path)), key=lambda x: x.lstrip(\"_\"))\n",
        "\n",
        "    def __len__(self):\n",
        "      return super().__len__()\n",
        "\n",
        "    def get_video_name(self, image_path):\n",
        "      return image_path.stem[:-8] + \".txt\", int(image_path.stem[-7:]) -1\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = Path(self.root).joinpath(self.imgs[idx])\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        video_name, image_idx = self.get_video_name(img_path)\n",
        "\n",
        "        video_targets = Utils.read_txt_visdrone(Path(self.target).joinpath(video_name))\n",
        "        image_targets = self.clean_targets(video_targets, image_idx)\n",
        "        image_targets[\"is_crowd\"] = 0\n",
        "        boxes = image_targets[[\"bbox_left\", \"bbox_top\", \"right\", \"bottom\"]]\n",
        "\n",
        "        boxes = boxes.astype('float32')\n",
        "\n",
        "        boxes = torch.as_tensor(boxes.values, dtype=torch.float32)\n",
        "        labels = torch.as_tensor(image_targets.object_category.astype('int64').values, dtype=torch.int64)\n",
        "        crowd = torch.as_tensor(image_targets.is_crowd.values, dtype=torch.int64)\n",
        "\n",
        "        image_id = torch.tensor([idx])\n",
        "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
        "\n",
        "        target = {}\n",
        "        target[\"boxes\"] = boxes\n",
        "        target[\"labels\"] = labels\n",
        "        target[\"image_id\"] = image_id\n",
        "        target[\"area\"] = area\n",
        "        target[\"iscrowd\"] = crowd\n",
        "\n",
        "        if self.preprocessing is not None:\n",
        "            img, target = self.preprocessing(img, target)\n",
        "\n",
        "        return img, target\n",
        "\n",
        "    def get_video_from_idx(self,idx):\n",
        "\n",
        "      video_lengths = [269, 58, 118, 501, 181, 85, 217, 97, 361, 361,\n",
        " 516, 1255, 398, 412, 213, 256, 261, 307, 348, 225, 421, 680, 341, 768, 721,\n",
        " 677, 725, 616, 548, 116, 680, 872, 962, 547, 508, 1424, 500, 210, 346, 556, \n",
        " 414, 230, 185, 403, 632, 127, 426, 369, 196, 277, 196, 691, 421, 219, 462,296]\n",
        "      \n",
        "      for i in range(len(video_lengths)):\n",
        "        if idx<video_lengths[i]:\n",
        "          return i, idx\n",
        "        else:\n",
        "          idx -= video_lengths[i]\n",
        "      return len(video_lengths), idx\n",
        "\n",
        "class VisDroneDataset(object):\n",
        "    def __init__(self, root, preprocessing = None):\n",
        "        self.root = root\n",
        "        self.preprocessing = preprocessing\n",
        "        \n",
        "        self.videos = sorted(listdir(Path(root).joinpath(\"sequences\")), key=lambda x: x.lstrip(\"_\"))\n",
        "        self.targets = sorted(listdir(Path(root).joinpath(\"annotations\")), key=lambda x: x.lstrip(\"_\"))\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "      return VisDroneVideo(Path(self.root).joinpath(\"sequences\").joinpath(self.videos[idx]),Path(self.root).joinpath(\"annotations\").joinpath(self.targets[idx]), self.preprocessing)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.videos)\n",
        "\n",
        "    '''\n",
        "        Concatenates the images of all videos into a large VisDroneVideo class\n",
        "        Allows the model to train on a broader sample of data\n",
        "    \n",
        "\n",
        "    def all_images(self):\n",
        "        large_dataset = VisDroneVideo()\n",
        "\n",
        "        for i in self:\n",
        "          for j in i[0]:\n",
        "            print(j)\n",
        "\n",
        "    '''"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3XhaZ_CZ6Z1"
      },
      "source": [
        "Utils.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfKM3TFaZ6M8"
      },
      "source": [
        "class Utils():\n",
        "\n",
        "  @staticmethod\n",
        "  def to_tensor():\n",
        "    transforms = []\n",
        "    # converts the image, a PIL image, into a PyTorch Tensor\n",
        "    transforms.append(T.ToTensor())\n",
        "    return T.Compose(transforms)\n",
        "\n",
        "  @staticmethod\n",
        "  def read_txt_visdrone(path):\n",
        "      \"\"\"\n",
        "          Input: Path of the txt file with annotations as in the VisDrone dataset\\n\n",
        "          Output: A numpy array containing the information for bounding boxes\n",
        "      \"\"\"\n",
        "      lines = []\n",
        "      with open(path) as f:\n",
        "          lines = f.readlines()\n",
        "          f.close()\n",
        "      df = []\n",
        "      for x in lines:\n",
        "          splitLine = x.split(\",\")\n",
        "          splitLine[-1] = splitLine[-1].split(\"\\n\")[0]\n",
        "          df.append(splitLine)\n",
        "      return df\n",
        "      \n",
        "  @staticmethod\n",
        "  def bottom_right(left,top,width,height):\n",
        "      \"\"\"\n",
        "          Input: co-ordinates for the top left corner of a bounding box and its width and height\\n\n",
        "          Output: co-ordinates for the bottom right corner\n",
        "      \"\"\"\n",
        "      bottom = top + height\n",
        "      right = left + width\n",
        "      return right, bottom\n",
        "\n",
        "  @staticmethod\n",
        "  def slice(array, start, stop):\n",
        "    result = []\n",
        "    for i in range(stop-start):\n",
        "      result.append(array[start + i])\n",
        "    return result"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlCt_fJY74uI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "973460c9-1566-4f41-a2e8-10c26f27644a"
      },
      "source": [
        "#eval = train('drive/MyDrive/Models/model.pth', epochs = 100, train_percentage= .65, test_percentage = .2, load_checkpoint=False, checkpoints = 1, gamma=.0001, cur_epoch = 1)\n",
        "eval = train('drive/MyDrive/Models/model.pth', epochs = 100, train_percentage= .7, load_checkpoint=True, checkpoints = 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: [3]  [   0/8470]  eta: 4:06:03  lr: 0.005000  loss: 0.6077 (0.6077)  loss_classifier: 0.1536 (0.1536)  loss_box_reg: 0.3202 (0.3202)  loss_objectness: 0.0515 (0.0515)  loss_rpn_box_reg: 0.0824 (0.0824)  time: 1.7431  data: 0.9709  max mem: 6244\n",
            "Epoch: [3]  [  10/8470]  eta: 1:44:17  lr: 0.005000  loss: 0.5854 (0.5707)  loss_classifier: 0.1505 (0.1596)  loss_box_reg: 0.3134 (0.3000)  loss_objectness: 0.0244 (0.0289)  loss_rpn_box_reg: 0.0824 (0.0822)  time: 0.7397  data: 0.1063  max mem: 6244\n",
            "Epoch: [3]  [  20/8470]  eta: 1:37:50  lr: 0.005000  loss: 0.5750 (0.5776)  loss_classifier: 0.1709 (0.1684)  loss_box_reg: 0.3134 (0.3143)  loss_objectness: 0.0208 (0.0256)  loss_rpn_box_reg: 0.0632 (0.0693)  time: 0.6423  data: 0.0198  max mem: 6244\n",
            "Epoch: [3]  [  30/8470]  eta: 1:35:32  lr: 0.005000  loss: 0.5772 (0.5817)  loss_classifier: 0.1715 (0.1709)  loss_box_reg: 0.3262 (0.3189)  loss_objectness: 0.0201 (0.0262)  loss_rpn_box_reg: 0.0505 (0.0658)  time: 0.6459  data: 0.0179  max mem: 6244\n",
            "Epoch: [3]  [  40/8470]  eta: 1:34:33  lr: 0.005000  loss: 0.6344 (0.5912)  loss_classifier: 0.1818 (0.1774)  loss_box_reg: 0.3315 (0.3214)  loss_objectness: 0.0244 (0.0257)  loss_rpn_box_reg: 0.0611 (0.0667)  time: 0.6502  data: 0.0167  max mem: 6244\n",
            "Epoch: [3]  [  50/8470]  eta: 1:33:43  lr: 0.005000  loss: 0.6359 (0.5968)  loss_classifier: 0.1843 (0.1798)  loss_box_reg: 0.3345 (0.3237)  loss_objectness: 0.0206 (0.0257)  loss_rpn_box_reg: 0.0637 (0.0676)  time: 0.6503  data: 0.0165  max mem: 6244\n",
            "Epoch: [3]  [  60/8470]  eta: 1:33:19  lr: 0.005000  loss: 0.5777 (0.5910)  loss_classifier: 0.1808 (0.1770)  loss_box_reg: 0.3196 (0.3226)  loss_objectness: 0.0205 (0.0249)  loss_rpn_box_reg: 0.0563 (0.0664)  time: 0.6511  data: 0.0167  max mem: 6244\n",
            "Epoch: [3]  [  70/8470]  eta: 1:33:02  lr: 0.005000  loss: 0.5774 (0.5914)  loss_classifier: 0.1806 (0.1784)  loss_box_reg: 0.3134 (0.3206)  loss_objectness: 0.0209 (0.0249)  loss_rpn_box_reg: 0.0507 (0.0674)  time: 0.6563  data: 0.0168  max mem: 6244\n",
            "Epoch: [3]  [  80/8470]  eta: 1:32:45  lr: 0.005000  loss: 0.5718 (0.5862)  loss_classifier: 0.1806 (0.1768)  loss_box_reg: 0.3095 (0.3177)  loss_objectness: 0.0226 (0.0247)  loss_rpn_box_reg: 0.0594 (0.0670)  time: 0.6559  data: 0.0160  max mem: 6244\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}